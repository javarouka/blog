{"title":"NonBlock","description":"javarouka 의 기술블로그","language":"ko","link":"https://blog.javarouka.me","webMaster":"JavaRouka","pubDate":"Thu, 08 Aug 2019 15:00:00 GMT","lastBuildDate":"Wed, 23 Sep 2020 03:57:47 GMT","generator":"hexo-generator-json-feed","items":[{"title":"[번역] Kotline Coroutine Basic","link":"https://blog.javarouka.me/2019/08/09/translate-kotlin-coroutine-basic/","description":"원문이 글은 번역글입니다. 오역에 주의하세요. https://kotlinlang.org/docs/reference/coroutines/basics.html 이 섹션에서는 기본적인 코틀린의 컨셉을 설명한다. My First Coroutine다음 코드를 실행해보라 12345678910import kotlinx.coroutines.*fun main() &#123; GlobalScope.launch &#123; // launch a new coroutine in background and continue delay(1000L) // non-blocking delay for 1 second (default time unit is ms) println(&quot;World!&quot;) // print after delay &#125; println(&quot;Hello,&quot;) // main thread continues while coroutine is delayed Thread.sleep(2000L) // block main thread for 2 seconds to keep JVM alive&#125; 모든 코드는 여기에 있다. 코드 실행으로 다음과 같은 결과를 볼 수 있다. 12Hello,World! 기본적으로 코루틴은 경량 스레드(light-weight thread)이다. 코루틴은 코루틴 스코프의 컨텍스트안의 빌더와 함께 시작된다. 여기서는 GlobalScope 에서 새 코루틴을 시작하고 있다. 이는 새 코루틴의 생명주기가 전체 어플리케이션의 생명주기에 제한된다는 것을 의미한다. GlobalScope.launch &#123; ... &#125; 를 thread &#123; ... &#125; 로 delay &#123; ... &#125; 을 Thread.sleep &#123; ... &#125; 로 바꿔도 같은 결과를 얻을 수 있다. 한번 해보자. 만일 GlobalScope.launch 를 thread 로 바꾸려고 하기 시작하면 컴파일러는 다음과 같은 에러를 낸다: Error: Kotlin: Suspend functions are only allowed to be called from a coroutine or another suspend function(에러: 코틀린: Suspend 함수들은 코루틴이나 다른 Suspend 함수에서의 호출만을 허용한다.) delay 는 코루틴 안에서만 사용되는, 코루틴을 중단 (suspend) 하고 스레드를 블럭하지 않는 특별한 sespending function 이기 때문이다. Bridging blocking and non-blocking worlds첫 예제는 같은 코드 안에 넌블럭킹(non-blocking) delay(...) 와 블럭킹(blocking) Thread.sleep 코드가 혼재되어 있다. 무엇이 블럭킹이고 무엇이 아닌지 따라가기 어려울 것이다. runBlocking 코루틴 빌더를 사용해서 블럭킹에 대해 명확히 밝혀보자. 123456789101112import kotlinx.coroutines.*fun main() &#123; GlobalScope.launch &#123; // launch a new coroutine in background and continue delay(1000L) println(&quot;World!&quot;) &#125; println(&quot;Hello,&quot;) // main thread continues here immediately runBlocking &#123; // but this expression blocks the main thread delay(2000L) // ... while we delay for 2 seconds to keep JVM alive &#125; &#125; 전체 코드는 여기에 있다 결과는 같지만, 이 코드는 단지 넌블럭킹 delay 를 사용한다. 메인 스레드를 실행하는 runBlocking 은 runBlocking 내부의 코루틴이 완료될 때까지 블럭된다. 이 예제는 더 관용적 방법으로 재작성할 수 있는데, main 함수 실행을 runBlocking 을 사용해 감싸는 것이다: 12345678910import kotlinx.coroutines.*fun main() = runBlocking&lt;Unit&gt; &#123; // start main coroutine GlobalScope.launch &#123; // launch a new coroutine in background and continue delay(1000L) println(&quot;World!&quot;) &#125; println(&quot;Hello,&quot;) // main coroutine continues here immediately delay(2000L) // delaying for 2 seconds to keep JVM alive&#125; 전체 코드는 여기에 있다 여기의 runBlocking&lt;Unit&gt; &#123; ... &#125; 은 최상위 메인 코루틴 시작에 사용되는 어댑터로서 작동한다. Unit 반환 형식을 명시적으로 지정하는데, 코루틴의 정상적인 메인 함수는 Unit 을 반환해야 하기 때문이다. 다음은 suspending 함수의 유닛 테스트를 작성하는 방법이다. 123456class MyTest &#123; @Test fun testMySuspendingFunction() = runBlocking&lt;Unit&gt; &#123; // here we can use suspending functions using any assertion style that we like &#125;&#125; Waiting for a job다른 코루틴이 동작할 동안 스레드의 시간을 지연키시는 것은 좋은 접근법이 아니다. 실행된 백그라운드 Job 이 완료될 때까지 명확하게 기다리자:(역자: 지금까지의 예제 코드가 코루틴이 종료될 때까지 Thread.sleep 으로 기다리는 부분을 말하고 있다.) 123456val job = GlobalScope.launch &#123; // launch a new coroutine and keep a reference to its Job delay(1000L) println(&quot;World!&quot;)&#125;println(&quot;Hello,&quot;)job.join() // wait until child coroutine completes 전체 코드는 여기에 있다 여전히 결과는 같지만, 메인 코루틴의 코드는 어떤 방식으로든 백드라운드 job 과 엮이지 않았다. 훨씬 낫다. Structured concurrency코루틴의 일반적이고 바람직한 사용법을 소개한다. GlobalScope.launch 을 사용하면 최상위 코루틴을 만든다. 실제 가벼운 동작일지라도, 여전히 동작하는 동안 조금의 메모리를 사용한다. 만일 새로 실행된 코루틴의 참조를 잊어도 코루틴은 여전히 실행된다. 만일 코루틴의 코드에 행이 걸리는 경우(예를 들면 과도하게 장시간 지연이 발생하는 경우) 나 너무 많은 코루틴이 실행되어 메모리 부족이 오는 경우엔 어떻게 될까?실행된 코루틴의 참조를 수동으로 유지하고 그것들을 join 하는 것은 오류가 나기 쉽다. 좋은 솔루션이 있다. 코드안에서 구조적 동시성을 사용할 수 있다. GlobalScope 에서 코루틴을 수행하는 대신, 일반적인 스레드와 함께 실행하는 것 처럼 수행중인 오퍼레이션 안의 특정 스코프에서 코루틴을 실행할 수 있다. 예제에서는 runBlocking 코루틴 빌더를 사용하여 코루틴으로 변환되는 메인 함수가 있다. runBlocking 을 포함한 코루틴 빌더로 생성되는 모든 코드 블럭 스코프에 CoroutineScope 인스턴스를 추가한다. 이 스코프 안에서는 코루틴을 명시적으로 join 하지 않고도 실행할 수 있는데, 바깥의 코루틴 (예제의 runBlocking) 이 그 스코프 안에서 실행된 모든 코루틴이 완료될 때까지 완료되지 않기 때문이다. 따라서 예제를 더욱 단순하게 만들 수 있다: 123456789import kotlinx.coroutines.*fun main() = runBlocking &#123; // this: CoroutineScope launch &#123; // launch a new coroutine in the scope of runBlocking delay(1000L) println(&quot;World!&quot;) &#125; println(&quot;Hello,&quot;)&#125; 전체 코드는 여기에 있다 Scope builder다른 빌더가 제공하는 코루틴 스코프 외에, coroutineScope Builder 를 사용해서 자신만의 스코프를 가지는 코루틴을 선언할 수 있다. coroutineScope Builder 는 코루틴 스코프를 생성하고 모든 자식들이 완료될 때까지 완료되지 않는다.runBlocking 과 coroutineScope 의 주된 차이점은 coroutineScope 이 모든 자식이 완료될 때까지 현재 스레드를 차단하지 않는다는 것이다. (역자: 관련해서 StackOverflow 의 이 질문 도 한번 보자) 1234567891011121314151617181920import kotlinx.coroutines.*fun main() = runBlocking &#123; // this: CoroutineScope launch &#123; delay(200L) println(&quot;Task from runBlocking&quot;) &#125; coroutineScope &#123; // Creates a coroutine scope launch &#123; delay(500L) println(&quot;Task from nested launch&quot;) &#125; delay(100L) println(&quot;Task from coroutine scope&quot;) // This line will be printed before the nested launch &#125; println(&quot;Coroutine scope is over&quot;) // This line is not printed until the nested launch completes&#125; 전체 코드는 여기에 있다 Extract function refactoringlaunch &#123; ... &#125; 안의 코드를 별도 함수로 추출해 보자. 이 코드에 함수 추출 리팩토링(역자: Intellij의 기능을 사용한다) 을 하면 suspend 수정자와 함께 새로운 함수가 추출된다. 이게 여기서 다루는 첫번째 suspending function 이다. suspending function 은 코루틴 안에서 일반 함수처럼 사용될 수 있으며, 추가적인 기능으로 예제의 delay 처럼 코루틴 실행을 일시적으로 suspend 할 수 있다. 123456789101112import kotlinx.coroutines.*fun main() = runBlocking &#123; launch &#123; doWorld() &#125; println(&quot;Hello,&quot;)&#125;// this is your first suspending functionsuspend fun doWorld() &#123; delay(1000L) println(&quot;World!&quot;)&#125; 전체 코드는 여기에 있다 그러나 추출된 함수에 현재 스코프에서 호출되는 코루틴 빌더가 포함되어 있으면 어떨까? 이 경우에 추출된 함수의 suspend 수정자는 충분하지 않다. CoroutineScope 에서 doWorld 를 확장 메소드(extension method) 로 만드는 것은 솔루션 중 하나이지만 API가 더 명확하지는 않으므로 항상 적용 가능한 것은 아니다. 관용적 솔루션은 대상 함수를 포함하는 클래스의 필드로 명시적 CoroutineScope 를 갖거나 외부 클래스가 CoroutineScope 를 구현할 때 암시적으로 그것을 필드로 가지는 것이다. 최후의 수단으로 CoroutineScope (coroutineContext) 를 사용할 수 있지만 이 방법으로는 실행 스코프를 더 이상 제어할 수 없기 때문에 이런 접근 방식은 구조적으로 안전하지 않다. 개인 API 만이 빌더를 사용할 수 있다. (뭔소리여… 아래 원문 붙임) But what if the extracted function contains a coroutine builder which is invoked on the current scope? In this case suspend modifier on the extracted function is not enough. Making doWorld an extension method on CoroutineScope is one of the solutions, but it may not always be applicable as it does not make API clearer. The idiomatic solution is to have either an explicit CoroutineScope as a field in a class containing the target function or an implicit one when the outer class implements CoroutineScope. As a last resort, CoroutineScope(coroutineContext) can be used, but such approach is structurally unsafe because you no longer have control on the scope of execution of this method. Only private APIs can use this builder. Coroutines ARE light-weight다음 코드를 보자 12345678910import kotlinx.coroutines.*fun main() = runBlocking &#123; repeat(100_000) &#123; // launch a lot of coroutines launch &#123; delay(1000L) print(&quot;.&quot;) &#125; &#125;&#125; 전체 코드는 여기에 있다 100K개의 코루틴을 시작하고 1초마다 후에 각 코루틴이 점을 찍는다. 이제 이 로직을 스레드로 시도해보라. 무슨 일이 일어날까? (아마도 Thread 를 사용한 코드에서 메모리 부족 오류가 발생할 것이다) Global coroutines are like daemon threads다음 코드는 GlobalScope 에서 “I’m sleeping” 을 1초에 두번 인쇄하고 그후 메인 함수에 약간의 delay 후 복귀하는 긴 시간의 코루틴을 실행한다: 1234567GlobalScope.launch &#123; repeat(1000) &#123; i -&gt; println(&quot;I&#39;m sleeping $i ...&quot;) delay(500L) &#125;&#125;delay(1300L) &#x2F;&#x2F; just quit after delay 전체 코드는 여기에 있다 실행하고 세줄이 찍히고 중단되는 걸 볼 수 있다. 123I&#39;m sleeping 0 ...I&#39;m sleeping 1 ...I&#39;m sleeping 2 ... GlobalScope에서 시작된 액티브 코루틴은 프로세스를 실행중인 상태로 유지하지 않는다. 그것들은 데몬 스레드와 비슷하다.","pubDate":"Thu, 08 Aug 2019 15:00:00 GMT","guid":"https://blog.javarouka.me/2019/08/09/translate-kotlin-coroutine-basic/","category":["kotlin","tech","translate","kotlin","coroutine"]},{"title":"Java / Kotlin 의 상속과 구성 (Inheritance & Composition) #1","link":"https://blog.javarouka.me/2019/04/07/interits-conposition/","description":"자바의 상속객체지향언어에서의 상속은 객체간의 관계를 언어레벨에서 정의하는 방법이다. 상속은 Simula 라는 언어의 객체지향적 부분에서 발전했다고 알려져 있다. C++ 개발자인 비야네 스트로스트롭이나 Java 개발자인 제임스 고슬링도 Simula 에서 언어 개발에 상당한 아이디어를 얻었다고. Java 의 상속은 다음과 같은 성격을 지닌다 수퍼/서브클래스어떤 클래스 B 가 다른 클래스 A 를 상속할 때 A를 수퍼클래스, B 를 서브클래스라고 한다. 간혹 수퍼타입/서브타입으로도 부르기도 하는데 다소 다른 의미다. 아래 코드에서 Truck 은 Car 의 서브클래스이기 때문에 자동차가게(CarStore) 에 Truck 을 둘 수 있다. 하지만 Ship 은 둘 수 없다. 1234567891011121314151617181920class Ship &#123;&#125;class Car &#123;&#125;class Truck extends Car &#123;&#125;class CarStore &#123; private Set&lt;Car&gt; carList = new HashSet&lt;&gt;(); public void put(Car car) &#123; carList.add(car); &#125;&#125;public class MainClass &#123; public static void main(String... args) &#123; CarStore shop = new CarStore(); shop.put(new Car()); shop.put(new Truck()); shop.put(new Ship()); // 컴파일 에러. 배는 차가 아니다. &#125;&#125; 상속관계인 클래스 Car 와 Truck 은 서로 각자의 타입이면서 클래스이다. 타입과 클래스는 다르다. 하나의 클래스는 대부분 두가지 이상의 타입으로 표현 될 수 있기 때문이다. 타입과 클래스Truck의 인스턴스는 Truck 와 Car 타입이 될 수 있다. 1234Car car = new Car();Truck truck = new Truck();Car truckCar = truck; // 가능하다.Object obj = truck; // 가능하다. Java 의 모든 클래스는 Object 를 상속하므로, Object 타입으로도 표현할 수 있다. 게다가 제네릭 클래스는 타입 인자에 따라 수많은 타입을 만들어낼 수 있다. 123ArrayList&lt;Object&gt; objs = new ArrayList&lt;Object&gt;();ArrayList&lt;Car&gt; cars = new ArrayList&lt;Car&gt;();ArrayList&lt;Truck&gt; trucks = new ArrayList&lt;Truck&gt;(); 다음과 같이 정리할 수 있겠다. 클래스는 구현 지향적이다. 내부 상태와 할 수 있는 연산이 구현되어 수행하는 자료구조에 가깝다. 타입은 선언 지향적이다. 특정 객체가 수행할 수 있는 일의 제한을 지정한다. 아마존 트럭. 트럭이고 차이고 기계이다. 타입 관계서브타입은 수퍼타입의 변수에 할당할 수 있다. 서브타입은 수퍼타입의 모든 기능을 상속받았고 수퍼타입이 할 수 있는 모든 일을 할 수 있으므로, 수퍼 타입이 할 수 있는 모든 기능이 문제없이 동작가능하게 구현되어야 한다. 리스코프 치환 원칙 으로도 부른다. 이러한 타입 관계에서는 변성(variance) 이라는 성질이 존재한다. 메서드의 인자로 전달된 객체의 상태가 변할땐 자신의 타입을 포함한 수퍼타입으로 제한되고, 특정 객체를 반환할 경우 반환형은 자신의 서브타입으로 제한된다. 특정 메서드에게 걸그룹을 인자로 전달하려면 특정 메서드의 선언은 걸그룹이거나 걸그룹의 수퍼타입(가수, 사람, 동물 …)이어야 한다. 특정 메서드에서 걸그룹을 반환할 경우 그 반환값은 걸그룹이거나 걸그룹의 서브타입(트와이스, 소녀시대 …)이어야 한다. 좀더 유식하게 표현하면 1번의 경우를 반공변적이라고 하고 2번의 경우를 공변적이라고 한다. 트와이스는 걸그룹이지만 소녀시대는 아니다. 가요무대 클래스의 멤버 메서드가 노래를 부를 가수 타입이 필요하다면 걸그룹 인자에 대해 반공변적이라고 할 수 있다. 보이그룹이나 솔로가수도 갈 수 있다. 하지만 걸그룹 어워드 클래스 메서드에서 특정 걸그룹중 1위를 반환한다고 하면 반환시에는 트와이스나 시스타, 소녀시대만으로 제한된다. 이때는 인자에 대해 공변적이다. 제네릭은 항상 서로 다르다제네릭을 처음 공부할때 다소 혼란스러운 부분이 제네릭 파라미터가 수퍼/서브타입의 관계일 경우 제네릭 클래스도 수퍼/서브타입이 성립할거라는 착각이다. 다음 코드는 컴파일 오류이다. 12// 호환되지 않는 타입. 컴파일 오류가 발생한다.ArrayList&lt;Car&gt; cars = new ArrayList&lt;Truck&gt;(); 제네릭 타입은 다른 모든 제네릭 타입과 수퍼/서브타입이 성립하지 않는다. 제네릭 파라미터화 타입이 서로 어떤 관계이든 항상 다른 타입이다. 이것을 유식한 단어로 불공변(invariant) 이리고 한다. 하지만 배열은 이상하다.배열은 위의 성질과 다르게 공변관계를 허용한다. 그래서 다음 코드는 문제가 없다 1Car[] cars = new Truck[1]; 문제는 위의 배열에 다음과 같은 코드를 실행할 때다. ArrayStoreException 이 발생하는데, 컴파일 타임이 아닌 런타임에 발생한다. 12// ArrayStoreExceptioncars[0] = new Taxi(); 배열은 제네릭과 다르게 런타임 시에도 타입이 소거되지 않고 유지하기 때문이다. 런타임 시 이 소거되지 않은 타입을 검사하며 오류를 출력한다. 배열의 이러한 공변성으로 인해 타입관련 잠재적인 런타임 오류가 발생할 수 있다. 이런 오류에 대해서는 컴파일러가 대부분은 경고를 해 주므로, 컴파일 시의 워닝 메시지를 무시하지 말자. 와일드카드 변성Java 에서는 배열의 제네릭 파라미터일 경우 이 관계를 와일드카드와 함께 써서 PECS (Producer-extends, Consumer-super) 로 정의한다. 123456789// 공변 제네릭 리스트List&lt;? extends GirlGroupSinger&gt; girlGroups1 = new ArrayList&lt;&gt;();// 이 문은 컴파일 오류이다. 이 값이 어떤 값인지 특정지을 수 없다.girlGroups1.add(new Twice());girlGroups1.add(new Sistar());// 걸그룹임이 보장된다.GirlGroupSinger some = girlGroups.get(0); 123456789// 반공변 제네릭 리스트List&lt;? super GirlGroupSinger&gt; girlGroups2 = new ArrayList&lt;&gt;(); // 걸그룹의 수퍼타입이면 뭐든 입력할 수 있다girlGroups1.add(new People());girlGroups1.add(new Animal());// 이 문은 컴파일 오류이다. 이 타입이 무엇인지 특정지을 수 없다.GirlGroupSinger some = girlGroups.get(0); 여기서 Producer 와 Consumer 의 주체는 제네릭 타입의 인자이다. extends 일 경우 인자가 값을 생산 (get) 한다는 의미이며 super 일 경우 인자가 값을 소비(set) 한다는 의미이다. 이 주제와 관련해서 좋은 StackOverflow 링크가 있다. https://bit.ly/2GdGEUh 자동 선언서브클래스는 수퍼클래스의 인스턴스 변수와 멤버 메서드들을 자동으로 상속한다. 상속한다는 뜻은 서브클래스에서 별도로 정의하지 않아도 정의된 것처럼 별도 선언 없이 사용할 수 있다. 인스턴스 변수, 멤버 메서드 라고 명시적으로 말한 건 static 으로 정의된 변수와 메서드는 제외되기 때문이다. 수퍼클래스에 대한 접근은 super 키워드를 사용한다. super 키워드는 사용처에 따라 다른 대상을 가르킨다. 생성자에서 사용되는 super 는 생성자 함수 를 가르킨다. 호출하는 함수 형태이다. 멤버 함수에서의 super 는 인스턴스 를 가르킨다. 부모 인스턴스를 레퍼런스하는 변수처럼 동작한다. 접근제어상속에 몇가지 제약을 걸 수 있는 접근제어자가 있다. Java 를 처음 학습할때 접하는 private, protected, public 이고 별도로 정의하지 않으면 default 접근제어가 적용된다. 보통 좋은 프로그램 코딩 가이드에서는 제한적인 접근을 먼저 적용하고 필요에 따라 넓혀가라고 조언된다. private 으로 전부 선언한 뒤, 필요에 따라 protected 혹은 public 으로 넓혀가는게 좋다. 애매한 건 default 접근 제어인데 이 케이스는 일반적인 케이스의 경우 잘 사용되지 않지만, 구현체를 직접적으로 사용하지 못하게 할때 유용하게 쓸 수 있다. 만일 같은 패키지에 UserInputController 클래스와 UserInputController 을 상속한 Mouse 클래스, Keyboard 클래스가 있다고 할 때 타 패키지에서는 UserInputController 으로만 추상적으로 접근하게 하고 싶다면 다음과 같이 구현하면 된다. 구현 클래스에는 public 접근제어 없이 default 로 선언했다 1234567891011// @file UserInputController.javapackage me.javarouka.input;public interface UserInputController &#123;&#125;// @file Mouse.javapackage me.javarouka.input;class Mouse implements UserInputController &#123;&#125;// @file Keyboard.javapackage me.javarouka.input;class Keyboard implements UserInputController &#123;&#125; 외부에서는 클래스를 생성하지 못한다. private 생성자 로도 이런 방법을 쓸 수 있지만, DI 프레임워크(Spring Framework 가 대중적이다.) 등을 쓰고 있다면 이 방법이 유용할 것이다. DI 프레임워크 등이 없다면 팩토리 클래스 같은 생성 헬퍼를 만들어줘야 할 것이다. 1234567891011package me.javarouka.input;public interface UserInputControllers &#123; public static UserInputController createMouse() &#123; return new Mouse(); &#125; public static UserInputController createKeyboard() &#123; return new Keyboard(); &#125;&#125; 실제 구현 클래스의 노출 없이 구현 클래스 타입을 제공하여 불필요한 정보 공개를 하지 않고 안전성을 높일 수 있다. 결론다음 포스트에서는 상속의 단점과 구성에 대해 알아보겠다. 그리고 코틀린에서 이런 상속 관계들을 어떻게 처리하는지 알아본다","pubDate":"Sat, 06 Apr 2019 15:00:00 GMT","guid":"https://blog.javarouka.me/2019/04/07/interits-conposition/","category":["java","kotlin","java","kotlin","composition","type","class","delegate"]},{"title":"[책] Elasticsearch In Action","link":"https://blog.javarouka.me/2019/04/07/book-elasticsearch-in-action/","description":"최근 엘라스틱서치를 좀 써보고 깊이 공부해야 할 필요성이 있어 인액션 시리즈를 구매해서 부록을 제외한 파트를 다 읽었다. 이런 두꺼운 책은 오랜만인것 같다. 읽으면서 많이 아쉬웠던건 예제나 설명이 구 버전에 맞춰져 있었고, 샘플 색인 데이터 스크립트는 Mac 에서 오동작했다 (스크립트 안의 curl 명령어를 조금 수정해줘야 색인할 수 있다) 번역의 품질은 번역서에서는 매우 중요한데 이 책은 번역 품질은 아쉽게도 그리 훌륭하지 않다. 용어 번역 그런 문제가 아니다.그냥 번역문이 매끄럽지가 못해서 같은 부분을 반복해서 읽어야 이해가 된다 (머리속에 더 잘남으려나;) 오탈자도 많다; 하지만 이런 단점에도 내용 자체가 깊이있고 훌륭하다. 상당히 괜찮은 책.","pubDate":"Sat, 06 Apr 2019 15:00:00 GMT","guid":"https://blog.javarouka.me/2019/04/07/book-elasticsearch-in-action/","category":["book","db","book","elasticsearch"]},{"title":"Redux-Saga 소개","link":"https://blog.javarouka.me/2019/04/02/redux-saga-1/","description":"Redux 와 부수효과Redux 는 상태 관리를 도와주는 간단한 라이브러리이다. 실제로도 소스코드 용량은 매우 작고, 해주는 일도 매우 단순하다. Redux 복습Redux 를 다들 잘 알겠지만 복습해보자. 스토어 액션 리듀서 Redux 는 자신이 관리하는 데이터 모음인 상태(state) 를 스토어(Store) 라는 저장소에 두고 이 상태를 변경할 수 있는 것은 액션(action) 으로 제한한다. 액션은 단순한 문자열이며 이 액션으로 상태를 변경하기 위해서는 스토어(Store) 에 디스패치(dispatch) 하는 행위가 필요하다. 디스패치(dispatch) 할 때 전달할 정보는 다음과 같은 인터페이스를 가지는 일반 자바스크립트 객체이다. 1234interface ReduxDispatchAction &#123; type: string, // required 액션은 반드시 문자열이어야 한다. [prop:any]?: any // optional N. 나머지는 옵셔널이며 객체에 할당할 수 있는 모든 키/값이 올 수 있다.&#125; 디스패치 함수는 스토어가 가지고 있고, 시그니쳐는 다음과 같다 123456interface ReduxStore &#123; dispatch(action: ReduxDispatchAction) =&gt; void // ... 스토어 기타 함수, subscribe 등&#125; 실제 사용 코드는 다음과 같다. doAmazingShow 라는 액션을 payload 속성과 같이 디스패치하는 코드다. 123456789// 문자열 액션const doAmazingShow = &#x27;doAmazingShow&#x27;store.dispatch(&#123; action: doAmazingShow, payload: &#123; invited: [ &#x27;Cool&#x27;, &#x27;Hot&#x27; ] &#125;&#125;); 디스패치의 결과로 reducer가 실행된다. reducer 는 모든 액션이 디스패치 될 때마다 액션과 현재 상태를 받는 단순한 함수다. reducer 의 시그니처는 다음과 같다. 123456789interface Reducer &#123; /** * @param currentState 현재 상태 * @param action 디스패치를 통해 전달된 액션 * @return 새로운 상태 객체 **/ (currentState): object, action: ReduxDispatchAction) =&gt; object&#125; 이 흐름은 한번의 실행 스택으로 수행되는데, 이 뜻은 다수의 액션 수행을 해도 그 순서를 보장한다는 뜻이다. 스크립트의 동작이 원래 그렇듯이 말이다. 여기까지가 Redux 의 간단한 흐름이다. 더 자세한 설명을 원하면 공식 사이트를 보자. Reducer 라는 네이밍은 Redux 제작자의 네이밍인데, 개인적으로는 액션처리기 같은 직관적 네이밍이 어땠을까 한다. 그럼 Redux 가 아니라 Execer 가 되었을지도 모르겠다. 그렇지만 액션을 누적해 하나의 상태로 처리하는 reduce 측면에서는 원래 이름인 Redux 가 더 어울린다. Side Effect실무에서 Redux 를 쓰다보면 액션이 동시다발적으로 발생되며, 액션 중간에 실제 Redux 액션이 아닌 일반 로직이 수행되거나 Ajax Call 등의 서버 리퀘스트도 발생한다. 그 와중에 여러 액션의 실행 보장도 해줘야 하는데, 자칫 코드가 상당히 난해해질 수 있다. 이럴때 사용을 고려해볼만한 라이브러리들이 몇개 있는대 대표적으로 Redux-Saga, Rx-Observable, MobX 등이다. Redux-Saga 나 Rx-Observable 등을 Redux 와 같이 사용할때 이점으로 보통 비동기 처리가 손쉽다…라는 문구로 광고가 보통 되지만, 구조화된 Redux 설계를 했다면 비동기 처리도 그렇게 더러워지진 않는다. (다시 말하면 설계가 좋지 않다면 유지보수가 힘든 스파게티가 나온다는 뜻이다) 사실 단순 비동기 처리보다 더 큰 어려움은 액션이 여러 의미를 가지게 되고 그에 맞춰 기능이 확장되면서 액션이 다른 액션과 체이닝되기 시작할 때이다. 이런 기능들을 기존의 Redux 로 일일해 대응하다보면 코드가 순식간에 누더기가 된다. 순진하게 액션 처리 후 다른액션, 그리고 그 액션 성공 후 다른 액션… 으로 이어지는 코드는 대부분 스파게티맛을 맛본다. 예를 들어 회원 정보 페이지가 있다고 해보자. 다음은 액션을 디스패치하는 코드이다. 12345678910111213141516const loadUser = async (&#123; userId &#125;) =&gt; &#123; try &#123; store.dispatch(&#123; type: &#x27;START_USER_LOADING&#x27; &#125;) const user = await Users.loadUser(userId) store.dispatch(&#123; type: &#x27;END_USER_LOADING&#x27;, payload: user &#125;) &#125; catch(error) &#123; store.dispatch(&#123; type: &#x27;FAIL_USER_LOADING&#x27;, payload: error &#125;) &#125;&#125; 하지만 앱에 새로운 기능이 추가되어 유저 로딩 후 사용자의 팔로워를 같이 로딩해야 한다고 해보자. 코드는 다음과 같이 변경할 수 있다 123456789101112131415161718192021222324252627282930313233343536const loadFollowersFrom = async (&#123; userId &#125;) =&gt; &#123; try &#123; store.dispatch(&#123; type: &#x27;START_FOLLOWER_LOADING&#x27; &#125;) const followers = await Users.loadFollowersFrom(userId); store.dispatch(&#123; type: &#x27;END_FOLLOWER_LOADING&#x27;, payload: user &#125;) &#125; catch(error) &#123; store.dispatch(&#123; type: &#x27;FAIL_FOLLOWER_LOADING&#x27;, payload: error &#125;) &#125;&#125;const loadUser = async (&#123; userId &#125;) =&gt; &#123; try &#123; store.dispatch(&#123; type: &#x27;START_USER_LOADING&#x27; &#125;) const user = await Users.loadUser(userId) store.dispatch(&#123; type: &#x27;END_USER_LOADING&#x27;, payload: user &#125;) // 이 부분이 추가되었다. 유저 정보 로딩 후 실행한다. loadFollowersFrom() &#125; catch(error) &#123; store.dispatch(&#123; type: &#x27;FAIL_USER_LOADING&#x27;, payload: error &#125;) &#125;&#125; 별로 나빠보이지 않는다. 그러나 이 코드는 앞으로의 코드 변경에 꽤나 힘들어질 수 있는 스타트를 끊은 코드다. 지금은 유저 정보 로딩 후 팔로워 로딩만 추가했지만 앞으로 이후 수많은 유저 관련 정보가 로딩될 수 있다. 예를 들면 추가적으로 유저 정보 로딩 후, 그 정보의 유무에 따라 현금성 결제 포인트와 이 유저를 방문한 유저를 로딩해야 할 수 있다. 그리고 사용성 트래킹을 위해 로그를 서버에 전송할 수도 있다. 그 호출 책임은 전부 loadUser 라는 함수가 담당하고 있다. 원래의 목적은 유저를 로딩한다는 목적으로 만들었지만, 이제는 유저도 로딩하고, 포인트도 로딩하고, 팔로워도 로딩하고 … 하는 함수가 되었다. 이쯤되면 이름을 loadUserThenFollowers 같은 이름으로 바꿔야 할지도 모르겠다. 더욱 힘들게 하는 건 만일 유저 정보 로딩 후 실행되는 부수 액션들(팔로워, 포인트…) 중 하나가 오류가 났을 때 각 부수 액션들끼리도 서로 영향을 줄 수 있다. 만일 비즈니스적으로 어떤 액션은 주변의 오류와 상관없이 진행해야 할 수도 있고 중단해야 할 수도 있다. 123456789101112131415161718192021222324252627const loadUser = async (&#123; userId &#125;) =&gt; &#123; try &#123; store.dispatch(&#123; type: &#x27;START_USER_LOADING&#x27; &#125;) const user = await Users.loadUser(userId) store.dispatch(&#123; type: &#x27;END_USER_LOADING&#x27;, payload: user &#125;) // FIXME 거슬리는 부분 1 // 비즈니스에 따라 처리해야 할 로직이 직접적으로 박힌다. // 이쯤 되면 함수 이름을 loadUser 가 아닌 다른걸로 바꾸는 걸 정말로 고려하는게 좋겠다. await loadFollowersFrom(userId) await loadPoint(userId) &#125; catch(error) &#123; store.dispatch(&#123; type: &#x27;FAIL_USER_LOADING&#x27;, payload: error &#125;) &#125; finally &#123; // FIXME 거슬리는 부분 2 // 오류 여부에 관계없이 실행해야 한다. await writeUserActionLogging(userId) &#125;&#125; 이러한 본래 액션 말고도 그 액션에 따라 다른 액션이나 이벤트가 파생되는건 꽤나 흔한 일이다. 이런 일을 부수효과 (Side-Effect) 라고 한다. Ajax 콜 비동기 타이머 애니메이션 후 콜백 요청 중 취소 스로틀링 디바운싱 페이지 이동 이러한 것은 일반적인 Redux의 액션 흐름으로는 나타내기가 조금 어렵고, 비동기 수행시에는 어디엔가 dispatch 함수의 레퍼런스를 가지고 있다가 필요할때에 호출하면서 수행해야 한다. 이러한 부수 효과들은 Redux-Saga 를 쓴다면 꽤 단순하고 직관적으로 풀어낼 수 있다. Redux Saga 적용다음은 Redux-Saga 로 위의 문제를 다시 작성해본 코드이다. 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950/** * 유저 현금성 포인트를 로딩한다. */const loadPoint = function* (&#123; userId &#125;) &#123; try &#123; const followers = yield call(Point.load, userId); yield put(&#123; type: &#x27;END_USER_POINT_LOADING&#x27;, payload: user &#125;) &#125; catch(error) &#123; yield put(&#123; type: &#x27;FAIL_USER_POINT_LOADING&#x27;, payload: error &#125;) &#125;)&#125;/** * 특정 유저의 팔로워를 로딩한다. */const loadFollowers = function* (&#123; userId &#125;) &#123; try &#123; const followers = yield call(Users.loadFollowersFrom, userId); yield put(&#123; type: &#x27;END_FOLLOWER_LOADING&#x27;, payload: user &#125;) &#125; catch(error) &#123; yield put(&#123; type: &#x27;FAIL_FOLLOWER_LOADING&#x27;, payload: error &#125;) &#125;)&#125;/** * 유저 정보를 로딩한다. */const loadUser = function* (&#123; userId &#125;) &#123; try &#123; const user = yield call(Users.loadUser, userId) yield put((&#123; type: &#x27;END_USER_LOADING&#x27;, payload: user &#125;) &#125; catch(error) &#123; yield put((&#123; type: &#x27;FAIL_USER_LOADING&#x27;, payload: error &#125;) &#125;&#125;/** * 각 워커의 시작점을 관리 */const watcher = function* () &#123; yield takeEvery(&#x27;START_USER_LOADING&#x27;, loadUser); yield takeEvery(&#x27;END_USER_LOADING&#x27;, loadFollowers); yield takeEvery(&#x27;END_USER_LOADING&#x27;, loadPoint);&#125;saga.runSaga(watcher) Generator를 모르는 사람은 문법에 어지러울지 모르겠다. Generator가 중요한 부분이 아니니 실행 흐름에 거쳐가는 키워드로 보자. Saga 는 액션을 구독하는 Watcher 와 실제 작업을 수행하는 Worker 의 구성을 따른다 Watcher watcher 함수 Worker loadUser loadFollowers loadPoint 먼저 액션을 처리할 워커 함수를 전부 정의한다. loadUser, loadFollowers, loadPoint 셋이 있다. 그리고 매니저가 될 와쳐 함수를 정의하고 그 함수에서 실행을 정의하면 끝이다. 이후에 좀 더 설명하겠지만 takeXXX 류의 함수는 특정 액션(들) 을 감시하는 함수이고, put 은 실제 액션을 dispatch 하는 함수이다. Redux 의 Dispatch 함수와 동일하다. (이것들을 Saga 에서는 Saga-Effect 라고 부른다. 이후에 설명한다.) 위 예제에서는 loadUser 는 START_USER_LOADING 가 디스패치될 경우 매번 loadUser 를 실행하게 되어 있다. 그 아래 두개의 함수도 마찬가지로 END_USER_LOADING 가 디스패치 될 경우 각각의 두번째 인자의 함수를 실행한다. 코드량이 약간 줄은 것 외에는 더 복잡해졌다고 생각할 수 있다. 하지만 각 함수들이 자신만의 일에 집중하는 구조로 바뀌었으며 실행 시점을 알기 편해졌다. 자신 외에 별도 부수효과에 신경쓸 필요가 없다. 만일 여기서 팔로워나 포인트를 유저 정보 로딩 후가 아닌 다른 타이밍에 호출하려는걸 추가한다면 다음과 같이 하면 된다. 실제 loadXXX 류의 작업 함수는 건드릴 필요가 없다. 다음과 같이 watcher 함수에 watching 할 액션만 추가로 넣어주면 된다. 1234567891011121314const watcher = function* () &#123; yield takeEvery(&#x27;START_USER_LOADING&#x27;, loadUser); yield takeEvery([ &#x27;END_USER_LOADING&#x27;, &#x27;START_FOLLOWER_LOADING&#x27;, // 추가 ], loadFollowersFrom); yield takeEvery([ &#x27;END_USER_LOADING&#x27;, &#x27;START_POINT_LOADING&#x27;, // 추가 ], loadPointFrom);&#125; 각 액션에 대해 로깅을 추가한다고 하면 다음 구문만 추가하면 된다. 12345yield takeEvery([ &#x27;END_USER_LOADING&#x27;, &#x27;END_USER_POINT_LOADING&#x27;, &#x27;END_FOLLOWER_LOADING&#x27;, ], writeUserActionLogging); 이렇게 액션의 감시와 해당 부수효과들을 아예 분리해서 각자의 일만 하게 두었다. 이런 방식으로는 각 액션별로 서로 영향을 주는 표현을 액션만으로 쉽게 나타낼 수 있게 된다. 실제 디스패치 하는 측에서도 비동기의 성공 여부를 고민할 것 없이 동기적 디스패치를 쓰는 것만으로 충분하다. 실제 작업은 Saga 내부적으로 처리되며 디스패치 된다. Saga-EffectSaga 는 이러한 부수효과를 처리하는 이펙트들을 지원한다. 앞의 코드에서는 put 과 takeEvery 가 나왔었다. 공식 문서의 Effect 들 https://redux-saga.js.org/docs/api/#effect-creators 모든 effect 들은 반드시 yield keyword 와 함께 사용해야 한다 taketake 는 특정 액션을 감시하는 용도로 쓰인다. 다음 코드는 REQUEST_ORDER 액션이 디스패치될 때까지 기다린 후 Api.requestOrder 를 호출하는 예제이다. 12345function* watchOrderRequest() &#123; const action = yield take(&#x27;REQUEST_ORDER&#x27;); const result = yield call(Api.requestOrder, action.orderId); // ... process ...&#125; 블럭된다는 성질을 이용해서 다음과 같이 매번 액션에 대해 반응하는 saga 를 만들 수 있다 123456789function* watchOrderRequest() &#123; // 무한 루프 while(true) &#123; const action = yield take(&#x27;REQUEST_ORDER&#x27;); // 하지만 이 라인에서 블럭된다. const result = yield call(Api.requestOrder, action.orderId); // ... process ... &#125;&#125; 이런 saga 를 만들일이 많으므로 공식적으로 이런 동작의 헬퍼인 takeEvery, takeLatest, takeLeading 등을 제공하고 있다 putput effect 는 단순하다. redux의 dispatch 함수와 완전히 동일하다. 이 effect 는 블럭되지 않기에 조심해야 한다. 1234567891011function* watchOrderRequest() &#123; // 무한 루프 while(true) &#123; const action = yield take(&#x27;REQUEST_ORDER&#x27;); const result = yield call(Api.requestOrder, action.orderId); // 결과를 스토어에 디스패치(put) 한다. yield put(&#123; type: &#x27;RESPONSE_ORDER&#x27;, result &#125;); &#125;&#125; fork새로운 하위 saga 태스크를 생성하는 effect 이다. fork 는 블럭되지 않으며 호출 시점에 호출자는 부모 task 가 되고 fork 된 saga 는 자식 task 가 된다. 부모 task 가 취소되면 자식 task 도 취소된다. 명시적으로 특정 자식 태스크만 취소시킬수도 있다. 아래에 예제가 있다. 1234567891011function* parentTask() &#123; const task1 = yield fork(childTask1); const task2 = yield fork(childTask2); // ... do something ... // 아직 동작중이면 취소시킨다. if(task2 &amp;&amp; task2.isRunning()) &#123; task2.cancel(); &#125;&#125; callcall 은 블럭되는 fork 라고 보면 된다. 인자로 함수나 saga task 를 받을 수 있다. 두번째부터는 실행될 함수나 사가의 인자로 들어간다. 보통 Promise 등의 실행 (보통은 Ajax Call) 에 쓰이며 Promise 가 resolve 될 때까지 블럭된다. 예제는 위에 이미 있으므로 생략한다. selectredux 의 state 에서 특정 상태를 가져올때 사용하는 effect 이다. redux-thunk 의 getState 와 비슷하지만, 인자로 셀렉터를 줄 수 있다. 블럭 effect 이다. 아래 예제는 활성 유저를 redux state 에서 찾은 뒤 그 아이디로 유저 정보를 Ajax call 하는 예제이다. 12345678910111213const activeUserSelector = state =&gt; &#123; return state.user.activeUser;&#125;; const getUserData = userId =&gt; ajax(`/user/data/$&#123;userId&#125;`); function* parentTask() &#123; const activeUser = yield select(activeUserSelector); const activeUserData = yield call(getUserData, activeUser.userId); // ... do something ...&#125;","pubDate":"Mon, 01 Apr 2019 15:00:00 GMT","guid":"https://blog.javarouka.me/2019/04/02/redux-saga-1/","category":["javascript","react","redux-saga","javascript"]},{"title":"Java HashMap 구현에 대해 (Effective java 3th - Item11)","link":"https://blog.javarouka.me/2018/11/28/java%EC%9D%98-HashMap-%EA%B5%AC%ED%98%84%EC%97%90-%EB%8C%80%ED%95%B4/","description":"Map 인터페이스Map 같은 동작을 하는 키-값의 자료구조는 연관 배열이라고 부르는 자료구조이다. 언어에 따라 Dictionary, Map, Symbol Table 등등으로 바꿔 부르기도 한다. JDK 8Map Interface(JDK9 기준) 는 단순하던 JDK 7 구현에서(기본적인 CRUD 성의 메서드 지원만 했다.) default method 가 추가된 JDK 8에서는 편의성 메서드들이 대거 추가되었다. 편의성을 위해 지정된 값에 대해 일정 연산을 수행하고 그 결과를 갱신하는 compute, computeIfAbsent, computeIfPresent, merge 요소를 엔트리로 순회가능한 forEach 값을 보고 없으면 두번째 인자를 반환하는 getOrDefault 첫번째 인자로 준 키가 없을때만 넣는 putIfAbsent 값과 키 둘이 일치해야 삭제하는 remove(key, value) 값을 교체하는 replace, replaceAll 이 중 getOrDefault 는 특정 경우에 따라 computeIfAbsent 와 대체해서 코드 량을 더욱 줄일 수 있다. 다음과 같은 코드를 보자. 키가 문자열이고 리스트가 값인 맵에서 특정 문자열 키의 값이 없다면 해당 값을 기본값을 리스트에 넣고 리스트를 값으로 put 하는 코드이다. 123456Map&lt;String, List&lt;String&gt;&gt; strListMap = new HashMap&lt;&gt;();// 기본값 넣기List&lt;String&gt; list = strListMap.getOrDefault(&quot;locale&quot;, new ArrayList&lt;&gt;());list.add(&quot;ko_KR&quot;);strListMap.put(&quot;locale&quot;, list); 이 코드를 computeIfAbsent 와 람다로 한줄로 줄일 수 있다. 1234Map&lt;String, List&lt;String&gt;&gt; strListMap = new HashMap&lt;&gt;();// 기본값 넣기strListMap.computeIfAbsent(&quot;locale&quot;, key -&gt; new ArrayList&lt;&gt;()).add(&quot;ko_KR&quot;); Java 8의 람다 함수 살펴보기:성능 비교 를 참고해보자. JDK 9JDK 9 에서는 좀더 기능이 확장되어 불변 맵을 생성하는 of default 메서드가 추가되었다. 오버로딩이 꽤 많이 되어 최대 인자 20개로 10개까지의 원소를 가지는 맵을 생성할 수 있다. 구현이 너무 정직해서 놀랐다. Google Guava 에는 이미 구현되어 있던 기능이다. 그냥 Guava를 정식 라이브러리로 하면 어떨까 싶다. 1Map&lt;String, String&gt; immutableMap = Map.of(&quot;키1&quot;, &quot;값1&quot;, &quot;키2&quot;, &quot;값2&quot;); Map 의 hash 함수Java 에서는 hashCode 라는 메서드가 기본적으로 최상위 클래스인 Object 에 존재한다. 이 코드로 Map 에 사용되는 key 를 대체하면 좋겠지만, hashCode 는 int 형이기에 Map 에 저장할 수 있는 객체의 숫자는 2의 32제곱의 사이즈만으로 제한될 것이다. 그렇다고 hashCode 를 long 으로 키워도 문제고, 다른 타입으로 교체할 경우 계산에 따른 성능 문제가 발생할 수 있다. 이런걸 다 무시하고 억지로 적용한다 쳐도, Map 이 생성될때마다 2의 32제곱의 사이즈만큼의 저장소(버킷이라고 한다)를 초기화해둬야 한다. 그래서 Map 의 버킷은 타협을 일정량의 버킷만 생성하고 몇가지 전략으로 버킷 충돌을 관리한다 (Open Addressing, Separate Chaining). Java 에서 사용하는 버킷 충돌 회피는 Separate Chaining 이며, 버킷을 일종의 LinkedList 로 관리한다. 버킷내의 충돌이 발생하면 기존 key와 신규 key의 equals 호출로 다시한번 중복여부를 검사하여 값을 교체하기에 키가 될 객체 Class 의 equals 구현은 상당히 중요하다. hashCode 의 구현 규칙에서 두 객체가 다르더라도 두 객체가 서로 다른 hashCode 를 반환하지 않아도 된다 라는 건 이 때문이다. 하지만 둘다 다르게 구현하는게 Map의 성능 향상에 크게 도움이 된다. (특정 버킷에 편중되어 저장되는 현상을 회피할 수 있고, 충돌 버킷의 순회 비용이 줄어든다) 위 조건을 만족하는 hashCode 구현을 완전 해시 함수 라고도 부른다","pubDate":"Tue, 27 Nov 2018 15:00:00 GMT","guid":"https://blog.javarouka.me/2018/11/28/java%EC%9D%98-HashMap-%EA%B5%AC%ED%98%84%EC%97%90-%EB%8C%80%ED%95%B4/","category":["Effective Java","java","effective"]},{"title":"Equals 구현과 리스코프 치환 법칙 (Effective java 3th - Item10)","link":"https://blog.javarouka.me/2018/11/27/object-equals-liskov/","description":"equals 구현 규칙equals 는 정해진 법칙에 따라 다양한 객체에서 호출되고 있다. 규칙을 지키지 않은 구현으로 의존성 객체에 처리를 맡긴다면, 의도하지 않은 동작이 발생하고 디버깅을 어렵게 만든다. 규칙들은 다음과 같다. 반사성 null은 항상 false 대칭성 추이성 일관성 반사성context 와 null이 아닌 인자가 같을 경우 항상 true 가 된다. 1context.equals(context); // true 대칭성context 가 어떤 대상 some 과 같다면 그 역방향도 true 가 된다. 12context.equals(some); // truesome.equals(context); // true 상속관계가 아닌 타입이 다른 객체에서 객체의 equals 비교로 true를 반환하는 구현은 거의 99.99% 대칭성 위반에 걸린다. 추이성말이 어려운데, A와 B가 같고 B와 C가 같다면 A와 C는 같아야 한다는 어디선가 본 논리적 법칙이다. 123context.equals(some); // truesome.equals(another); // truecontext.equals(another); // true 이 구현에서 주의할 것은 상속관계가 얽힐 때다. 특정 클래스를 확장하여 새로운 필드등을 추가한 클래스는 추이성을 만족시킬 수 없다. 특정 클래스를 특정지어 비교하는 방법으로 구현된 equals 의 경우 언뜻 조건 만족을 하는 것 같지만 리스코프 치환 법칙을 위배하기에 쓸 수가 없다. 이 경우에는 컴포지션 을 통해 문제를 해결할 수 있다. 리스코프 치환 법칙서브타입은 언제나 자신의 상위 타입으로서의 기능을 해야 한다. 만일 상위 클래스가 직사각형이고, 하위 클래스를 정사각형이라고 해보자 12345678910111213141516171819202122232425262728293031323334@Getterclass Rectangle &#123; private int height; private int width; public Rectangle(int height, int width) &#123; this.height = height; this.width = width; &#125; public void setSize(int height, int width) &#123; this.height = height; this.width = width; &#125;&#125;@Getterclass Square extends Rectangle &#123; public Square(int height, int width) &#123; super(height, width); if(height != width) &#123; throw new AssertionException(&#x27;cannot create!&#x27;); &#125; &#125; public void setSize(int height, int width) &#123; if(height != width) &#123; throw new AssertionException(&#x27;cannot create!&#x27;); &#125; this.super(height, width); &#125;&#125; 직사각형(Rectangle) 은 마음대로 크기 조절이 가능하지만 정사각형(Square) 은 크기 조절에 제약이 있다. 일견 문제가 없어 보이지만 문제는 정사각형이 직사각형의 문맥에서 사용될 때다. 1234// 직사각형 문맥 로직 수행public void changeWideSize(Rectangle rec) &#123; dim.setSize(dim.getHeight(), dim.getWidth() * 2); // throw Exception.&#125; 사용자 측에서는 직사각형이라고 생각하고 인자를 처리하고 있다. 하지만 불행히도 객체지향의 인자는 반공변적(contravariant)이다. 이 뜻은 인자는 실제 객체의 하위타입이 올 수 있다는 뜻이다. 예제에서는 직사각형(Rectangle) 뿐 아니라 정사각형(Square) 도 올 수 있다는 뜻이다. 그리고 어떤 객체가 오느냐에 따라 코드의 동작은 변한다. 이럴 경우 리스코프 치환 법칙이 깨졌다고 설명할 수 있다. 정사각형 객체의 가로세로의 크기가 달라져 버렸다. 일관성몇번을 호출해도 어떤 상황에서 호출해도 두 대상 객체의 내용이 같다면 결과는 항상 같아야 한다. equals 는 언제나 해당 객체를 대상으로 동치성을 비교해야 하는데, 다른 조건을 참고해가며 비교하게 되면 이 조건이 깨지기 쉽다. 1234567891011context.equals(some); // trueint i = 10;while(i &gt; 0) &#123; i--; try &#123; Thread.sleep(1000) &#125; catch(Exception ignore) &#123;&#125; context.equals(some); // true&#125;","pubDate":"Mon, 26 Nov 2018 15:00:00 GMT","guid":"https://blog.javarouka.me/2018/11/27/object-equals-liskov/","category":["Effective Java","java","effective"]},{"title":"객체 소멸자의 슬픈 디자인 (Effective java 3th - Item8, 9)","link":"https://blog.javarouka.me/2018/11/26/Finalizer%EC%99%80-Cleaner/","description":"Finalizer1234@Overridepublic void finalize() &#123; // ...&#125; finalize 메서드를 Override 하면 해당 객체가 JVM 에게 Garbage Collection 을 해야 할 대상이 될 때 호출된다. 객체가 없어지기 전 다른 연관 자원을 정리하려는 의도로 작성된다. 하지만 이 메서드는 사용해서는 안되며 실제로 java9+ 부터 Deprecated 되어버렸다. 오류/시점/성능/수행성 뭐 하나 보장하지 못하며 때로는 영원히 수행되지 않거나 불행하게도 Lock 이 걸려 프로그램 전체가 블럭될 수도 있다. java9 에서는 대안으로 Cleaner 를 지원하게 되었다 CleanerJava9 에서 도입된 소멸자로 생성된 Cleaner 가 더 이상 사용되지 않을 때 등록된 스레드에서 정의된 클린 작업을 수행한다. 혹은 명시적으로 clean 을 수행할수도 있다. 보통 AutoCloseable을 구현해서 try-with-resource 와 같이 사용한다. (이 편이 추천된다) 123456789101112131415161718192021222324252627public class CleaningRequiredObject implements AutoCloseable &#123; private static final Cleaner cleaner = Cleaner.create​(); private static class CleanData implements Runnable &#123; @Override public void run() &#123; // 여기서 클린 작업 수행 &#125; &#125; private final CleanData; private final Cleaner.Cleanable cleanable public CleaningRequiredObject() &#123; this.cleanData = new CleanData(); // 등록 this.cleanable = cleaner.register(this, state); &#125; @Override public void close() &#123; cleanable.clean(); &#125;&#125; 자칫 Clean 작업을 실제로 수행할 클래스의 디자인에 실패해서 다른 외부 참조나 의존성이 걸릴 경우, 최악의 경우 순환의존성 덕분에 GC의 기회가 없어질 수도 있다. 이를 피하기 위해 보통은 AutoCloseable - try-with-resource 로 안전장치를 거는 편이 좋다. try-with-resourceI/O 등의 작업에서는 어떤 모듈이 사용이 종료될 경우 해당 자원을 해지하고 없애야 할때가 많다. 보통 그럴 경우 try-finally 구문으로 처리하는데 이 경우 코드가 상당히 지저분하다. 또한 작업 메서드가 오류가 나더라도 close 를 해야 할 경우와 close 자체에서도 오류를 던지는 경우가 있어 그 두 부분을 전부 try-catch 하다보면 코드 가독성은 현저하게 저하된다. try-with-resource 로 이런 고충을 한방에 날려버릴 수 있다. 다음 Worker 클래스는 테스트를 위해 명시적으로 오류를 내고 있다. 이 경우에 try-with-resource 를 사용하면 아주 깔끔한 코드가 나오며, 오류또한 잘 캡처된다. 12345678910111213141516171819202122public class Boss &#123; public static class Worker implements AutoCloseable &#123; public String work() &#123; throw new RuntimeException(&quot;work Exception!&quot;); &#125; @Override public void close() &#123; throw new RuntimeException(&quot;close Exception!&quot;); &#125; &#125; public static void main(String...args) &#123; // 짧다! try(Worker worker = new Worker()) &#123; worker.work(); &#125; &#125;&#125; 출력 오류는 다음과 같다 123456Exception in thread &quot;main&quot; java.lang.RuntimeException: work Exception! at Boss$Worker.work(Boss.java:6) at Boss.main(Boss.java:16) Suppressed: java.lang.RuntimeException: close Exception! at Boss$Worker.close(Boss.java:10) at Boss.main(Boss.java:18) Cleaner / Finalizer 둘다 애매하다.하지만 둘다 일반적으로는 사용이 불필요하다. 둘다 성능에 문제가 많고, Serialize 를 통한 보안 이슈가 존재하며, 수행 시점이 보장되지 않는다. JVM 구현에 따라 동작도 매우 달라질 여지가 많다. 사용할수밖에 없을때는 다음과 같은 케이스가 있다 JNI Off-Heap 메모리 사용시 (DirectBuffer 류 사용시) 읽을만한 글 Java’s Finalizer Is Still There Java Reference와 GC Java Garbage Collection - Understanding Phantom Reference with examples","pubDate":"Sun, 25 Nov 2018 15:00:00 GMT","guid":"https://blog.javarouka.me/2018/11/26/Finalizer%EC%99%80-Cleaner/","category":["Effective Java","java","effective","try-with-resource"]},{"title":"String과 Boxing, 그리고 객체생성 (Effective java 3th - Item6)","link":"https://blog.javarouka.me/2018/11/25/%EB%B6%88%ED%95%84%EC%9A%94%ED%95%9C-%EA%B0%9D%EC%B2%B4%EC%83%9D%EC%84%B1-%ED%9A%8C%ED%94%BC/","description":"객체 재활용불변 객체이고, 재활용이 자주 되는 객체는 매번 생성해서 좋을게 없다. 미리 만들어두고 참조만 지정하면서 재사용하는게 유리하다. Java 내부 구현에서도 String 이 이런 패턴을 따른다. 1String hello = &quot;world&quot;; 나중에 다시 “world” 문자열이 필요해서 다음과 같이 선언해도 같은 객체를 사용함이 보장된다. 1234while(!isEnd()) &#123; String world = &quot;world&quot;; // 계속 같은 인스턴스 참조 // ...&#125; 이렇게 동작하는 이유는 Java에서 쓰이는 모든 String 객체는 상수풀에서 관리되며 프로그램 종료때까지 유지되기 때문이다. 강제로 상수풀의 문자열을 사용하게 하는 메서드로 intern 이 있다. intern 된 문자열은 상수 풀에서 사용되기에 true 를 반환한다. 123String hello = &quot;world&quot;;hello == new String(&quot;world&quot;); // falsehello == new String(&quot;world&quot;).intern(); // true Auto-Boxing / Auto-UnBoxingPrimitive 타입의 박싱에서 주의해야 할게 잘못 코딩할 경우 원치않는 객체 생성이 일어난다. 비슷하게 쓸 수 있다고 해서 루프문이나 과도한 계산에 박싱타입과 Primitive 타입을 섞어 쓸 경우에는 끔찍한 성능 이슈를 겪을수도 있다. 123long first = 3L;long second = 2L;Long value = first + second; // 객체 생성.","pubDate":"Sat, 24 Nov 2018 15:00:00 GMT","guid":"https://blog.javarouka.me/2018/11/25/%EB%B6%88%ED%95%84%EC%9A%94%ED%95%9C-%EA%B0%9D%EC%B2%B4%EC%83%9D%EC%84%B1-%ED%9A%8C%ED%94%BC/","category":["Effective Java","java","effective"]},{"title":"신규 통합 CS 시스템 관리 개발기 # 혼란편","link":"https://blog.javarouka.me/2018/11/23/new_project_2/","description":"신규 통합 CS 시스템 관리 개발기 # 설계편 # 신규 통합 CS 시스템 관리 개발기 # 혼란편 # 생각 이상으로 많이 생기는 Behavior, DTO 문제단순 조회라도 Controller -&gt; Service -&gt; Behavior -&gt; Repository 로 이어진다. 그리고 그 레이어간의 통신시마다 각자의 레이어들이 요구하는 DTO 를 만들다보면, 필드 값들이 매우 유사한 많은 Class 가 정의된다. 특히 단순 아이디 조회건의 경우에는 형식적인 각 레이어 관련 class 들이 생성되고 그에 대응하는 동일 필드의 DTO 들이 정의되며, 그를 위한 변환 로직이 들어간다. 많다... 각 도메인의 지식이 명확하고 이해도가 깊다면, 모든 Layer 에서 참고할 수 있는 Top-Level 레이어 수준으로 Entity (JPA Entity 말고) 를 만들어볼 수 있겠지만, 현실은 쉽지 않았다. 전사 도메인이 그렇게 일관된 통일성이 있는게 아니라 A 비즈니스 팀 에서 해야할 일을 B 비즈니스 팀에서 하는 일도 있고 자주 바뀌기에 이것에 대응하려는 설계는 참으로 어려웠다. 하지만 정석은 언제나 통한다고 생각한다. 많은 시간을 들여 분석해가며 설계하면 이런 점까지 커버할 수 있는 시스템을 만들 수 있다. 하지만 이번에는 일단 초기에 만든 규칙대로 다수의 파일 생성도 감안하며 가는 방식을 선택했다. 후에 리팩토링을 통해서라도 개선하고 싶다. API 분할과 정의 문제전 글 에서 언급한 데이터 토막치기 로 간단히 데이터를 합쳐서 한방에 내려주는 방식이 아닌 각각의 논리적 단위로 데이터를 가져오는 방식으로 변하면서, 서버 API 설계가 상당히 중요해졌다. API 를 전체적으로 알지 못하면 같은 데이터가 필요할 때 비슷한 기능의 API 가 생성될 수도 있고, 적절한 관리가 안될 경우 나중엔 비슷비슷한 응답의 endpoint 만 조금씩 다른 API가 많아질 수 있다. 이번에 작업한 내용은 주문정보 라는 컨텐츠 하나였지만 그 안에서도 서로 비슷한 필드 몇개만이 다른 endpoint API 가 몇개 정도 존재하게 되었고 그대로 product 배포 상태이다. 이 점은 문서화와 관련이 깊다고 생각한다. 나중에 문서화를 위해 다급히 swagger 를 붙이고 주석 annotation 을 코딩했지만 만족스럽진 않다. 문서 정리는 언제나 귀찮다 개발단계에서 보다 쉽게 API 를 파악할 방법이 있다면 좋겠는데. Client 에서의 요청 증가 문제역시 데이터 토막치기 로 인해 기존에 한방에서 여러 요청으로 나뉘면서 Http Request 의 숫자가 늘어났다. 데이터 각자가 자신이 필요한 데이터만 응답하기에 경량화된건 사실이다. 하지만 화면에서는 여전히 여러 데이터가 필요하고 그 데이터를 구하려면 필요한 수 만큼의 API 요청을 해야 한다. 복잡한 도메인이 포함된 비즈니스로 구성되는 컨테이너의 경우 많은 요청으로 인해 느릴 수밖에 없고 네트워크의 Latency 가 나쁜 상황에서는 몇배로 느려진다. 이 때문에 논리적인 데이터 토막을 잘 정의하는게 매우 중요하다. 데이터를 과하게 합쳐 응답할 경우 특정 UI 나 비즈니스만을 위한 API 가 되고, 과도하게 나눠 응답할 경우 Client 로직이 복잡해지고 Http request 가 증가한다. 이에 대해서는 확실한 기준을 세우지 못했다. 대략적으로 만든 아래와 같은 기준이 있을 뿐이다. 반복적으로 조회되며 변경율이 낮은 상수 데이터는 앱 초기에 로딩하여 store 에 저장한다 키 조회 API 는 분리한다 (상품, 주문, 취소, 반품 …) 정책 API 는 분리한다 (취소가능, 배송지 변경가능, 접수 수정가능 …) 복수의 데이터의 조합으로 결정되는 데이터는 합친다 (회원 특별등급, 3P,Retail 배송상태 …) 데이터의 변경/생성/삭제 에 대해서는 최소한의 파라미터로 한번의 트랜잭션으로 처리한다 Client 로직에서의 Container 단위 정의 문제데이터를 분할해서 받았으니 역시 분할된 데이터를 조립해야 한다. 그 영역은 Container 라 부르는 Redux Store 에 connect 되는 영역에서 처리하기로 했다. 각 Ducks 를 확장한 ReDucks 에서 selector entity 들의 데이터를 잘 조합하는 Container 용 selector 를 만든다. (selector 는 메모이징을 지원하도록 reselect 를 사용했다) Container 는 특정 목적의 비즈니스의 집합이라 UI 와 강하게 결합되기에 그냥 한파일에 selector 를 넣었다. 이렇다보니 Container 를 잘못 정의할 경우 엄청난 크기의 selector 가 만들어진다. 그렇다고 모든 UI Component 들을 Container 화 할 경우 모든 UI 에 entitiy selector 가 달리게 되고, 데이터 구조 변경에 강한 영향을 받게 된다. 현재는 데이터의 응집력(나름대로의…) 단위로 나눠두긴 했는데, 이것도 불명확하긴 매한가지. 참고할 만한 기준따위 있을리도 없고, 결국에는 실전 운영으로 타협점을 찾아가는게 좋을 듯 하다. Webpack Code Splitting 문제asset(js, css, images…)들의 로딩은 단일 서버 운영에서는 문제가 일어나지 않는다. 하지만 복수의 서버로 운영되는 환경에서 운영되는 배포 프로세스중에는 Canary Release 라는 방식이 있다. Canary Release 는 새로운 버전의 소프트웨어를 운영 환경에 배포할 때, 전체 사용자들이 사용하도록 모든 인프라에 배포하기 전에 소규모의 사용자들에게만 먼저 배포함으로써 리스크를 줄이는 기법이다. - 너굴너굴 블로그 이 환경에서는 일정 기간동안은 asset 의 버전이 다른 미배포 서버와 canary 서버가 다를 수 있는데 canary 서버의 변경이 있는 상태에서 변경되지 않은 미배포 서버의 asset 을 로딩할 경우 asset 버전 불일치로 인한 장애가 발생할 수 있다. 꼭 canary 방식이 아니더라도 순차적으로 N대씩 배포되는 환경에서는 문제가 발생한다. Webpack 에서는 기본 전략으로 asset 파일들을 hash 문자열로 변환하여 배포시마다 파일이름이 [hash].[ext] 형식으로 번들되어 배포되는데, 문제는 canary 서버가 배포된 뒤 이 서버에서 asset 을 미배포 서버에 요청하게 되는 일이다. 당연히 해당 asset 은 없어서 404 error 가 발생한다. 파일 이름을 강제로 고정 이름 (예를 들면 534fsdnfg23543gf.js 가 아닌 main.js) 으로 정해도 되지만, 이 경우 client cache 를 피하기 어렵다. 운 좋게 canary 서버가 요청한 asset 을 canary 가 받았다 하더라도, Chunck 등의 Code Splitting 이나 Lazy Loading 등을 적용해뒀다면 Chunk Loading Error 도 보게 된다. 처음에는 장애 포인트를 알 수 없어서 Canary Release 를 건너뛰고 항상 Deploy All 을 했었다. 해결책은 S3빌드번호를 webpack 번들링 타이밍에 인자로 넘겨 output 설정에 Public Path를 만드는 방법이었다. Public Path 가 고정되니 배포 Scope 으로 asset 을 요청하게 되고 자신의 배포버전에 맞는 asset 을 서버에서 로딩하도록 유도할 수 있었다. 이부분에서 꽤나 많은 시행착오가 있었던걸로 기억한다. 익숙하지 않은 도구들 문제styled-component 스타일 도구로 styled-component 를 사용했는데, 기존의 css 와 className 개념과는 아주 달랐다. Component 에서 Style 의 요소를 Component 로 분리하는 생각이 생각대로 잘 되지 않았다. 별도 파일로 분리해야 하는 것인가, 기존 css 처럼 하나의 파일에 전부 모아두고 selection import 하는 방식인 것인가부터, 어느 레벨로 그룹해야 하는지도 혼란스러웠다. 문법적으로도 3.x 버전과 4.x 버전의 과도기에 사용해서 라이브러리의 구조가 변했고, 대응하느라 리소스의 낭비도 있었다. 사용하면서 내린 나름의 결론은 이렇다. 각 컴포넌트는 가급적 React.Fragment 로 래핑한다 부모 레벨이 자식 컴포넌트의 스타일을 지정할 수 있게 한다. StyleComponent 로 자식을 감싸서 사용한다는 뜻이다 StyleComponent 든 DataComponent 든 네이밍과 파일 단위는 동일하게 한다. 사용 측에서는 이 컴포넌트가 Style 인지 Data 인지 알 필요가 없다. 현재 (2018.11.23) 운영 배포된 소스는 위의 룰을 지키지 못했다. 천천히 수정해야 할 일이다. Redux-Saga Redux-Saga 의 사용에 미숙하여 여러 착오를 겪었다. 제일 심하게 겪은 문제는 take 관련인데 Ajax 등의 비동기 Side-Effect 를 동반하는 Task 일 경우 같은 요청이 다수가 중복된다면 첫번째만 처리하는 것이 보통 효율이 좋다. 이런 경우는 대부분 사용자의 반복된 클릭등으로 요청되는게 대부분이기 때문이다. Saga 에서는 Helper 함수로 takeLatest, takeEvery, takeLeading 등을 지원한다 takeEvery 매번 요청건 처리 takeLatest 제일 마지막 건만 처리 takeLeading 제일 첫번째 건만 처리 개발 초기에는 대부분의 Saga Watcher 에 takeLeading (1.x) 을 걸어두었다. 중복 요청일 경우 두번째는 무시하기 위해서이다. 하지만 나중에 테스트와 액션 리포트를 보면 사용자의 반복 요청에 막히는 것은 거의 없고 오히려 특정 사이드이펙트 action watcher (트리거 action이 여러개 존재하는 watcher) 가 서로 다른 action dispatch 에 영향받게 되면서 나중 요청을 전부 씹는 상황이 발생했다 예를 들면 주문 상세를 트리거하는 ORDER_DETAIL 액션으로 주문 A 를 trigger 했다가 바로 B 를 trigger 하면 주문 A 의 정보를 로딩하는 watcher 들이 takeLeading 방식이라 나중에 들어온 B 정보 action 을 dispatch 하지 않고 주문 A 관련만을 처리하게 되는 것이다. take 디자인에도 생각없이 하면 안된다는 걸 깨닫고 액션과 UI 의 관계에 따라 다른 take 전략을 사용해야 한다는 걸 깨달았다. 잘 모르겠으면 take helper 들을 안쓰는 것도 좋은 방법인것 같다. fork 된 액션은 부모의 try-catch 에 영향이 없다라든지 call 과 fork Blocking 차이라든지 하는 Redux-Saga 이해도가 부족한 것에서 오는 어려움도 있었지만 이런건 Document 를 잘 봤으면 해결될 문제라… 결론CS 상담 시스템 개편이 현재 시간 기준 한창 테스트중이다. 여러모로 아쉬운 점이 많은 프로젝트였다. 여기엔 적지 않았지만 잘못된 시간분배나 플래닝, 계획들도 큰 장애거리였다. 테스트 결과와는 관계없이 기록을 남겨 나중에 기술 선택에 좀더 도움이 되길 바랄 뿐이다.","pubDate":"Thu, 22 Nov 2018 15:00:00 GMT","guid":"https://blog.javarouka.me/2018/11/23/new_project_2/","category":["Tech","java","javascript","scaffolding","legacy","new-cs-system"]},{"title":"Dependency Inject & Dispatch (Effective java 3th - Item5)","link":"https://blog.javarouka.me/2018/11/21/dependency-inject/","description":"개요java 객체지향은 많은 모듈들의 의존성으로 이뤄진다. 다만 의존성을 코드상에 명시할 경우 그 의존성이 클라이언트 코드에 강하게 결합되게 된다. 다음과 같은 싱글턴 클래스가 있다. 만화 드래곤 볼에 나오는 드래곤 레이더이다. 1234567public class DragonBallRadar &#123; private static final HeightMap heightMap = new EarthMap(); private DragonBallRadar() &#123;&#125; public static Coordinate detect() &#123; /* 구현 */ &#125;&#125; 이 드래곤 레이더는 지구에서는 아주 잘 동작할 것이다. 지구에 대한 데이터가 미리 주어지기 때문에 지구에 대해 드래곤 볼의 위치를 잘 표시할 수 있다. 하지만 작중에서 피콜로가 죽고 나메크별로 무대가 옮겨지는 때가 있다. 안타깝지만 부르마와 Z 전사들은 이 드래곤 레이더로 나메크성의 드래곤볼을 찾을 수 없게 될것이다. 이 레이더는 지구맵만 지원하고 있기 때문이다. 높이맵 (HeightMap) 을 바꾸기 위해 setHeightMap 를 추가할수도 있지만, 싱글톤 객체에 setter 를 추가하는건 멀티환경에서는 오류를 내기 쉽다.다수의 스레드의 접근 상태에서 setter 를 호출할 경우 의도하지 않은 오류가 발생할 수 있고 문법적으로 매우 어색하다. 정적 클래스의 메서드는 같은 상태일 때 A 를 호출하면 B 를 받는 순수 함수의 형태가 되어야 옳다. 상태를 가지는 것도 물론 어색하다. 사용하는 자원에 따라 동작이 달라지는 클래스에는 정적 유틸리티 클래스나 싱글턴 방식이 적합하지 않다-Effective Java 3th 29 page 이 경우에는 정적 메소드는 지양해야 하며, 사용자 측에서 높이맵을 바꿔줄 수 있어야 한다. 123456789public class DragonBallRadar &#123; private final HeightMap heightMap; private DragonBallRadar(Supplier&lt;HeightMap&gt; supplier) &#123; this.heightMap = supplier.get(); &#125; public static Coordinate detect() &#123; /* 구현 */ &#125;&#125; Spring Framework 를 사용하면서 자연스럽게 쓰고 있을 규칙이지만, 간혹 static 과 의존성을 섞어 쓰는 사례가 있는데 조심해야 한다. 의존성이 추가되기 전에도 정적 메서드는 호출할 수 있으며, Spring Application Context 가 완전히 초기화되기 전에 정적 메서드가 호출된다면 문제가 생길 것이다. 간단한 변경으로 나메크별의 높이맵 생성 팩토리를 만들어 주입한 결과 이제 프리저보다 먼저 드래곤볼을 찾을 수 있게 됨은 물론, 나중에 지구에서도 사용할 수 있는 만능 레이더가 되었다.","pubDate":"Tue, 20 Nov 2018 15:00:00 GMT","guid":"https://blog.javarouka.me/2018/11/21/dependency-inject/","category":["Effective Java","java","effective","di","double dispatch"]},{"title":"LazyHolder 기법 (Effective java 3th - Item4)","link":"https://blog.javarouka.me/2018/11/20/no-instance/","description":"개요Java 에서의 생성자는 접근제어로 통제할 수 있기에 객체 생성에 생성자를 쓰고 싶지 않다면, private 접근제어를 줘서 막자. 위 그림의 예제처럼, 상속을 방어하는 효과도 있다. 클래스 A 는 B의 생성자를 체이닝하려 하지만 접근이 막혀 컴파일 오류를 발생시킨다. LazyHolder 기법책에는 소개되지 않지만 싱글턴 기법으로 LazyHolder 라는 방법이 있다. 책에서는 Enum 방식을 안전하다고 제안하고 있지만 Android 같이 Context 의존성이 있는 환경일 경우, Singleton의 초기화 과정에 Context라는 의존성이 끼어들 가능성이 있다. LazyHolder 는 그에 대한 대안으로 나온 방법이다. JVM에게 객체의 초기화를 떠님기는 방식으로, 멀티스레드 환경에서도 객체의 단일성을 보장할 수 있다. 123456789101112public class OnlyOne &#123; private OnlyOne() &#123;&#125; public static OnlyOne getInstance() &#123; return LazyHolder.IT; &#125; private static class LazyHolder &#123; private static final OnlyOne IT = new OnlyOne(); &#125;&#125; 객체 생성을 담당할 내부클래스를 하나 정의하는데, 이것이 LazyHolder 다.OnlyOne 클래스는 초기에는 아무런 상태가 없기에 LazyHolder 클래스를 초기화하지 않지만, getInstance 메서드가 호출될 때 LazyHolder 가 로딩되며 초기화가 진행된다. 클래스의 내부의 클래스는 외부의 클래스가 초기화될때 초기화되지 않고, 클래스의 static 변수는 클래스를 로딩할 때 초기화되는 것을 이용한 기법이다. Class 를 로딩하고 초기화하는건 JVM 의 영역이고 Thread Safe 를 보장한다.","pubDate":"Mon, 19 Nov 2018 15:00:00 GMT","guid":"https://blog.javarouka.me/2018/11/20/no-instance/","category":["Effective Java","java","effective","singleton","lazyholder"]},{"title":"Java 의 Serialize (Effective java 3th - Item3)","link":"https://blog.javarouka.me/2018/11/19/serialize-java/","description":"Serialize?JVM 메모리 - Heap or Stack - 에 있는 객체 데이터를 바이트 형태로 변환하는 기술. 이 역방향 변환을 Deserialize 라고 한다. Java 에서의 Primitive Data Types은 별도의 처리 없이도 Serialize 가 가능하다. 다만 Object 형식의 객체는 java.io.Serializable 을 구현해야 Serialize 대상이 된다. 12345678910111213import java.io.Serializable;/** * Serializable 를 구현해서 Serialize 가능하게 한다. */public class Sleep implements Serializable &#123; private int duration; public Sleep(int duration) &#123; this.duration = duration; &#125;&#125; Serialize 에는 java.io.ObjectOutputStream 을 사용한다 123456789101112131415Sleep sleep = new Sleep(1000);try ( ByteArrayOutputStream arraySerializer = new ByteArrayOutputStream(); ObjectOutputStream objectSerializer = new ObjectOutputStream(arraySerializer);) &#123; // 실제 Serialize 수행 objectSerializer.writeObject(sleep); // 배열로 저장 persistSerialized(arraySerializer.toByteArray());&#125; catch(IOException serializeFailed) &#123; handleSerializeFail(serializeFailed);&#125; serialVersionUIDSerialize/Deserialize 간에 Serialize 대상의 고유 번호 표시이다. Serialize 인터페이스를 상속한 클래스는 가급적 이 번호도 추가하는게 좋다. serialVersionUID는 명시적인 선언 없이도 자동으로 생성되나 없을 경우 특정 알고리즘을 사용 하여 클래스의 해시값으로 지정된다. Serialize 는 상당히 까다롭게 동작한다. 클래스가 같더라도 Serialize/Deserialize 시에 serialVersionUID 값이 다르다면 InvalidClassException 이 던져진다 자동 생성된 serialVersionUID 는 클래스의 해시값이기에 클래스 구조에 변화가 생기면 다를 수밖에 없다. 또한, 명시적인 선언이 있어도 데이터 타입이 변경될 경우 오류가 발생한다. 이 경우에는 InvalidClassException 이 던져진다. Pre-Process MethodsSerialize/Deserialize 중 Singleton 등의 인스턴스 제한, 알수없는 데이터에 대한 Deserialize 검증 등의 특수한 처리가 필요할 경우가 종종 있다. 이럴 경우에 대해 Serialize 전처리 메서드들이 준비되어 있다 12345void writeObject(java.io.ObjectOutputStream out) throws IOExceptionvoid readObject(java.io.ObjectInputStream in) throws IOException, ClassNotFoundException;void readObjectNoData() throws ObjectStreamException;Object writeReplace() throws ObjectStreamException;Object readResolve() throws ObjectStreamException; writeObject/readObject해당 class 에 위의 전처리 메서드를 구현할 경우 Serialize/Deserialize 시에 호출된다. 보통은 해당 클래스의 상태에 전처리를 할때 사용한다. 특정 데이터를 writeObject 시에 추가한뒤 readObject 시에 다시 읽거나, 외부 시스템으로부터 받은 수상한 데이터에 대한 방어 목적으로도 사용할 수 있다. 객체에 특정 서명을 추가하거나 해서 어느정도의 보안도 적용 가능해진다. 만일 이 메서드에서 NotSerializableException 을 던지게 되면 Serialize 가 불가능하게 된다 123456789101112131415161718192021222324/** * place 필드는 transient 로 실제 직렬화 대상이 아니지만 * writeObject/readObject 구현으로 추가로 직렬화에 포함시켰다. */public class Sleep implements Serializable &#123; private int duration; private transient String place; public Sleep(int duration, String place) &#123; this.duration = duration; this.place = place; &#125; private void writeObject(ObjectOutputStream out) throws IOException &#123; out.defaultWriteObject(); // static, transient 필드를 제외하고 현재 객체에서 데이터를 읽는다. out.writeObject(this.place); &#125; private void readObject(ObjectInputStream in) throws IOException, ClassNotFoundException &#123; in.defaultReadObject(); // static, transient 필드를 제외하고 현재 객체로 데이터를 읽는다. this.place = (String) in.readObject(); &#125;&#125; readObjectNoDatahttps://stackoverflow.com/questions/7445217/java-when-to-add-readobjectnodata-during-serialization/7445415 writeReplace/readResolve이 메서드를 구현해서 원래 Serialize/Deserialize 대상 객체를 변경할 수 있다.직렬화에 대한 프록시 기능이나 인스턴스 수 제한에 유용하다. 링크 하나 공유한다. Serialization and magic methods","pubDate":"Sun, 18 Nov 2018 15:00:00 GMT","guid":"https://blog.javarouka.me/2018/11/19/serialize-java/","category":["Effective Java","java","effective","serialize"]},{"title":"빌더 패턴 (Effective java 3th - Item2)","link":"https://blog.javarouka.me/2018/11/14/builder/","description":"객체 생성시에 거슬리는 요인 많은 인자 인자의 순서를 실수할 경우가 잦아진다 기본값 옵셔널 기본값을 주고 싶지만 주기 어렵다 많은 멤버 수많은 멤버를 가진 객체의 경우 생성자가 비대해진다 기본 생성자 호출 뒤 Setter로 하나하나 세팅하는 방법도 있지만 시간의 흐름에 따라 멤버가 초기화되기에 일관성이 해쳐진다. 그리고 불변객체를 만들 수 없어 스레드, 코딩 안정성이 저하된다. 그래서 준비했습니다일반적인 빈즈의 빌더 패턴123456789101112131415161718192021222324252627282930313233343536373839public Car &#123; private final String name; private final int price; private final Color color; private Car(String name, int price, Color color) &#123; this.name = name; this.price = price; this.color = color; &#125; public static class Builder &#123; private final String name; // 필수값 private int price = 0; // 기본값 private Color color = Color.RED; // 기본값 public Builder(String name) &#123; this.name = name; &#125; public Builder price(int price) &#123; this.price = price; return this; &#125; public Builder color(Color color) &#123; this.color = color; return this; &#125; public Car build() &#123; return new Car( this.name, this.price, this.color ); &#125; &#125;&#125; 사용1234Car superMyCar = new Car.Builder(&#x27;내 애마&#x27;) .price(9999999999) .color(Color.INDIGO) .build(); Lombok!@Builder","pubDate":"Tue, 13 Nov 2018 15:00:00 GMT","guid":"https://blog.javarouka.me/2018/11/14/builder/","category":["Effective Java","java","effective","serialize"]},{"title":"객체 생성 정적 팩토리 메서드를 쓰는게 왜 유리한가 (Effective java 3th - Item1)","link":"https://blog.javarouka.me/2018/11/12/static-creator/","description":"생성자 기본지식java 에서의 보통의 객체 생성은 new 를 사용한다 1List&lt;String&gt; strList = new ArrayList&lt;&gt;(); 공개된(public) 생성자를 new 연산자와 함께 호출해서 객체를 생성한다. 이 과정에서 알아둘 생성자에 대한 몇가지 기본적인 지식이 있다 class 정의 시 생성자를 정의하지 않았다면 기본적으로 인자가 없는 생성자가 언어레벨에서 지원된다. Subclassing 된 class 라면 자식 생성자 호출 시 부모의 생성자도 연쇄적으로 호출한다. 생성자 체이닝이라고도 부른다. 어떤 클래스가 기본 생성자가 아닌 생성자가 정의되었다면 Subclass 도 반드시 생성자를 정의해야 한다. 그리고 그 생성자에는 super로 명시적 체이닝을 해줘야 한다 생성자 호출은 모듈에는 Spring 등의 DI Framework 를 쓰고, 일반 객체는 Builder 패턴 을 사용하게 되면 거의 쓸일이 없어진다. 하지만 독자 레이어링 시에는 간간히 호출하는 경우가 있기에 알아두면 좋을 것 같다. 정적 팩토리 메서드이 책에서 생성자 대신 정적 팩토리 메서드 생성을 추천하는 이유로 5가지를 들고 있다. 이름을 가질 수 있다객체 생성의 목적은 상황에 따라 다르다. 그리고 그 결과가 어떤 값이 될련지는 생성자 정의에 따라 달라지지만 new XXX 로 호출하는 표현에는 명시적으로 나와있지 않다. 이름을 가지게 되면 해당 생성의 목적을 이름에 표현할 수 있어 가독성이 증가한다. 객체 생성 제한이 가능하다객체 생성에 제한을 걸거나, 불변 객체를 매번 반환하는 등의 요령을 쓸 수 있다.상황에 따라 신규 생성인지 기존 객체 반환인지도 정할 수 있다. SubClass 를 반환할 수 있다상속 계층과 타입 상 하위 객체를 반환할 수 있고, 사용자는 그걸 모른채로 사용할 수 있다. 특정 버전의 class 정적 팩토리 메서드가 하위클래스 A를 반환하다가, 역시 Sub-Classing 된 B 를 반환하더라도 Client 코드에서는 그걸 신경쓰지 않고 작업이 가능하다. 기본적인 생성자를 사용한다면 구현체 자체가 바뀌었기에 Client 코드의 변경이 불가피해진다. 입력 매개변수에 따라 다른 타입으로 반환 가능하다위 SubClass 를 반환할 수 있다 랑 비슷한 이점이다. 매개변수에 따라 선택적인 Sub-Classing 된 객체를 반환할 수 있다. 실제 구현체 클래스가 없어도 된다1234567891011class Car &#123; public static Car newTruck() &#123; Class&lt;?&gt; truckClz = Class.forName(&quot;me.javarouka.vehicle.Truck&quot;); return truckClz.newInstance(); &#125; public static Car newBus() &#123; Class&lt;?&gt; busClz = Class.forName(&quot;me.javarouka.vehicle.Bus&quot;); return busClz.newInstance(); &#125;&#125; 위 코드처럼 처음 클래스가 로더에 존재하지 않아도 동적으로 현재 코드가 실행되는 클래스 로더에 해당 클래스 (예제에서는 com.vehicle.Truck, com.vehicle.Bus) 들을 로딩한다. 그리고 그 클래스의 인스턴스를 생성해서 반환할 수 있다. 추가적으로 Class.forName 으로 로딩된 클래스들은 static 구문을 수행한다 . 보통 JDBC 3.x 이하를 써본 사람은 많이 본 코드일 것이다 정적 팩토리 메서드의 단점책에서는 2가지를 소개하고 있지만 큰 단점으로 보이지 않는다. Sub-Classing 어려움 문서화 하지만 둘다 큰 단점으로 보이진 않는다.오히려 이시대의 사회악처럼 되어버린 상속을 방지하는 부가효과(?) 가 있고, 문서화는 코드 표현과 네이밍으로 대체할 수 있기 때문이다. 주로 쓰는 네이밍들은 다음과 같다. from 매개변수 하나인 메서드 of 매개변수가 N개인 메서드 getInstance 인스턴스를 생성한다. 앞서 반환한 객체와 같을 수도 있다. newInstance 인스턴스를 생성한다. 앞서 반환한 객체와는 항상 다르다. getSomeType 인스턴스를 생성하지만 자신의 타입이 아닌 다른 타입 (SomeType) 으로 반환한다. 다른 내용은 getInstance 와 같다 newSomeType 인스턴스를 생성하지만 자신의 타입이 아닌 다른 타입 (SomeType) 으로 반환한다. 다른 내용은 newInstance 와 같다","pubDate":"Sun, 11 Nov 2018 15:00:00 GMT","guid":"https://blog.javarouka.me/2018/11/12/static-creator/","category":["Effective Java","java","effective","serialize"]},{"title":"Effective Java 3th 정리노트","link":"https://blog.javarouka.me/2018/11/10/effective-java/","description":"Effective Java 3th 정리노트 Item 1 객체 생성 정적 팩토리 메서드를 쓰는게 왜 유리한가 Item 2 생성자에 매개변수가 많다면 빌더 패턴을 고려하라 Item 3 private 생성자나 열거 타입으로 싱글턴임을 보장하라 Item 4 인스턴스화를 막으려거든 private 생성자를 사용하라 Item 5 자원을 직접 명시하지 말고 의존 객체 주입을 사용하라 Item 6 불필요한 객체 생성을 피하라 Item 8,9 finalizer 와 cleaner 사용을 피하라 &amp; Try-With-Resource Item 10 equals 는 일반 규약을 지켜 재정의하라 Item 11 equals를 재정의하려거든 hashCode도 재정의하라 …","pubDate":"Fri, 09 Nov 2018 15:00:00 GMT","guid":"https://blog.javarouka.me/2018/11/10/effective-java/","category":["Effective Java","java","effective"]},{"title":"신규 통합 CS 시스템 관리 개발기 # 설계편","link":"https://blog.javarouka.me/2018/10/28/new_project_1/","description":"신규 통합 CS 시스템 관리 개발기 # 설계편 # 신규 통합 CS 시스템 관리 개발기 # 혼란편 # Customer Service 관리 시스템 개발전자상거래의 CS 관리 시스템이라는 건 생각보다 복잡하다. 회원정보 조회 회원 정보 (아이디, 계좌, 주소지 …때로는 탈퇴처리) 변경 이 회원이 주문한 내역 이 회원이 최근 주문한 상품 이 회원의 상담 이력 상품 판매 업체와 연동 택배 연동 메시지, 전화 등의 Channel 연동 etc … 사실상 전자상거래의 모든 도메인이 다뤄진다고 볼 수 있다. 그만큼 의존성이 문어발 식으로 연결되어있고, 그 만큼 타 도메인의 변화에 영향을 많이 받는다. 나 말하나...? 과장하면 타 도메인에서 재채기를 하면 감기에 걸릴수도 있는게 CS 관리 프로그램이다. 버틸수가 없다MSA(Micro Service Architecture) 환경에서 동시다발적으로 벌어지는 각 도메인들의 변화를 추적하고 반영하다보면, 쉴새없는 오류와, 호환성 문제를 겪게 된다. 이런 상황을 잘 관리하지 못하면 결과는 끔찍하다. 쓰레기를 가득 실은 트럭이 도로 제한속도를 넘어 과속하는 것만으로 위험한데, 이 트럭이 사고가 나 전복된다면 쓰레기들이 도로를 가득 메우는 상황이 펼쳐질 것이다. 아마 CS 개발자 대부분이 어떤 로직에 추가사항을 넣으려고 할때 이 코드는 누가 만들었지?! 하며 git blame 을 (혹은 annotation) 을 안해본 사람이 없을 것이다. (때로는 만든 사람이 자신인 웃기는 경우도 있다…) 테스트 코드 부재는 예사이고, 팀원들끼리 충분한 커뮤니케이션이 없으면 중복된 코드가 각자의 개성으로 암세포처럼 자라난다. 그 코드가 관련된 도메인이 변할 경우 이곳저곳에서 자란 해당 코드 모두가 수정되어야 한다.새 기능이 추가될 때 하나라도 이 부분을 누락하면 바로 장애로 이어지거나 유지보수 이슈가 등록된다. 리팩토링에도 한계가 있다. 리팩토링 범위를 아무리 최소로 해도 하다보면 너무나 광범위한 영역을 다루게 되며 결국 포기하는 일이 많다. 리팩토링이 때로는 새로운 버그를 만들기도 한다. 이건 이 경우와는 별개로 애초에 잘못된 습관 탓도 있고, 다른 상황에서도 마찬가지인 경우가 많긴 하다. 버틸수가 없다! 이런 환경속에서 부족한 리소스로 일을 진행하면서 몇차례의 개편을 하다보니 코드의 유지보수성에 많은 생각을 하게 되었다. 외부 변화에 큰 타격이 없을 것 도메인 대응이 늦어도 해당 도메인의 기능을 제외하고는 정상 동작해야 할것 서버와 클라이언트의 분리가 될 것 새 기능의 추가가 쉬울 것 프로그램 속도에 문제가 없을 것 코드가 Readable 할 것 재미있을 것(?) 이런 생각이 정리되어 가던 때에 드디어 다시한번 개편을 시도할 기회가 생기게 되었다. 신규 주문정보의 개편이 시작된 것이다. 이번이 나에겐 4번째이다. 그동안 고민했던 문제들을 쭉 펼쳐보고 기존에서 바꾼 방법을 하나하나 적어보겠다. 모든 것은 팀원들과의 회의를 통해 결정 했다. 이 과정은 상당히 길고 잦었지만 그 시간은 상당히 유익했던 시간이었다 새로운 방법Layer기존의 구조는 Spring 의 Controller - Service - Repository or Domain API 의 정석적인(?) 구조였다. DDD 방식으로의 전환도 고려해보았지만, 5년을 넘게 일해도 이해할 수 없는 여러 비즈니스들과 도메인 개념들, 그리고 팀 전체적으로 (나 포함) 낮은 DDD 숙련도 등으로 그냥 전통적인 Controller - Service - Repository or Domain API 로 결정했다. 약간 아쉽기도 하지만, 시간이라는 제약도 있고 익숙하지 않은 모험을 하기에는 약간 위험했다. 다만 저 기본적인 흐름에 레이어링을 적용하기로 했다. Controller 외부 요청을 처리하는 용도. 일반적인 Controller. Service 요청에 대한 비즈니스 로직의 묶음. 비즈니스가 변할 경우 서비스만 재작성하면 된다. 여러 비즈니스 단위 모듈 의존성을 주입받아 처리한다. 하나의 의존성만 있을 수 있고, 여러 비즈니스가 얽힌 의존성이 처리될 수도 있다. Business Logic Behavior 단일 비즈니스를 처리하기 위한 모듈 Repository 등에 의존성이 있다. Repository 팀 오너십 데이터에 대한 CRUD 및 외부 API 에 대한 래퍼. Repository 와 Api 를 나누려고 했으나 그냥 하나의 레이어로 래핑하기로 함. Helper 유틸리티. 무상태이거나 Controller, Service, Behavior, Repository 에는 의존성이 없는 모듈. 순수 함수들의 집합. Helper 를 제외한 각 레이어끼리는 의존성을 걸지 않는게 기본이다. 초창기에는 Collector Layer 도 추가했지만, 나중에 설명할 데이터 토막치기 덕분에 잘 쓰이지 않아 사장되었다. Collector 는 각 데이터를 Aggregation 하는 레이어였다. DTODTO 도 구분했다. 데이터의 포장에도 각자의 목적이 있다 기본적으로 Request 로 받는 Condition 류를 제외한 모든 DTO 에는 모든 필드가 final 로 불변객체이다. 불변이 아닐 경우 각 로직이나 레이어를 거치면서 전달되는 객체의 필드가 실제 값이 있는지, 중간에 값이 어떻게 변하는지, 등의 상황에서 한 레이어만 보고서는 추적이 되지 않기 때문이다. 1234567891011/** * 확장성이 없고 반드시 필요한 순서대로 호출해야만 한다. */// 주문정보를 읽는다DetailOrderDTO order = this.readOrderData(orderId);// 주문에 상품정보를 넣는다order = productModule.appendProductData(order);// 주문에 업체정보를 넣는다order = vendorModule.appendVendorData(order); 이러한 로직이 있을 경우 productModule.appendProductData, vendorModule.appendVendorData 는 주문의 특정 필드의 nullable 여부가 중요해진다. 게다가 상품에 업체정보가 있으므로 앞선 로직에서 상품정보가 정상적이지 않을 경우 다음 업체정보도 얻을 수 없게 된다. 이 상황에서는 필드의 초기화 여부와 각 모듈의 호출 순서가 매우 중요하다. 이 규칙아래 에서 모듈 의존성 뿐 아니라 로직 의존성까지 발생한다. 리팩토링을 할 때도 문제가 된다. 각 모듈 호출 순서를 반드시 지켜야 하며 각 모듈안의 로직을 자세히 살펴보고 완전히 로직을 파악한 뒤에야 리팩토링을 할 수 있다. 하지만, 모든 필드가 final 일 경우 어떠한 DTO 를 전달받았을 경우 각 필드들이 반드시 초기화가 되었다는 걸 의미하기에 앞선 문제의 대부분이 해소된다. 어디선가 전달받은 객체라도 값의 내용물에 대해 안심하고 쓸 수 있다는 뜻이다. (필드의 Null 여부가 아니라 초기화 여부를 말한다) 각 레어이간 데이터는 다음과 같은 기준으로 정했다. 네이밍이 약간 이상한것 같지만 그런가보다 하자; VO Repository 등에서 얻는 기본 데이터. Condition Client 의 요청 데이터. 불변처리가 힘들기에 일반적인 Setter 가 달려있다. Form 비즈니스 로직 단위의 요청 폼. 대부분 서비스에서 생성되어 각 비즈니스 처리기에 전달된다. Result 각 VO 를 수집하여 Client 가 요구하는 데이터로 빌드되는 DTO 예를 들면, MemberFindCondition 으로 요청되면 서비스는 그 요청으로 각 비즈니스에 MemberFindForm, MemberBlockForm, MemberXXXForm 등을 만들어 처리하고 그 결과를 MemberFoundResult 로 응답한다. Data Aggregation다양한 도메인을 한번에 다루는 CS 특성상 여러 도메인의 데이터를 조합하는 경우가 많다. 재료를 잘 섞어야 맛있다. 어디에도 끼는 회원이나 상품 말고도 CS의 99% 이상의 문의가 주문 관련이니 주문 데이터와 주문에 따라오는 배송 데이터 등은 항상 데이터 조합 대상이다. 기존 시스템은 클라이언트 요청에 서버는 각 도메인의 데이터를 한번에 합쳐서 보여주는 방식으로 동작했다. 가령 회원이 최근에 주문한 데이터를 봐야 한다면 회원정보, 주문정보, 상품정보, 배송정보, 취소정보를 읽은 뒤 조합했다. 요청이 하나만 있을 경우에는 이 방법도 나쁘지 않지만, 요청이 다수가 겹칠 경우 문제가 될 수 있다. 요청하는 데이터끼리 중복되는 데이터를 포함할 수 있기 때문이다. 최근 주문목록을 보여주는 컴포넌트가 있고 주문목록에서 특정 주문을 선택할 경우 다시 해당 주문의 상세를 보여주는 UI가 있다고 가정한다면,매 요청의 응답에는 공통적으로 연관 상품정보, 취소정보, 결제정보, 배송정보가 포함되게 된다. 불필요한 반복적 요청이 되는 셈이다. 게다가 비즈니스의 변화로 데이터에 변화가 생길 경우 각 화면별로 더 추가되거나 제거될 수 있어 수정도 동시에 여러 군데에서 일어난다. 이런 방법보다 데이터의 조합은 연관결합도가 높은 것끼리만 하고, 공통적인 데이터는 분할 요청하는 방식을 선택했다. 난 이걸 데이터 토막치기 라고 (나 혼자 쓰는 용어이다) 명명했다. 데이터 토막치기 토막쳐보자... 부우우우우웅!! 최근 주문목록에 필요한 데이터를 조합한다고 가정해보자 회원정보 요청 회원이 주문한 내역 리스트 데이터를 최근 순으로 요청 주문내의 정보로 다음 정보 요청 주문 내의 상품정보로 상품 정보 요청 주문 아이디로 결제 정보 요청 주문 아이디로 취소 정보 요청 상품 정보가 응답되면 그 정보로 다시 업체 정보 요청 상품 정보로 상품의 각 배송타입, 유형, 카테고리 정보 요청 각 정보를 조합해서 화면에 표시한다. 여기서 다시 특정 주문의 상세를 보고 싶다고 한다면 앞서 요청한 상품상세와 각 메타데이터, 업체, 결제, 취소 정보는 요청하지 않아도 된다.필요한 상세 데이터를 추가 요청한뒤 데이터를 조합하면 끝이다. 그리고 다른 주문번호를 보다가 다시 같은 주문 상세를 조회할 경우, 이미 로딩된 정보를 활용할 수도 있다.어떤 데이터 종류는 갱신이 자주 되는 데이터는 만료 관리가 필요하거나 아예 새로 로딩해야 할 때도 있지만, 대부분의 경우 앞서 설명한 로딩된 데이터끼리의 조합 방식이 훨씬 유리하다. 이렇게 데이터를 최대한 분할하여 재활용성과 서버 자원 낭비를 줄이고 성능 향상도 고려했다. 모든 데이터를 토막치는게 아닌 비즈니스나 UI 상황, 효율및 결합도에 따라 데이터 구성을 하여 합치는게 유리하다는 것도 잊지 않았다. 마침 적용하려고 하는 상태관리기 Redux 의 selector 개념과 이를 보좌해주는 Reselect 는 이런 방식에 찰떡 궁합이었고, 디렉토리 구조도 그에 맞게 가져갔다. 서버 기반을 수정해보자서버 개발에서는 특별한 개선을 하기 어려웠다. 프로젝트를 온전하게 새로 설정했으면 좋았겠지만, 기존부터 쌓인 코드에 의존성이 상당하고 타 팀의 코드도 섞여 있기에 서버의 완전한 새판 짜기는 불가능했다. 위에 설명했던 레이어링 및 패키지와 설정 파일의 분리 정도가 가능했고, 나머지 모듈 의존성 등은 크게 손댈 수 없었다. 기회가 된다면 Spring Boot 부터 Mbean 등을 좀 더 잘 써보고 싶은데… 한다면 팀 스탠드얼론이 가능한 프로젝트에나 도입할 수 있을 것 같아 아쉽다. OTL 클라이언트 기반을 수정해보자클라이언트는 이야기가 달라서 완전한 재설정이 가능했다. 클라이언트쪽은 기존의 나쁜 냄새를 모두 제거하기 위해 바닥부터 새로 시작하기로 했다. Global N Sub 방식의 Multi-Store 클라이언트 사이드 라우팅 스크립트 용량 축소 컴포넌트의 재사용성 사용자 액션 추적 에러 리포트 Multi StoreRedux 는 기본적으로 단일 스토어를 추천한다. 하지만 새로 개편하는 어플리케이션에는 단일 스토어의 이점이 전혀 떠오르지 않았다. 데이터가 각 회원 혹은 주문 단위로 휘발성이며 상태들의 재사용성이나 히트율이 낮고, 동일한 구조의 회원이나 주문 등의 컨텍스트만 다른 데이터가 대다수이다. 이 역시 컨텍스트가 바뀌면 버려진다. 게다가 개편 대상인 어플리케이션은 동적 탭 단위의 구조이다. 같은 탭이 여러개 열릴 수도 있다. 그러면 탭마다 관리되는 상태는 컨텍스트마다 종속 데이터를 관리해야 한다. 또한 탭이 바뀌거나 하면 화면의 모든 요소를 새 화면의 컨텍스트에 맞게 계산하고, 컴포넌트를 렌더링해야 한다. 탭 하나가 굉장히 많은 데이터를 가질텐데, 단순한 탭의 스위칭만으로 모든 요소가 새로 그려질 것이고 그만큼 화면의 부하는 커진다. 컨텍스트에 따른 reducer - state 설계도 만만치 않은데다, 성능저하는 단일 스토어에 대해 깊이 생각해보게 되었다. 결론은 전역 스토어는 하나 두고, 특정 컨텐츠 탭에 대해서는 서브 스토어를 생성하며 스토어를 가진 탭이 닫힐 경우 상태를 정리하는 것보다 그냥 그 스토어를 버리는 구조로 정하게 되었다. 자식 스토어는 선택적으로 부모 스토어에서 상태를 구독할 수 있고, 액션중 특정 Symbol 을 통해 전역 스토어에도 dispatch 를 할 수 있도록 설계했다. 클라이언트 라우팅 이리저리 가시오 라우팅 기능을 하는 React-Router 라는 훌륭한 라이브러리가 이미 존재하고, 이걸 쓰면 되겠지 라고 생각했다. 그러나 이리저리 돌려본 결과는 실제 CS 툴에는 그리 어울리지 않다는 결론을 내렸다. 다음과 같은 이유에서다. 단일 스토어에 최적화되어 있다. 라우팅이 바뀔 경우 현재 스토어의 state 에 따라 컴포넌트를 새로 렌더링하는데, 만들려는 어플리케이션은 잦은 라우팅 변경이 있어서 성능 문제가 생긴다 props 가 아닌 state 의 관리가 어렵다 결국 React Router 에서 Route 기능만을 빌려와서 직접 라우팅 시스템을 구현할 수밖엔 없었다. 겸사겸사 React Router 에서 지원하기 좀 애매한 동적 모듈 로딩 라우팅도 적용했다. (개발 당시에는 없었는데 지금 버전에서는 잘 지원하고 있더라…) 사용한 라이브러리는 Univasal-Router 이다. 단순하지만 프로젝트에서 필요로 하는 모든 기능이 들어있었다. 스크립트 용량 축소위에 잠깐 언급되었지만 기존 시스템의 스크립트 용량은 무려 5mb 였다. 어플리케이션에 사용되는 모든 스크립트를 하나의 파일로 만들어서 한번어 로딩하는 방식이었기 떄문이다. 이 방법으로 인해 성능이 느리거나 네트워크가 불량할 경우 어플리케이션이 상당히 느려졌었고, 브라우저으 javascript 성능이 다소 안좋을 경우 (IE…) 페이지가 한참동안 흰색으로 보이거나 Timeout 에 걸리는 백화 현상 이라는 일이 발생했었다. 이번에는 필요한 자원이 있을때 로딩하는 동적 로딩을 도입하기로 했다. 동적 로딩은 간단했다. webpack, babel 조합으로 간단히 import 구문으로 구현할 수 있었고, webpack 의 chunkName 조합으로 디버깅 및 파일 이름 지정도 가능했다. 1234567891011121314151617181920212223242526272829// 동적 컴포넌트 예시import React from &#x27;react&#x27;const loadComponent = () =&gt; import(&#x27;component/DynamicComponent&#x27;);class MyComponent extends React.Component &#123; this.state = &#123; DynamicComponent: null, &#125;; componentDidMount() &#123; loadComponent().then(DynamicComponent =&gt; &#123; this.setState(&#123; DynamicComponent &#125;) &#125;); &#125; render() &#123; const &#123; DynamicComponent &#125; = this.state; if(!DynamicComponent) &#123; return null; &#125; return ( &lt;DynamicComponent /&gt; ); &#125;&#125; 적용 후 첫 로딩 스크립트의 용량이 300kb 도 안될 정도로 좋아진 걸 보고 꽤나 좋았던 기억이 난다. 컴포넌트 재사용성이 문제는 참 어렵다. 재사용성을 아무리 고려해도 실제 이리저리 재활용을 하려고 하면 각자의 조금씩 다른 요구사항과 스타일 등에 버려지는 케이스가 많기 때문이다. 재활용성이 높은 컴포넌트는 무엇보다 이런 고민이 잘 커버되는 설계가 상당히 중요하다. 설계 능력이 그리 좋지 못한 덕분에 나는 아직도 재활용성이 높은 컴포넌트가 뭔지 헤메이고 있다. 그래도 노력이 나를 조금이나마 동정했는지, 몇몇 컴포넌트는 재사용성을 확보할 수 있었다. 디자인 요소를 배제할수록, 도메인 이해도가 높을 수록 재사용성이 높았던 것 같다. PureComponent 를 최대한 다수를 생성하려고 했다. 재활용의 시작이 되니까. React 16.6 에서는 React.memo 라는 것도 지원해서 PureComponent 사용이 더 좋아졌다. 재활용 요소는 가급적 React.Fragment 로 래핑한다. 이 요소가 어느 레이아웃으로 재활용될지 모르기 때문이다. 스타일 요소는 하나하나를 스타일링하지 말고 Styled-Component 로 대체할 수 있게 디자인한다. 사용자 액션 추적 / 에러 리포트이 문제는 사실 Redux의 middleware 만 잘 활용하면 달성이 쉽다. 다만, 액션으로 잡히지 않는 것까지 모두 처리하려면 직접적인 상태 변화가 없는 (다시 말하면 reducer 에서 처리하지 않는) 액션까지 디테일하게 설계해야 한다. 이런 건 보통 사이드이펙트 뿐인 작업을 수행할 때 발생하는데, 이런 것에 잘 어울리는 방식을 찾다가 Redux-Saga 를 도입하기로 했다. Redux-Saga 는 Redux 플로우에서 사이드이펙트를 관리하기 위한 미들웨어이다. Redux Saga 로 사용자의 모든 행동은 Saga 를 통해 로깅되며 사이드이펙트로 서버에 리포트되도록 했다. 이런 액션 로깅은 Elastic Search 등으로 쌓아서 통계나 어플리케이션 사용 행태를 분석하는 용도로 쓰려고 준비중이다. 사용자의 흐름이나 행동 및 발생하는 에러를 분석하면 버그나 기능 개선, 사용율 체크에 큰 도움이 되지 않을까 한다. 에러 시에는 현재 상태의 스냅샷을 전송한다면 재현도 어렵지 않게 할 수 있기에 처리가 좀 더 쉬울것이라 예상한다. 서비스를 해봐야 알겠지만… 클라이언트 단독 개발이 가능하도록 프론트 엔드 성 아래의 백 엔드 심해 요청사항에 따라 클라이언트 개발만 진행하거나 소소한 수정건이 있을 수 있다. 이런 경우 예전의 구조에서는 클라이언트 수정이라도 로컬 서버를 먼저 실행시키고 로컬 서버를 구동하여 개발을 진행했다. 이 방법이 나쁜건 아니나 어차피 현재 구조에서는 페이지 라우팅을 클라이언트에서 하는데다가, 인증과 데이터 말고는 서버가 화면에 하는 일이 없기때문에 굳이 클라이언트 수정할때 무거운 local WAS 를 실행시킬 필요가 없다고 생각했다. 이 구조에서는 데이터만 제공된다면 클라이언트 개발에는 무리가 없다. 가상 데이터를 제공할 수 있는 mock 서버를 시작하고 가상 데이터를 내려주는 로컬 서버를 시작하고 webpack-dev-server 를 mock 서버에 연결하는 작업으로 로컬서버만으로 개발이 가능하게 되었다. mock 서버는 node-mock-server 을 사용했다. 문서가 다소 부족해서 사용법 사용에 애를 먹었지만, 파일 기반으로 GET, POST, PUT, DELETE 등 지원에 커스텀 파라미터에 따른 커스텀 데이터 생성기능까지 쓸만한 기능은 다 있어서 단순한 기능 사용에는 문제가 없었다. webpack-dev-server 와 mock 연동에는 express-http-proxy 를 사용했다. 이 방법으로 mock 연계를 하고나니 좀 더 나아가서 실제 서버로 화면 개발을 진행할 수 있을것 같았다. 추가 개발은 proxy 에 https 지원을 추가하고 npm 스크립트를 몇개 수정한 것 뿐으로 훌륭한 실서버 &lt;==&gt; webpack-dev-server 의 연계가 만들어졌다. 이 작업으로 클라이언트 개발 매우 편해져서 작업 효율이 크게 증가했다. 아직이다지금까지 개선과 설계 방향을 쭉 나열한 것 같다. 다음 글 에는 이러한 개념을 적용하며 겪은 문제점과 아쉬운 부분을 나열해보겠다.","pubDate":"Sat, 27 Oct 2018 15:00:00 GMT","guid":"https://blog.javarouka.me/2018/10/28/new_project_1/","category":["Tech","java","javascript","scaffolding","legacy","new-cs-system"]},{"title":"Inline styles","link":"https://blog.javarouka.me/2018/01/01/inline-styles/","description":"인라인 스타일에 대한 생각 스타일이 각각의 엘레먼트에 있음으로 인해 HTML 문서의 용량이 증가. 이는 과한 트래픽으로 이어진다. CSS 의 경우엔 첫 로딩 이후에는 일반적으로 캐시되며 트래픽 감소 효과가 있다. 공통적 스타일을 변경할 경우 해당하는 모든 스타일을 수정해야 한다. 요소에 붙은 스타일을 보고 어떤 스타일인지 추론하는 것이 불가능하다. 예를 들어 highlight-box 라는 클래스네임이 있다면 강조 성격의 UI 블럭요소라고 추론해볼 수 있지만 인라인일 경우 직접 스타일 코드를 읽어야 한다. Left-To-Right, Right-To-Left 등의 언어 방식의 경우 대응이 힘들어진다.","pubDate":"Sun, 31 Dec 2017 15:00:00 GMT","guid":"https://blog.javarouka.me/2018/01/01/inline-styles/","category":["Tech","css"]},{"title":"Lerna","link":"https://blog.javarouka.me/2018/01/01/lerna/","description":"LernaOfficial Sitehttps://lernajs.io/ links Why we dropped Lerna from PouchDB The highs and lows of using Lerna to manage your JavaScript projects Monorepo setup with Lerna and Yarn workspaces Monorepo? Yarn Workspace! Mono-repo or multi-repo? Why choose one, when you can have both? What Lerna?Lerna 는 여러 패키지로 구성된 대규모 npm 프로젝트를 관리하기 위한 도구이다.세분화된 구성 요소로 구성된 대구모 프로젝트의 경우 각 서브 프로젝트들의 의존성을 서로 관리하다보면 각 프로젝트별 업데이트 관리가 꽤나 힘들어진다.이럴 경우 lerna 를 사용하여 대규모 프로젝트 관리에 큰 도움을 받을 수 있다.","pubDate":"Sun, 31 Dec 2017 15:00:00 GMT","guid":"https://blog.javarouka.me/2018/01/01/lerna/","category":["Tech","npm"]},{"title":"운영되던 서비스, ES5 에서 ES6 으로 옮긴 이야기 2 (feat Webpack)","link":"https://blog.javarouka.me/2017/05/14/convert-legacy-to-webpack-bundle-2/","description":"2016년 5월부터 2016년 6월까지 진행된 나의 to ES6 삽질을 기록해본다. 100% Real 은 아니고… 95% 정도? 전 글 버틸수가 없다전 포스트의 막바지에 썼듯이 실무는 실전이었다. 다음과 같은 문제를 부딪히며 하나하나 해결해 나갈 수 밖에 없었다. 컨트롤러 매핑 문제requirejs 를 쓰면서 AMD 식으로 필요할 때 스크립트를 로딩했는데, 이 부분부터 고쳐야 했다 Controller 의 이름이 만일 order/MemberController 라면 다음과 같은 방법으로 컨트롤러를 로딩한다. 1234567// const controllerPath = &#x27;order/MemberController&#x27;;require([`controller/$&#123;controllerPath&#125;`], ControllerClass =&gt; &#123; const controlelr = new ControllerClass(contentElement, controllerPath) controlelr.execute(); &#125;); 이 방법은 필요할 때 비동기로 네트워크 상에서 스크립트를 로딩하고, 완료 시 콜백 함수의 인자를 통해 모듈을 사용한다 일단은 기본적으로 모든 모듈이 바로 접근 가능해야 하는 ES6의 모듈은 이런것을 허용하지 않았다. 결국 아래와 같은 controllerMap 을 만들었다 1234567891011121314151617181920212223// @file controllerFactory.jsimport EmptyController from &#x27;./EmptyController&#x27;import MainController from &#x27;./OrderController&#x27;import OrderController from &#x27;./order/OrderController&#x27;import MemberController from &#x27;./member/MemberController&#x27;import MemberBlockController from &#x27;./member/MemberBlockController&#x27;// ... Controller import Statement 다수const controllerMap = &#123; &#x27;MainController&#x27;: MainController, &#x27;order/OrderController&#x27;: OrderController, &#x27;member/MemberController&#x27;: MemberController, &#x27;member/MemberBlockController&#x27;: MemberBlockController, // ...&#125;;// 이름으로 매핑해둔 컨트롤러를 반환한다.export default function(conrollerPath) &#123; return controllerMap[conrollerPath] || new EmptyController();&#125; 이런식으로 미리 Controller 모듈을 로딩해두고 맵으로 관리되게 한 다음, 반환하는 Factory 모듈을 만들어서 처리했다. 동적 로딩을 완전히 포기하고 초기에 모든 스크립트를 로딩하게 한 선택이다. 물론 초기 스크립트 로딩 용량이 굉장히 커지고 컨텐트와 컨트롤러가 추가될수록 증가하지만, 별 방법이 없다고 생각했다. require.ensure 를 사용하여 동적 로딩을 선택할 수도 있었지만 동적 로딩도 동적 문자열로 모듈을 로딩하는건 불가능하기에, 각 컨트롤러의 매핑마다 동적 로딩 코드를 적어주어야 했다. 다음과 같이 말이다. 별로 마음에 들지 않았다. 1234567891011121314151617181920212223242526// @file asyncControllerFactory.jsimport EmptyController from &#x27;./EmptyController&#x27;const controllerMap = &#123; [&#x27;MainController&#x27;]() &#123; return new Promise(resolve =&gt; &#123; require.ensure([], () =&gt; resolve(require(&#x27;./MainController&#x27;))) &#125;) &#125;, [&#x27;order/OrderController&#x27;]() &#123; return new Promise(resolve =&gt; &#123; require.ensure([], () =&gt; resolve(require(&#x27;./order/OrderController&#x27;))) &#125;) &#125;, // ...&#125;;export default function(conrollerPath) &#123; const factory = controllerMap[conrollerPath]; return factory ? factory().then(Controller =&gt; new Controller().execute()) : Promise.resolve(new EmptyController().execute());&#125; 저 ensure 구문은 반드시 저렇게 패스와 같이 적어줘야지 별도로 분리하게 되면 webpack 번들링 후 실제 로딩이 잘 동작하지 않았다. 컨트롤러 수가 작업 당시에는 그렇게 많지 않았고 동적 로딩 시 종종 Timeout 등의 네트워크 오류도 났기에 그냥 전체를 한번에 번들링해버리는 선택을 했다.(그리고 나중에 엄청 후회했다…) Webpack2 에서의 Async Module LoadingWebpack 2 에서는 import 와 async/await 를 사용해서 동적 로딩을 할 수 있다.이런식의 코딩이 가능. 표준을 준수한다는 것 외엔 특별한 외형 차이는 없다. 12345678// ES7 의 async 와 await 를 사용한다async function loadOrderCancelController() &#123; const Controller = await import(&#x27;./OrderCancelController&#x27;); return Controller;&#125;loadOrderCancelController() .then(Controller =&gt; new Controller().execute()); 이제 각 컨트롤러를 매핑해주고 컨텐츠 로더가 그것을 잘 사용할 수 있게 수정하는 노가다만 남은듯 했다. 하지만 현실은 … ES6 모듈과 commonjs, amd 모듈은 달랐다.Webpack 은 분명 AMD 와 commonjs 모듈도 사용할 수 있다. 실제로도 그렇다.하지만, 이 두 스펙의 모듈 정의를 ES6 모듈과 함께 사용할때는 큰 문제가 발생했다. ES6 모듈 정의에는 default export, named export 라는 AMD, commonjs 에 없는 개념이 있었기 때문이다. 다음에 세가지 스타일로 모듈을 정의해보았다.이 모듈의 이름은 rouka/blog/module 이라고 해보자 먼저, AMD 모듈은 다음과 같은 형식이다. 1234567891011121314define([ &#x27;jquery&#x27;, &#x27;moment&#x27; ], function factory($, moment) &#123; const YMD_FORMAT_STR = &#x27;YYYYMMDD&#x27;; return &#123; getEl(selector, context) &#123; return $(selector, context || document); &#125;, todayString() &#123; return moment().format(YMD_FORMAT_STR); &#125; &#125;;&#125;) commonjs 의 모듈은 다음과 같은 형식이다 123456789101112const $ = require(&#x27;jquery&#x27;); const moment = require(&#x27;moment&#x27;); const YMD_FORMAT_STR = &#x27;YYYYMMDD&#x27;;exports.getEl = function(selector, context) &#123; return $(selector, context || document);&#125;;exports.todayString = function() &#123; return moment().format(YMD_FORMAT_STR);&#125;; ES6 모듈은 다음과 같은 형식이다. 123456789101112import $ from &#x27;jquery&#x27;; import moment from &#x27;moment&#x27;;const YMD_FORMAT_STR = &#x27;YYYYMMDD&#x27;;export function getEl(selector, context) &#123; return $(selector, context || document);&#125;export function todayString() &#123; return moment().format(YMD_FORMAT_STR);&#125; 여기까지는 세개 다 비슷해 보인다. 모듈을 로딩할때 쓰는 statement 나 문법만 다른 정도.하지만 위의 정의 모듈을 사용할때 달라진다. 먼저 AMD 와 commonjs 는 기본적으로 형태만 다를 뿐 기본적인 사용은 같다. 모듈을 로딩하고, 해당 모듈을 객체를 얻으면 그 모듈을 사용할 수 있다 12345678// AMDrequire([&#x27;rouka/blog/module&#x27;], function(blogModule) &#123; console.log(blogModule.todayString()); // 오늘 날자...&#125;);// commonjsconst blogModule = require(&#x27;rouka/blog/module&#x27;)console.log(blogModule.todayString()); // 오늘 날자... 하지만 이 모듈을 ES6 에서 사용하려면 좀 다르다. 1234// ES6// 이 부분이 다르다!import &#123; todayString &#125; from &#x27;rouka/blog/module&#x27;console.log(todayString()); // 오늘 날자... import 시에 실제 사용할 기능 프로퍼티 이름을 적어주고 있다.만일 그냥 123// ES6import blogModule from &#x27;rouka/blog/module&#x27;console.log(blogModule.todayString()); // throw TypeError 이런식으로 사용할 경우 오류를 낸다. 위의 문법은 rouka/blog/module 에서 default 모듈을 사용하겠다는 뜻이다.ES6 모듈에는 default export 라는게 있다. 123456789101112131415import $ from &#x27;jquery&#x27;; import moment from &#x27;moment&#x27;; export function getEl(selector, context) &#123; return $(selector, context || document);&#125;export function todayString() &#123; return moment().format(YMD_FORMAT_STR);&#125;// default exportexport default function setTodayOnEl(selector, context) &#123; getEl(selector, context).html(todayString());&#125; default export 로 해당 엘리먼트에 오늘 날자를 HTML 로 넣어주는 함수를 정의했다. 123456789101112131415// default 모듈 사용import setTodayOnEl from &#x27;rouka/blog/module&#x27;console.log(setTodayOnEl(&#x27;body&#x27;)); // 오늘 날자...// ........................// 명시적으로 사용import &#123; setTodayOnEl &#125; from &#x27;rouka/blog/module&#x27;console.log(setTodayOnEl(&#x27;body&#x27;)); // 오늘 날자...// ........................// 혼용해서 사용. 앞이 defaultimport setTodayOnEl, &#123; todayString &#125; from &#x27;rouka/blog/module&#x27;console.log(setTodayOnEl(&#x27;body&#x27;)); // 오늘 날자... 실제 Babel 은 ES6 모듈과 이외 모듈을 다른 방식으로 컴파일하는데, ES6 의 모듈일 경우에는 __esModule 이라는 마크를 해 두고 import 구문을 만날 경우 다른 방식으로 import 를 수행한다. Controller 모듈을 기본적으로 ES6 으로 변경하고 있었는데 이 경우 Controller 를 commonjs 나 amd 모듈이 import 할 경우 추가적으로 default 프로퍼티로 접근해야 했다. 123456789101112// ./es6.style.module&#x27; 모듈은// named export 와 default export 가 섞여있다.var es6Module = require(&#x27;./es6.style.module&#x27;);// 이 반환된 모듈 안은// &#123; default: doSome, otherSome &#125; 같은 형식이다.// 물론 doSome 사용에는 default 프로퍼티가 필요하다.es6Module.default.doSome();// named export 모듈은 그냥 사용한다es6Module.otherSome(); 실제 프로젝트에 적용 시 세가지 스타일의 모듈 정의가 뒤섞여 작업되고 있었고, 각 모듈마다 모듈 사용에 있어 각기 다른 방법으로 사용해야 하는 지경에 이르르니, 거의 수라계에 온 듯한 느낌을 받게 했다. webpack 에서 뱉어내는 빨간색 천지의 오류 메시지와 함께 내 마음도 붉게 물들기 시작했다 위의 ES6 및 commonjs 모듈의 다른 점을 알고 싶다면 엑셀박사님의 블로그를 한번 읽어보자. [Babel and CommonJS modules] 결국, 개발된 모든 파일을 ES6 으로 변환~!여러 꼼수를 써보다가, 결국 선택한건 모든 파일에 대해 ES6 스타일로 코드를 변환하는 것으로 선택했다. 프로젝트 내에서 한가지 스타일로 코딩이 되어 있어야 하는건 당연한 것이고, 기왕이면 표준 스펙으로 선택하는 것이 유리했으며, ES6 모듈을 적용하면 Dead Code Elimination(Tree Shaking) 이라는 최적화 전략까지 쓸 수 있기 때문이었다. Tree Shaking Tree Shaking 은 요약하면 모듈 import 최적화로 실제 컴파일 시 모듈 import 에서 사용하는 코드만 컴파일 결과에 포함시키는 것이다. 당연히 용량이 작아지고 연산이 줄어든다. 암튼 나는 당시 900 개가 넘는(…) js 코드들을 하나하나 열어서 ES6 스타일의 모듈 코드로 변환하기 시작했다. 정말 즐거운 일이었다. 개발서버와 번들서버스크립트를 동적으로 컴파일한다는건 파일이 작을땐 별 문제가 되지 않는다. 하지만 프로젝트의 규모가 나름 컸으므로 생성된 파일은 상당히 많았고, 이 파일을 실제 컴파일하여 실제 파일을 만들어내는 데에는 2~3 분의 시간이 걸렸다. 뭐 배포 전 한번이라면 괜찮다. 하지만 이 것이 watch 등으로 코드 수정시마다 일어난다고 할 경우에는 문제가 심각해진다. webapack 은 webpack dev server 를 제공했고, 이것을 사용할 경우 파일을 실제 Disk 에 생성하는게 아닌 메모리에 생성하고 그것만을 갱신하기에 속도가 상당히 빠르다. 설정은 예제 사이트들이 아주 잘 되어있어서 그것을 가져다가 쓰면 되었다. 여기에 express 를 사용해서 Data Server 를 Proxy 로 감싸서 쓰게 되면 로컬에 별도의 java 를 구동하지 않고도 사용할 수 있어서 클라이언트 개발에는 순수하게 webpack-dev-server 만으로도 충분하도록 설정했다.(뭐 결국 서버까지 손대는 일이 부지기수지만…갑작스러운 오류 등으로 클라이언트에 대해 디버깅하기에는 엄청나게 유용했다.) express-http-proxy 를 사용해서 정적 리소스 외에는 프록시로 이미 구동중인 서버로 요청을 하게 했다. 프록시-번들서버 코드는 매우 간단하다. 12345678910111213141516171819202122232425262728293031323334353637383940import proxy from &#x27;express-http-proxy&#x27; // 이놈이 효자import Express from &#x27;express&#x27;export default function startProxyServer() &#123; const delegateServer = new Express(); // 프록시 서버 정보 const proxyServer = &#x27;localhost&#x27;; const proxyPort = 11980; // 번들서버 정보 const bundleServerHost = &#x27;localhost:11980&#x27;; // API 서버 정보 const targetServer = &#x27;myproject.companydev.com&#x27;; // 번들서버 요청 delegateServer.use(&#x27;/resources/*/bundles/:name&#x27;, proxy(bundleServerHost, &#123; forwardPath(req) &#123; return &#x27;/bundles/&#x27; + req.params.name; &#125; &#125;)); // 이 외의 요청은 Proxy 를 통해 설정된 서버로. delegateServer.use(&#x27;/&#x27;, proxy(targetServer)); // 시작~ delegateServer.listen(proxyPort, err =&gt; &#123; if (err) &#123; console.error(err); reject(err); &#125; else &#123; console.info(&#x27;Webpack development proxy server progress... %s&#x27;, `http://$&#123;proxyServer&#125;:$&#123;proxyPort&#125; to $&#123;targetServer&#125;`); resolve(); &#125; &#125;);&#125; webpack-dev-server 를 구동할때 프록시 개발서버까지 같이 돌려주면 완벽. 이제 남은건 실제 배포 환경이었다. 실제 배포환경실제 운영 환경에서는 번들서버같은걸 띄울수도 없고 띄워서도 안된다. 운영시에는 메모리에 존재하는 스크립트가 아니라 실제 파일을 만들어야 해서 별도로 webpack 설정을 production 용으로 하나 만들고 이 설정에서는 별다른 번들서버나 프록시, 기타 개발 서포트 플러그인을 제외하고 구성했다. 개발에는 없던 UglifyPlugin 옵션을 추가해서 소스를 압축했다. 사내에서는 빌드에 gradle 을 사용하고 있었기에 다음과 같은 구문을 넣어서 gradle 의 war task 수행 전 npm 을 사용해서 소스를 컴파일하고 파일을 지정된 위치에 생성되게 했다. 12345678apply &#x27;war&#x27;task packageClient (type : Exec) &#123; executable &quot;$&#123;project.projectDir&#125;/packageClient.sh&quot; // npm 빌드 스크립트&#125;// 여기~war.dependsOn packageClient 끝났나검색 - 삽질 - 노가다 - 삽질 - 검색의 무한루프를 돌며 변환이 끝났다. 이 작업은 기존의 잘 돌아가던 시스템을 다시 엎은거라서, 잘 되어야 본전인 일이라 사실 티는 그다지 나지 않았다.중간에 몇가지의 문제로 압박받은것만 많았고… 게다가 모든 코드를 한번에 로딩하는 방법을 선택해서, 스크립트 용량이 상당히 거대해져버린 문제는 과제로 남았다. 최근 webpack 2가 나오면서 webpack 1 이 deprecated 되었다. 다시 설정을 만질 때가 온 듯 하니 같이 작업하면 될 듯 하다.","pubDate":"Sun, 14 May 2017 14:30:17 GMT","guid":"https://blog.javarouka.me/2017/05/14/convert-legacy-to-webpack-bundle-2/","category":["Tech","javascript","Handlebars","webpack","개고생"]},{"title":"운영되던 서비스, ES5 에서 ES6 으로 옮긴 이야기 1","link":"https://blog.javarouka.me/2017/05/03/convert-legacy-to-webpack-bundle-1/","description":"2016년 5월부터 2016년 6월까지 진행된 나의 to ES6 삽질을 기록해본다. 100% Real 은 아니고… 95% 정도? 프로젝트의 안정화 마무리 즈음의 위험한 만남회사에 입사한 뒤로 내가 주로 한 일은 통으로 되어있던 프로젝트에서 내가 소속된 팀의 기능만 빼서 별도의 프로젝트로 분리하는 일이었다. MSA 로의 이전을 위해 한창 전사가 달리던 때다. 내가 속해있던 팀은 기존의 Spring + MyBatis 에서 Spring + JPA 를 적용하여 새로 프로젝트를 구성하였고 개발은 그럭저럭 마무리가 코 앞으로 다가왔다. 이때 쯤 신기술이 유행하고 있었는데 ~ ECMAScript, React React 라는 녀석과 함께 ES6 의 유혹은 매우 강렬했다. 개발자들의 일종의허세끼인 “신기술이면 우왕 굿” 하는 설레발 주도 개발에 푹 빠진 것도 있었고, 현재 팀 내에서 사용하고 있는 기술이 낙후되었다는 생각을 해오던 터라, 써보고 싶은 마음이 요동쳤다. 사실 난 이 전까지는 JavaScript 의 Source to Source Compile 에 대한 거부감이 상당했고 그동안 별 불편함을 느끼지 못해 그냥 무시해왔지만, 한번 맛을 들이고 나니 이놈들은 끊을 수 없는 콜라같은 마력을 뿜어냈다 선행 학습을 며칠간 진행하고 관련 스터디와 예제 코드를 몇번 직접 작성해 보고 더욱 그런 느낌이 들었다. 이건 바로 적용해야돼!! 기존 구조는 AMD + Handlebars하지만 기존에 완성되어 가던 프로젝트는 프로젝트 초기에 열심히 나름대로 세팅한 AMD 기반으로 동적으로 서버에서 Handlebars 컴파일 된 HTML 을 로드하고 그것을 화면에 innerHTML 등으로 붙여넣어 처리하는 구조였다. 동적으로 컨텐트와 그에 맞는 스크립트를 로딩하는 간단한 프레임워크였는데, 간간히 발생하는 모듈 Timeout 만 아니면 나름 잘 동작했다. 뭐 요약하면, Rouka Framework 0.0.1 정도 되려나. 간단히 소개하면 이런 구조다. hash url 기반의 SPA 다 컨텐츠가 요청되면 서버에서는 server side의 handlebars 를 사용하여 완성된 html을 응답한다. 그 응답 html 의 루트 엘리먼트에는 data-controller 라는 속성이 optional 로 있다. 그 속성은 실제 js 파일의 경로이며 require(경로) 를 통해 실제 그 컨텐츠가 사용할 Controller.js 를 동적 로딩한다 그 컨트롤러 파일은 로딩된 컨텐츠의 엘리먼트 레퍼런스를 가지고 UI의 이벤트 및 초기화를 수행한다. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354function getViewEL() &#123; // ... 동적 디스플레이 뷰 영역 반환&#125;/** * HTML 컨텐트 생성 */function createContentWrapper(html) &#123; var wrap = document.createElement(&#x27;DIV&#x27;); wrap.innerHTML(html); getViewEL().appendChild(wrap); return wrap;&#125;/** * 이 부분이 핵심. * 컨트롤러 속성을 가져와서 해당 컨트롤러 모듈을 로딩한다. */function loadController(wrap) &#123; return new Promise( function( resolve ) &#123; var contentEl = wrap.querySelect(&#x27;[data-controller]&#x27;); if(!contentEl) return resolve(contentEl); var controllerPath = contentEl.dataset.controller if(!controllerPath) return resolve(contentEl); require([&#x27;controller/&#x27; + controllerPath], function(Controller) &#123; var controller = new Controller(contentEl, controllerPath); controller.execute(); resolve(contentEl); &#125;); &#125;);&#125;function reportError() &#123; // ...컨트롤러 에러 보고&#125;function ajax(path) &#123; // ...서버에 컨텐트 요청&#125;function loadContents(path) &#123; ajax(path) .then(wrapContent) .then(loadController) .catch(reportError)&#125;// 새 페이지 요청loadContents(&#x27;/where/are/you&#x27;); 글을 읽다보면, 이 코드가 나중에 어떻게 바뀌는지 보게 될 것이다. 실제 코드는 이보다 훨씬 여러 상황을 고려했고, pre, post 등의 Hook 과 Attribute-Auto-Event-Bind 기능이 붙어있지만 뭐 이 글에선 중요한게 아니니 개별 파일을 일일히 컴파일이 상황에서 나는 ES6의 매력에 빠져 Babel 을 사용하여 ES6/React 를 적용하기 시작한다. 처음에는 Webpack 이 그리 정돈되지도 않았고, 학습이 좀 어려워(라는 핑계로) 개별 파일을 jsx 컴파일러 (Facebook 에서 제공하던 ES6/React 컴파일러. 지금은 Deprecated 되었다) 를 사용하였다. 그리고 일일히 파일 하나하나를 트랜스파일하여 js 를 두개를 커밋하였는데, 이 과정에서 일어나는 비효율성은 엄청났지만 마침내 작성된 ES6/React 의 코드의 결과물은 나에게 멋지게만 보였다. IntelliJ File Watcher!하지만 매번 커맨드라인으로 일일히 컴파일하는 작업은 고역이었고, 실수라도 컴파일하지 않은 코드를 올리는 순간 클라이언트에서 사용할 수 없는 문법 오류가 속출했다. 실수로 올라간 트랜스파일되지 않은 상태로 ES6 이나 JSX 문법을 사용한 파일을 구동하면 브라우저가 이해하지 못하는 것이었다. 이런 도중에 팀 동료의 도움을 받아 Intellij 의 File Watcher를 추가하여 코딩과 동시에 Transpiling 되는 기능을 적용했다. 별도로 커맨드라인을 수행할 필요도, js 파일을 생성할 필요도 없이 jsx 파일만 코딩하면 자동으로 js 파일이 트랜스파일링되어 생기는 점은 너무 편했고, 이내 이 툴로 드디어 production 에 몇몇 기능을 개발하여 적용하게 되었다. 하지만 이건 불행의 전주곡의 시작이었다. 괴롭다.. 한계가 매우 빠르게 느껴졌다.크게는 다음과 같은 것들이 막 앞통수 뒤통수를 서라운드로 타격하기 시작했다. 그 중 크리티컬 히트를 자주 터뜨리는 녀석들은 다음과 같았다. 개별 컴파일로 인한 기반 코드가 모든 파일에 삽입. (modules, createClass 등의 유틸성 코드 등) OS 및 로컬 Babel, Jsx 컴파일러 버전, Babel 플러그인 설정마다 미묘하게 다른 코드 생성 컴파일 된 파일을 실수로 Commit 하지 않으면 장애로 연결되는 등의 소스파일 이중관리 다량의 파일 변경 이력을 pull, checkout 등을 통해 겪을 경우 intellij 가 file watcher 과부하로 intellij 가 수분(심하면 5분이상)정도 멈춤 이대로는 더이상 개발이 힘들어졌고, 나는 결국 애써 외면하던 외부 Source to Source Compile 도구를 찾게 되었다. Webpack &amp; Browserify정확히 말하면 Source to Source Compiler 를 사용한 번들 도구 (bundle tool)를 찾았다. 위의 크리티컬한 이슈를 처리하기 위해서는 어쩔 수 없이 source 전체적인 번들 및 변환이 필요했기 떄문이다.또한 Intellij 의 File Watcher 가 지원하던 개발의 편의성 또한 필요했다 소스를 고칠때마다 매번 수동으로 컴파일하기는 너무 번거로웠다. 기본적인 Source to Source Compile 이 동작하고, 번들링 기능에, 가급적 소스를 고칠 때 자동으로 백그라운드에서 시스템이 자동으로 최신 내역을 Compile 하는 Watch 기능은 없어서는 안됐다. 찾아보니 두개가 있었다. Webpack Browserify 이 둘 관련으로 좋은 글 하나 링크한다.Browserify VS Webpack - JS Drama BrowserifyBrowserify 는 NPM 생태계의 모듈들을 브라우저에서 사용하는 것을 목표로 하는 도구다. 코드를 CommonJS 문법으로 작성해두면 npm 의 모듈들을 바로 브라우저 환경에서 돌려볼 수 있고, Watchify, Factor Bundle, deAMDFy 등의 도구로 파일 감시, 멀티 번들, AMD 지원등이 가능하다. 제일 좋은 점은 아주 적은 설정으로 바로 시작할 수 있다는 점이지만, 다른 Task 도구를 사용하지 않으면 사용이 조금 불편할 수 있어서 추가적인 Task Runner(주로 Gulp) 설정이 들어가게 된다. WebpackWebpack 은 Browserify 와는 다르게, 혼자서 할 수 있는 일이 거의 없다. 대부분 별도의 loader 라 부르는 모듈과 그 모듈을 적용할 대상을 지정해주는 설정을 같이 요구한다. commonjs 를 사용하려면 babel-loader 를 설치하고 설정해야 하며, React 를 사용하려면 babel-loader 의 설정에 react 관련 플러그인의 추가 및 설정이 필요하다. 다만 webpack 은 정적 리소스까지도 다룰 수 있는 loader 를 제공하며, hot-loading 등의 강력한 기능까지 붙여볼 수 있다. 별도 Task Runner (gulp 등) 없이 혼자서도 전부 할 수 있는 것도 장점이다. 인생은 실전선택에는 고민자체가 필요없었다. NodeJS 모듈을 만들것도 아니고, 정적 파일 관리까지 지원하며 부가적인 기능들이 더욱 막강한 Webpack 으로 정했다. 먼저 간단한 Webpack 을 학습하기 위해 bolierplate 코드를 받아서 이리저리 변경해보았다. boilerplate 역시나 모든 툴들이나 신기술이 그렇듯 hello world 수준의 사용법은 너무나 간단하고 쉬웠다. 대충 학습을 끝내고 바로 프로젝트에 적용해보기 시작했다. 예상대로 실제 프로젝트,그리고 이제 어느정도 커져버려서 꽤나 규모가 있는 프로젝트에는 문서대로의 친절함따윈 없었다. 나는 야생의 아마존을 서성이는 모든게 두려운 새끼 고양이가 된 느낌을 받기 시작했다. 기존에 사용하던 AMD 툴인 requirejs 를 너무 헤비하게 쓰고 있었던 것이다. path 의 정리도 엉망에 controller 의 로딩이 순식간에 전부 작업분으로 남아버렸고, commonjs, amd, es6 모듈은 서로 충돌하기 바빴다.모든게 어우러져 새빨간 컴파일 오류가 작렬했다. 내용이 길어져 2부로 나눈다.","pubDate":"Wed, 03 May 2017 14:30:17 GMT","guid":"https://blog.javarouka.me/2017/05/03/convert-legacy-to-webpack-bundle-1/","category":["Tech","javascript","Handlebars","webpack","개고생"]},{"title":"넌 Redux 가 필요 없을지도 몰라","link":"https://blog.javarouka.me/2017/03/18/YouMightNotNeedRedux/","description":"Dan Abramov 의https://medium.com/@dan_abramov/you-might-not-need-redux-be46360cf367를 번역한 글입니다. You Might Not Need ReduxPeople often choose Redux before they need it.사람들은 종종 Redux 가 필요하기도 전에 선택한다. “What if our app doesn’t scale without it?”앱을 Redux 없이 확장하려면 어떻지? Later, developers frown at the indirection Redux introduced to their code.나중에, 개발자들은 자신의 코드에 Redux 가 도입되어 있는 것들에 눈살을 찌푸리게 된다. “Why do I have to touch three files to get a simple feature working?”왜 간단한 기능 개발 작업에 세개의 파일을 손대야 하는거야? Why indeed!왜 이런! People blame Redux, React, functional programming, immutability, and many other things for their woes, and I understand them.사람들은 Redux, React, 함수형 프로그래밍, 불변성 그리고 많은 다른 것들이 나에게는 고통이라며 비난하고, 난 그들을 이해한다. It is natural to compare Redux to an approach that doesn’t require “boilerplate” code to update the state, and to conclude that Redux is just complicated.“보일러 플레이트” 코드를 사용하지 않고 state 를 갱신하는 방법을 비교해본 뒤 Redux 는 단지 복잡하다고 여기는건 당연하기 때문이다. In a way it is, and by design so.어떤 면에서 보면 그건 의도된 설계다. Redux offers a tradeoff. It asks you to:Redux 는 트레이드오프를 제공한다. 그건: Describe application state as plain objects and arrays. 일반 객체와 배열로 어플리케이션 상태를 표현한다. Describe changes in the system as plain objects. 일반 객체들로 시스템의 변경을 표현한다 Describe the logic for handling changes as pure functions. 변경 처리를 순수 함수를 사용한 로직으로 표현한다. None of these limitations are required to build an app, with or without React.React 를 사용하든 안하든 이러한 제약들은 앱을 만들때 요구되는 게 아니다. In fact these are pretty strong constraints, and you should think carefully before adopting them even in parts of your app.실제로 이건 정말로 강력한 제약들이며 앱의 일부에 작업할때도 주의깊게 생각해야만 한다. Do you have good reasons for doing so?그런데, 그렇게 할 만한 이유가 있나? These limitations are appealing to me because they help build apps that:이런 제약들은 다음과 같은 앱을 빌드할 때 도움을 주기 때문에 나에겐 매력적이다 Persist state to a local storage and then boot up from it, out of the box. 앱 상태를 로컬스토리지에 유지하고, 상자 밖에서 시작 Pre-fill state on the server, send it to the client in HTML, and boot up from it, out of the box. 서버에서 상태를 미리 채우고, HTML 안에 담아 클라이언트에 보내, 상자 밖에서 시작. Serialize user actions and attach them, together with a state snapshot, to automated bug reports, so that the product developers can replay them to reproduce the errors. 유저 액션을 시리얼라이즈해서 상태 스냅샷과 함께 자동화된 버그 리포트에 첨부해서, 프로덕트 개발자들이 에러를 재현을 되돌려봄 Pass action objects over the network to implement collaborative environments without dramatic changes to how the code is written. 액션 네트워크를 통해 액션 객체를 넘겨봄으로써 코드 작성 방법을 드라마틱하게 변경하지 않고 협업 환경 구현 Maintain an undo history or implement optimistic mutations without dramatic changes to how the code is written. 드라마틱하게 코드 작성 방법을 변경하지 않고 실행 기록 유지나 낙관적인 가변성을 구현 Travel between the state history in development, and re-evaluate the current state from the action history when the code changes, a la TDD. 개발에서 상태 이력을 여행면서 코드가 바뀌면 액션 이력에서 현재 상태를 계산해봄. TDD로. Provide full inspection and control capabilities to the development tooling so that product developers can build custom tools for their apps. 개밸 도구에 전체 검사 및 제어를 제공함으로써 제품 개발자가 앱용 커스텀 도구를 개발할 수 있음. Provide alternative UIs while reusing most of the business logic. 대부분의 비즈니스 로직을 재사용하며 다른 UI 를 제공 If you’re working on an extensible terminal, a JavaScript debugger, or some kinds of webapps, it might be worth giving it a try, or at least considering some of its ideas (they are not new, by the way!)확장형 터미널, 자바스크립트 디버거, 그리고 일부 앱에서 작업을 한다면 이걸 시도해볼만 한 가지가 있고 최소한 아이디어를 고려해볼만 하다. (이건 새로운 것이 아니다!) However, if you’re just learning React, don’t make Redux your first choice.하지만 React 를 배우는 중이라면 Redux 를 처음부터 선택하지 마라. Instead learn to think in React.리액트로 생각하는 법을 대신 배워라. Come back to Redux if you find a real need for it, or if you want to try something new. But approach it with caution, just like you do with any highly opinionated tool.Redux 가 필요한 진짜 이유를 찾거나, 새로운 무언가를 시도하려고 할때 Redux 로 돌아오라. 그러나 매우 조심스러운 도구를 사용하듯이 주의해서 접근해라. If you feel pressured to do things “the Redux way”, it may be a sign that you or your teammates are taking it too seriously. It’s just one of the tools in your toolbox, an experiment gone wild.“Redux 방식” 으로 일해야 한다는 것에 부담을 느낀다면, 너나 너의 동료들은 그걸 매우 심각하게 받아들인다는 신호일 수 있다. Redux 는 단지 도구 상자의 거친 실험 도구 중 하나일 뿐이다. Finally, don’t forget that you can apply ideas from Redux without using Redux. For example, consider a React component with local state:마지막으로, Redux를 사용하지 않고 Redux 의 아이디어를 적용할 수 있다는 것을 잊지 마라. 예를 들면 로컬 상태의 React 컴포넌트를 고려해보자: 123456789101112131415161718192021222324252627import React, &#123; Component &#125; from &#x27;react&#x27;;class Counter extends Component &#123; state = &#123; value: 0 &#125;; increment = () =&gt; &#123; this.setState(prevState =&gt; (&#123; value: prevState.value + 1 &#125;)); &#125;; decrement = () =&gt; &#123; this.setState(prevState =&gt; (&#123; value: prevState.value - 1 &#125;)); &#125;; render() &#123; return ( &lt;div&gt; &#123;this.state.value&#125; &lt;button onClick=&#123;this.increment&#125;&gt;+&lt;/button&gt; &lt;button onClick=&#123;this.decrement&#125;&gt;-&lt;/button&gt; &lt;/div&gt; ) &#125;&#125; It is perfectly fine as it is. Seriously, it bears repeating.완벽하게 좋다! 훌륭하게 반복성을 유지한다. (역자 주석: setState 는 객체 외에도, 함수를 받을 수 있습니다. 이 경우 기존의 비동기성 업데이트 대신에 setState 에 전달한 함수들은 큐로 쌓이고 첫 처리된 상태가 두번째 처리에 전달됩니다.) Local state is fine.로컬 상태는 좋다! The tradeoff that Redux offers is to add indirection to decouple “what happened” from “how things change”.Redux 가 제공하는 트레이드오프는 “상황이 어떻게 변하는지” 에서 “발생한 것” 을 분리하기 위한 간접참조를 추가하는 것이다. Is it always a good thing to do? No. It’s a tradeoff.항상 좋은 걸까? 아니다. 그건 트레이드오프다. For example, we can extract a reducer from our component:예를 들면 컴포넌트에 reducer 를 추출할 수 있다 123456789101112131415161718192021222324252627282930313233343536373839import React, &#123; Component &#125; from &#x27;react&#x27;;const counter = (state = &#123; value: 0 &#125;, action) =&gt; &#123; switch (action.type) &#123; case &#x27;INCREMENT&#x27;: return &#123; value: state.value + 1 &#125;; case &#x27;DECREMENT&#x27;: return &#123; value: state.value - 1 &#125;; default: return state; &#125;&#125;class Counter extends Component &#123; state = counter(undefined, &#123;&#125;); dispatch(action) &#123; this.setState(prevState =&gt; counter(prevState, action)); &#125; increment = () =&gt; &#123; this.dispatch(&#123; type: &#x27;INCREMENT&#x27; &#125;); &#125;; decrement = () =&gt; &#123; this.dispatch(&#123; type: &#x27;DECREMENT&#x27; &#125;); &#125;; render() &#123; return ( &lt;div&gt; &#123;this.state.value&#125; &lt;button onClick=&#123;this.increment&#125;&gt;+&lt;/button&gt; &lt;button onClick=&#123;this.decrement&#125;&gt;-&lt;/button&gt; &lt;/div&gt; ) &#125;&#125; Notice how we just used Redux without running npm install. Wow!npm install 실행 없이 Redux 를 사용한 것에 주목해보라! 와우! Should you do this to your stateful components? Probably not.너의 “stateful 컴포넌트” 에 이 작업을 해야 할까? 아마 아닐거다. That is, not unless you have a plan to benefit from this additional indirection.그건 이 간접적인 참조의 추가에서 얻을 계획이 없다면 아니다. Having a plan is, in the parlance of our times, the 🔑.플랜을 가지는 건 우리 즐거운 시간이다. 🔑. Redux library itself is only a set of helpers to “mount” reducers to a single global store object.Redux 라이브러리는 단지 하나의 전역 store 객체에 reducer들을 탑재한 헬퍼 셋이다. You can use as little, or as much of Redux, as you like.넌 적게 혹은 많게 좋을대로 Redux 를 사용할 수 있다. But if you trade something off, make sure you get something in return.하지만 무언가를 교환한다면, 그 대가로 무언가를 받아라.","pubDate":"Fri, 17 Mar 2017 15:00:00 GMT","guid":"https://blog.javarouka.me/2017/03/18/YouMightNotNeedRedux/","category":["Tech","Translate","javascript","ecmascript","redux","react"]},{"title":"비동기와 Promise #3","link":"https://blog.javarouka.me/2016/11/12/javascript-async-promise-3/","description":"전 포스트 에 이은 글이다. 이 포스트의 예제 코드는 ES6 으로 작성되었습니다. 뒤돌아보기전 포스트들에서 비동기의 대략적 흐름과 Promise 의 기본 동작에 대해 다루다가 잠깐 언급한 내용이 있다. Timer 와 Promise 를 비교하면서 Timer 함수보다 Promise 가 더 우선권이 있다고 했었다. 실제로 Promise 다른 javascript 일반적인 비동기 수행보다 앞선 비동기적 우선권을 가진다. 이것에 대해 이해하려면 HTML Living Standard 에 새로 추가된 Micro Task 에 대해 좀 더 알 필요가 있다. Task 와 MicroTask 에 대해 자세히 알아보자 TaskEvent Loop 는 하나 혹은 그 이상의 Task Queue 라는 부르는 Task 가 순서대로 정렬된 List 를 가진다. Task 는 다음과 같은 여러 작업들의 모음이다. 스크립트 실행 이벤트 HTML 파싱 콜백 Fetch, Ajax DOM 조작 javascript 를 실행하는 것도 태스크, HTML 파싱, Timer, DOM 조작 등이 전부 Task 이다. javascript 가 코드 블럭을 수행하면 call stack 에 함수 호출을 쌓으며 실행해나가는 Task 를 수행하고, 도중 Ajax, DOM 조작을 만나면 Task Queue 에 넣고 계속 루프 작업을 진행하게 된다. 타이머를 만나면 바로 Task Queue 에 추가되지 않고 지정된 시간 후 Task Queue 에 추가된다. 삽입된 Task 는 다음 Event Loop, 혹은 지정된 시간, 이벤트 트리거에 의해 다시 수행된다. 비동기와 Promise #1 에서 다뤘듯 특별할게 없는 동작이다. Micro TaskMicro Task 는 새로운 Task 로서 기존의 Task 에 영향을 받지 않고 Async 로 빠르게 수행되는 Task 들이다. process.nextTick Promise Object.observe MutationObserver Micro Task 는 현재 실행중인 Task 의 실행이 종료된 뒤 바로 다음에 일어날 일들이 쌓이는 곳이다. 일반적인 구현으로는 각 Task 가 끝나거나, Event Loop 의 시작과 끝에서 체크된다. 이 작업을 표준 문서에서는 Micro Task checkpoint 라고 정의하고 있다. Task 의 종료와 루프의 시작과 끝에서 수행되기에 일반적인 Task 의 실행이 다음 루프에서 처리되는 것보다 우선권이 있다. HTML 스펙의 Micro Task checkpoint - perform a microtask checkpoint 의 설명을 대략 요약하면 다음과 같다. 중간에 여러 개념들이 등장하지만, Micro Task 에 초점을 맞춰 요약해보면 다음과 같은 흐름이다. Micro Task checkpoint 수행 핸들링 : 이벤트 루프의 Micro Task 큐가 비어 있으면 완료 단계로 Event Loop 의 Micro Task 큐 대기열에서 가장 오래된 Micro Task 를 선택 Event Loop 의 현재 실행중인 작업 을 3번 단계에서 선택한 작업으로 설정 실행 : 선택한 Task 를 실행. Event Loop 의 현재 실행중인 작업을 null 로 설정 위의 단계에서 실행 된 Micro Task 를 큐에서 제거하고 Micro Task 큐 처리 단계 (2번 단계) 로 완료 : Micro Task checkpoint 완료 아래는 위의 흐름을 개념적 코드로 표현해보았다. (실제 구현이 이렇다는건 절대 아니다) 123456789101112131415161718function performMicroTaskCheckPoint(eventLoop) &#123; // 재진입성(reentrant invocation) 방지를 위한 플래그 프로퍼티 // http://sunyzero.tistory.com/97 while(eventLoop.microCheckPointFlag) &#123; if(eventLoop.microTaskQueue.length &lt; 1) &#123; // 2 eventLoop.microCheckPointFlag = false; break; &#125; const microTask = eventLoop.microTaskQueue.shift(); // 3 eventLoop.setCurrentRunngingTask(microTask); // 4 eventLoop.executeCurrentTask(); // 5 eventLoop.setCurrentRunngingTask(null); // 6 &#125;&#125; 여기서 알 수 있는건 Micro Task 큐가 비어있지 않다면 Task 가 비어있을 때까지 무한히 핸들링 -&gt; 실행 단계를 반복하도록 되어 있다는 점이다. 만일 Micro Task 에서 다른 MicroTask 를 등록하는 작업을 반복하면 다음의 이벤트 루프는 수행되지 못할 수도 있다는 뜻이다. Micro Task 과다 중첩 예제테스트 코드로 알아보자. 사용할 Micro Task 는 이 시리즈에서 한창 다루는 Promise 를 사용한 예제이다. 먼저 사용할 함수 두개를 만들자 12345678910111213// Promise 를 받아 상태값에 1을 증가시키고,// resolved Promise 를 반환하는 함수const doIncrementChain = promise =&gt; &#123; return promise.then(val =&gt; &#123; console.log(&#x27;Promise value&#x27;, val); return Promise.resolve(++val) &#125;);&#125;;// 제일 빠르게 수행되는 Timer 를 예약하는 함수const putImmidiateTimer = fn =&gt; &#123; setTimeout(fn, 0);&#125;; 위 두 함수를 사용해서 예제 코드는 다음과 같다. 123456789101112131415// Timer 를 예약한다.putImmidiateTimer(_=&gt; console.log(&#x27;I am Timer!&#x27;));// Promise 생성let promise = new Promise(resolve =&gt; &#123; console.group(&#x27;promise start~&#x27;); return resolve(1);&#125;);// loopCount 만큼 순회하며 Promise 를 연결한다.let loopCount = 100000;while(loopCount--) promise = doIncrementChain(promise);// 완료되면 완료로깅을 출력하는 Promise를 연결한다.promise.then(_=&gt; console.groupEnd(&#x27;promise executed!&#x27;)); 이 코드는 위의 스펙대로 모든 Promise 가 추가한 MicroTask 를 전부 소비하고 난 뒤에야 타이머 작업이 시작된다. 혹 사양이 낮은 PC나 환경에 따라서는 PC가 멈추거나 오류를 낼 수 있다.(NodeJS 의 경우 아마 1000 번의 Micro Task 큐 작업이 한계라고 알고 있다) 이 블로그를 작성중인 작업 컴퓨터의 사양이 좀 낮은 관계로 10번만 수행시켰다. (Chrome 브라우저 콘솔) 실행 결과를 보았듯이 Timer 작업은 앞선 Micro Task 인 Promise 에 밀려 제일 나중에 실행된다. 루프 카운트를 10000 으로 늘려도 결과는 같다.(다만 과하게 늘릴 경우 수행이 늦어지거나 엔진 다운이 있을 수 있다.) 결론비동기 및 Promise 포스팅이 이걸로 끝났다. 비동기에 대해서는 여기 써놓은 내용 이상으로 다룰 내용이 너무 깊고 많다. 노오력이 부족한 관계로 새로운 사실을 알게 될 때마다 포스트를 수정해나갈 생각이다. 참고 비동기와 Promise 1 비동기와 Promise 2 비동기와 Promise 3 C언어:reentrant (재진입성) 함수와 쓰레드안전(MultiThread-safe) BsideSoft 공식 블로그 # 동기화 vs 비동기화 1 BsideSoft 공식 블로그 # 동기화 vs 비동기화 2 BsideSoft 공식 블로그 # 동기화 vs 비동기화 3 NHN Enter # 자바스크립트와 이벤트 루프 2ality # ECMAScript 6 promises - foundations jakearchibald’s blog # Tasks, microtasks, queues and schedules","pubDate":"Fri, 11 Nov 2016 15:00:00 GMT","guid":"https://blog.javarouka.me/2016/11/12/javascript-async-promise-3/","category":["Tech","javascript","ecmascript","promise","async"]},{"title":"비동기와 Promise #2","link":"https://blog.javarouka.me/2016/11/09/javascript-async-promise-2/","description":"전 포스트 에 이은 글이다. 그동안 우리가 해오던 미래일의 처리온라인 쇼핑을 하다보면 주문서에 택배기사에게 전할 말을 기록하는 공간이 있다. 보통 그곳에는 이렇게 적는 사람이 많을것이다 (나는 대부분 아래와 같이 적어둔다.) 택배 완료전에 전화주세요. 지금은 택배가 오지 않았지만 택배가 올 미래 에 전화해달라 는 처리를 부탁하고 있는 것이다. 물건을 주문한 사람은 택배가 올 때까지 마냥 기다릴 필요가 없고 다른일을 하다가 택배 도착 전 오는 전화를 받을 수 있다. 택배를 받으려고 택배직원을 아무것도 안하고 마냥 기다리려는 사람은 없을것이다 12var goods = goodsOnDelivery(); // 배달될 때까지 기다려야한다!enjoyLife(goods); // 만일 배달되지 않는다면 인생을 못즐길 것이다. 콜백함수보통 이런 경우에는 비동기 함수와 콜백을 같이 쓴다. 아래와 같은 방식이다 12345// 배달될 경우에 수행할 작업을 콜백으로 전달해둔다.goodsOnDeliveryAsync(function(goods) &#123; // 콜백! enjoyLifeByGoods(goods);&#125;);enjoyLifeByExistsGoods(); 배송을 시키고, 다른걸로 놀다 (enjoyLifeByExistsGoods) 가 배송되면 배송된 걸로 노는 것 (enjoyLifeByGoods) 이다. 물론 실행 순서는 goodsOnDeliveryAsync -&gt; enjoyLifeByExistsGoods -&gt; enjoyLifeByGoods. 콜백의 문제점여기서 조금 더 생각해보자. goodsOnDeliveryAsync 는 자신이 맡은 배송 외에도, 추가적으로 자신과는 전혀 관계가 없는 콜백 함수를 처리할 임무를 맡고 있다. 콜백으로 전달된 인자의 유효성 검증은 물론, 예외가 나든 오류가 나든 반드시 콜백을 호출해줘야 한다. 또, 콜백을 다수 처리해야 할 경우에도 문제가 된다. 이렇게 콜백을 지정할수도 있다. 하지만 별로 좋아보이진 않는다. 12345asyncFunc(function(goods) &#123; callback1(goods); callback2(goods); callback3(goods);&#125;); 물론 콜백안에 함수 셋을 전달할 수도 있지만 가독성 면에서 그리 좋은 방법은 아니다. 게다가, callback1 에서 예외가 던져질 경우 나머지 콜백들은 수행조차 하지 못한다. 더 심각한건, 만일 콜백을 받는 함수에서 어떤 문제가 발생하여 콜백을 실행하지 않을수도 있다. 위에서 본 goodsOnDeliveryAsync 함수는 내가 만든 함수이기에 문제가 발생해도 수정이 가능하지만, 만일 타 팀이나 외부 라이브러리의 콜백을 사용한다면 그 함수를 신뢰할 수 있는지는 고민해볼 문제다. 콜백이라는 것은 결국 내 코드가 다른 로직에서 수행되는 조그만 제어의 역전 (IoC) 이 일어난다고 보면 된다. 타겟 함수에 복수의 핸들러 전달이 깔끔하지 못하다. 타겟 함수에서 자신과는 관계없는 콜백 함수의 유효성 체크를 담당한다. 타겟 함수가 어떤 이유로 콜백을 한번도 호출하지 않을 수 있다. 타겟 함수가 어떤 이유로 콜백을 여러번 호출할수도 있다. 타겟 함수에서 발생하는 오류 처리 시 콜백을 주게 된다면 서로간 코드가 수정된다. 이런걸 방지하기 위해 실행할 함수는 자신의 로직 외에도, 위의 내용을 전부 방어할 자신의 실제 업무와는 관계없는 코드들로 범벅이 될 것이다. 이럴땐 앞서간 선배들은 관심사의 분리 (참고) 를 이야기한다. 서로의 두 흐름 사이에 메신저 역할의 인터페이스나 매니저를 두는 방향으로 한번 구현해보자 수도 코드로는 대충 이런 식으로 1실행기(실제로직).인터페이스(콜백).에러인터페이스(에러핸들러) 아래는 구현 코드. 뭔가 장황해 보이고 장점이 없어 보이지만, 이 코드는 한번 잘 구현해둘 경우 다시는 볼일이 없으니 괜찮다(?). 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152/** * @param job 비동기 함수 * @return callback 등록 인터페이스 */function AsyncRunner(job) &#123; var ms = 1000; var future = []; var errorHandler = function(err) &#123;&#125; var executed = false; // 비동기 함수에서 콜백을 실행한다. // 유효성 검사를 할 필요가 없이 확실한 함수를 전달한다. job(function(data) &#123; // 이미 수행되었거나 실행할 작업이 없어도 중단한다. if(executed || !future.length) return; try &#123; // Go. future.forEach(function(job) &#123; job(data); &#125;); &#125; catch(error) &#123; // 에러가 나면 지정된 에러 핸들러를 실행하고 중단한다. return errorHandler(new Error(error)); &#125; finally &#123; executed = true; &#125; &#125;); return function(goods) &#123; return &#123; // 미래에 처리할 작업을 등록하는 메서드를 반환한다 ok: function(job) &#123; if(job) future.push(job); return this; &#125;, // 에러 핸들러를 등록한다. error: function(_errorHandler) &#123; errorHandler = errorHandler || _errorHandler; return this; &#125; &#125; &#125;&#125; 이제 사용해보자 12345// 러너로 실행한다!new AsyncRunner(goodsOnDeliveryAsync) .ok(enjoyLifeByGoods) .ok(presentGoods) .error(crySadLife) asyncRunner 함수의 신뢰성만 유지되는 한 타겟 함수와 콜백의 실행 로직은 서로 겹치지 않게 된다. 제어 역전 포인트를 아예 분리해버렸고, 한번 실행된 뒤 다시 콜백을 수행할일도 없이 방어로직을 넣어두었다. 코드가 읽기 간결해지는건 덤이다. 아, 위 코드에서는 한번도 실행하지 않음 에 대해서는 처리하지 않았는데, ok, error 이외에 timeout 같은 인터페이스를 공개해서 내부적으로 타이머를 돌려 executed 변수를 갱신하면서 오류 핸들러를 호출해주는 식으로 구현하면 될 것이다. 그래서 Promise 는 뭔데?사설이 길었다. 이제부터 제목에 맞는 내용이다. Promise 는 JavaScript 에서 여러 방법으로 수행하던 비동기 처리에 대한 표준이다. 지금 (now) 은 아니지만 나중 (future) 에 처리될 것으로 생각되는 처리를 표현할 수 있다. Promise 는 꽤 단순한(해 보이는) Promise/A Plus 스펙에 맞춰 구현되어 있으며, ES2015 에서 표준으로 정해지기 전에도 여러 오픈소스 라이브러리 들이 이 표준을 구현하였고 사용되는 것들도 꽤 많다. ES2015 에서는 언어 자체에 Promise 를 Native 로 지원하게 되어서 위의 라이브러리를 쓰지 않고도 편하게 Promise 를 사용할 수 있고, 추가적으로 위 라이브러리를 써서 유틸성도 얻을 수 있다. 기본기본 사용법은 다음과 같다 1new Promise([FactoryFunctionExpression]) 1234567891011// FactoryFunctionExpressionvar promise = new Promise(function(resolve, reject) &#123; // implementation ... // call resolve([val]) or reject([val])&#125;);promise.then(function(fulfilledValue) &#123; // ... fulfilled callback ...&#125;)promise.catch(function(rejectedValue) &#123; // ... reject callback ...&#125;); 의 방식이다. example예제는 이런 식이다 123456789101112131415var promise = new Promise(function(resolve, reject) &#123; resolve(&#x27;약속해줘~&#x27;);&#125;);promise.then(function(val) &#123; console.log(val); // 약속해줘~&#125;);var promise = new Promise(function(resolve, reject) &#123; reject(&#x27;약속은 어기라고 있는 것&#x27;);&#125;);promise.catch(function(val) &#123; console.log(val); // 약속은 어기라고 있는 것&#125;); FactoryFunctionExpression 에는 두가지 인자가 오는데, 첫번째 인자는 Promise 의 상태를 resolved 로 바꾸는 함수, 두번째 인자는 상태를 rejected 로 바꾸는 함수가 온다. 이 두 콜백에는 상태값을 인자로 줄 수 있으며 그 뒤의 then 이나 catch 등의 메서드의 처리 함수들이 그 값을 인자로 받는다. 인자는 하나만 허용되며, 두번째 인자는 무시되니, 다수의 인자를 주고 싶다면 Object 타입을 사용 해야 한다. then, catch위에서 설명했듯이, Promise 생성자의 첫번째 인자는 함수이고 Promise 의 프로토타입은 다음과 같다. then은 인자를 두개 받는다. 첫번째 인자는 resolved 상태에 대한 상태값을 받아 처리하는 콜백함수이고 두번째 함수는 rejected 상태에 대한 상태값을 받아 처리하는 콜백 함수이다. catch 는 인자를 하나만 받는데, rejected 상태에 대한 상태값을 받아 처리하는 콜백 함수가 인자가 된다. 12somePromise.then(null, function() &#123;&#125;)somePromise.catch(function() &#123;&#125;) 단축 표현이라고 보면 정확하다. 실전 예제일정량의 딜레이 뒤에 수행되는 미래를 나타내는 Promise 을 만들어보자 12345678910111213141516171819202122/** * ms 만큼 지연된 Promise 를 반환 * * @param ms 딜레이 밀리초 * @return tid 타임아이디, ms 대기시간 */function throttle(ms) &#123; // Promise 를 생성한다 return new Promise(function(resolve) &#123; // 주어진 ms로 Timer 를 예약한다 var tid = setTimeout(function() &#123; // 대기가 끝나면 resolve 로 Promise 의 resolved 상태를 바꾸고 변화를 알림 resolve(&#123; tid: tid, // Timer 아이디 ms: ms // 대기시간 &#125;); &#125;, ms); &#125;);&#125; 주석으로 설명은 대체한다. 사용은 다음과 같다. 123throttle(1000 * 60).then(function() &#123; console.log(&#x27;God is dead. - Friedrich Wilhelm Nietzsche&#x27;)&#125;); 변하지 않아!Promise 는 한번 상태가 결정되면 절대 변하지 않는다. resolve 나 reject 함수를 호출하기 전을 pending 상태라고 한다. 이후 resolve 혹은 reject 가 수행되면 resolved 혹은 rejected 상태로 변한다. 한번 상태가 정해지면 다른 상태로는 변하지 않는다. 다시 then 을 호출한다고 해서 전 pending 상태의 로직이 다시 실행되거나 하지도 않는다. 12345678var outer = 1;var promise = new Promise(function(resolve) &#123; resolve(++outer);&#125;);promise.then(console.log); // 2promise.then(console.log); // 2 몇번을 호출해도 결과는 같다. 한번 정해진 상태는 그대로 유지된다. 이건 기존의 콜백 로직과는 확실히 구분되는 강력함이라고 볼 수 있다. 또한, 한번 resolved, rejected 상태로 변경된 뒤에는 다른 상태 변환 시도는 무시된다. 123456789101112// 일부러 두 콜백을 모두 호출해본다.var promise = new Promise(function(resolve, reject) &#123; // resolved 로 상태가 변경됨. resolve(&#x27;완료되었어!&#x27;); // resolved 된 상태에서 reject 를 호출한다. reject(&#x27;이런! 벌써 완료되었나!&#x27;);&#125;);promise.then(console.log); // 수행된다promise.catch(console.log); // 수행되지 않는다 이 reject 를 먼저 호출하고 resolve 를 호출해도 마찬가지다. 아주 중요한 개념이니 잘 알아두자. 여유로운 비동기 실행Promise 의 then 과 catch 등의 콜백은 기본적으로 비동기로 실행 된다. 다음 예제를 보자 12345678console.log(&#x27;시작합니다&#x27;);new Promise(function(resolve) &#123; console.log(&#x27;Promise 시작합니다&#x27;); resolve(&#x27;Promise 수행되었습니다&#x27;) &#125;).then(console.log);console.log(&#x27;종료되었습니다&#x27;); 실행 순서는 어떻게 될까? 답을 보기 전 5초만 생각해보는걸 추천한다. … … … … … 답은 아래와 같다. 1234시작합니다Promise 시작합니다종료되었습니다Promise 수행되었습니다 그럼 Timer 함수들과는 어떨까? 12345678910111213console.log(&#x27;시작합니다&#x27;);console.log(&#x27;Timer 설정합니다&#x27;);setTimeout(function() &#123; console.log(&#x27;Timer 수행되었습니다&#x27;);&#125;, 0);new Promise(function(resolve) &#123; console.log(&#x27;Promise 시작합니다&#x27;); resolve(&#x27;Promise 수행되었습니다&#x27;) &#125;).then(console.log);console.log(&#x27;종료되었습니다&#x27;); 이 문제는 배경 지식이 없으면 예측이 어렵다. 답은 다음과 같다. 123456시작합니다Timer 설정합니다Promise 시작합니다종료되었습니다Promise 수행되었습니다Timer 수행되었습니다 같은 한번의 수행 프레임내에서 예약되는 Timer 와 Promise 는 언제나 Promise 의 실행이 우선되고, Timer 는 나중이 된다. Timer 에 아주 짧은 시간을 설정해도 소용없다. 이 건에 대해서는 다음 포스트 에서 다룬다. 지금은 Timer 보다 Promise 의 콜백이 내부적으로 실행 우선권을 가지고 있다고만 생각하자. 체이닝!Promise 의 then 과 reject 메서드는 체이닝 메서드 로서 다음과 같이 코딩할 수도 있다 1234567somePromiseInstance .then(function(data) &#123; // ... fulfilled callback ... &#125;) .catch(function() &#123; // ... reject callback ... &#125;); 중요한 건 then 을 연결할 경우 앞선 promise 의 반환값이 다음 then 의 인자로 전달되며 순차적으로 실행된다. 다음 코드를 보자 12345678910111213new Promise(function(resolve, reject) &#123; resolve(100); // resolved! &#125;) .then(function(value) &#123; // 앞선 결과를 연결한다. return value * 2 &#125;) .then(function(value) &#123; return value - 10 &#125;) .then(function(value) &#123; return value + 60 &#125;) .then(console.log); // 20 then 을 호출한 순서 차례대로 실행되며 이전 then 의 결과를 다음 then 이 받는다. 만일 then 에서 아무것도 반환하지 않을 경우 undefined 가 전달된다. (이걸 자주 잊어 실수하는 프로그래머들이 종종 있다. 잘 기억하자) chaining VS forking메서드 체이닝 시 주의할 점이 있다. 체이닝으로 사용할 때가 있고 사용하지 않아야 할 때가 있다. 아래 예제에서 위 코드와 아래의 코드는 전혀 다른 동작을 유발한다. 123456789101112var promise = new Promise(function(resolve, reject) &#123; resolve(100);&#125;);function pow(val) &#123; return val * val &#125;// CASE 1promise.then(pow);promise.then(pow).then(console.log);// CASE 2promise.then(pow).then(pow).then(console.log); CASE 1 의 코드는 resolved 상태의 값이 한번만 곱해지지만, CASE 2 는 resolved 상태의 값이 두번 곱해지며 전혀 다른 결과를 내놓는다. 단순하지만 종종 헷갈릴 수 있으니 조심하자. 약속에서 다른 약속을 잡을 때재미있는건 반환값이 일반적인 표현식이 아닌 Promise 를 반환할 경우 그 Promise 로 다음 then 값이 대체된다는 점이다. 이걸 활용하면 여러가지 재미있는 일들을 할 수 있다. 앞으로의 글의 이해를 더 돕기 위해 포스트 내에서 계속 사용될 유틸성 함수 두개를 작성하자. 12345678910111213141516171819202122232425262728/** * 지연 함수 * * @param action 실행 작업 함수 * @param ms 작업 지연 밀리초 * @return promise 객체 */function delay(ms, action) &#123; return new Promise(function(resolve, reject) &#123; setTimeout(function() &#123; resolve(action &amp;&amp; action()); &#125;, ms); &#125;);&#125;/** * 로깅 Thunk 함수. * Thunk 는 일단 [아직 평가되지 않은 값(value that is yet to be evaluated)] 을 말한다. * js 에서는 보통 함수로 호출될 코드 조각을 말한다. * * logThunk 함수는 메시지를 받으면 그 메시지를 호출하는 함수를 반환하는 Thunk. * * @param message 로깅할 함수 */function logThunk(message) &#123; return function() &#123; console.log(message); &#125;&#125; delay 함수는 특정 시간이 지난 뒤에 resolve 되는 Promise 를 반환한다. 인자는 두개로 첫번째 인자는 대기시간, 두번째 인자는 선택적으로, 지연 뒤 수행할 함수를 받는다. 이 함수의 실행 결과는 resolve 에 전달된다. logThunk 는 logging thunk 를 반환하는 함수다. 이제 이 두 함수로 Promise resolve 에서 Promise 를 반환하게 해보자. 1234567delay(1000, logThunk(&#x27;첫번째&#x27;)) .then(function() &#123; return delay(1000, logThunk(&#x27;두번째&#x27;)); &#125;) .then(function() &#123; return delay(1000, logThunk(&#x27;세번째&#x27;)); &#125;); 대략 1초 간격으로 첫번째 두번째 세번째 가 콘솔에 출력될 것이다. Promise 를 반환하여 그 뒤의 then 메서드의 컨텍스트가 반환된 Promise 로 교체된 것이다. 비동기 로직인데도, 순차 실행되는 것을 확인할 수 있다. 에러 처리도 간단Promise 의 예외 처리를 하고 싶어서 다음과 같은 코드를 작성했다. 12345678try &#123; delay(1000, function() &#123; throw new Error(&#x27;Oops&#x27;); &#125;);&#125;catch(ex) &#123; console.log(ex.stack); // Oops?&#125; 이 코드의 catch 블럭안의 stack 은 찍히지 않는다. 다음 포스트 의 Task 와 MicroTask 에서 다루겠지만, Promise 는 이런식의 예외 처리는 불가능하다. Promise 는 Timer 와 비슷하면서도 다른 비동기 처리를 하며 Promise 의 콜백들은 그룹화된 Task Queue 로 관리된다. (MicroTask 라고 한다) 실제 Promise 콜백이 실행되는 시점은 try/catch 구문이 끝난 뒤다. 그럼 예외가 날 경우 어떻게 하지?! 걱정하지 않아도 괜찮다. 간단하게 처리할 수 있게 Promise 가 만들어져 있다. Promise 는 흐름 중에 예외가 발생할 시 내부적으로 상태가 rejected 상태로 변경되고 reject 콜백으로 전달된다. 123456789delay(1000, function() &#123; throw new Error(&#x27;Oops&#x27;);&#125;).catch(function(err) &#123; console.log(err.message); // Oops&#125;).then(function() &#123; console.log(&#x27;에러 처리 완료&#x27;);&#125;); catch 를 사용하여 일관되게 에러를 핸들링이 가능하다. catch 콜백도 체이닝되므로 catch 뒤에 then 을 붙이면 안전하게 Promise 체이닝을 이어가는것도 가능하다. 기타 정적 메서드들Promise.resolve([statusValue]);즉발로 상태값이 resolved 으로 설정된 Promise 인스턴스를 생성한다. 1Promise.resolve(100).then(console.log) // 100; 이 함수는 아주 강력한 기능이 있다. Promise.resolve 는 상태값으로 넘기는 인자가 Promise 인 경우 Promise 그대로 반환한다. 1234567var promise1 = new Promise(function(resolve) &#123; resolve();&#125;);var promise2 = Promise.resolve(promise1);console.log(promise1 === promise2); // true. 같다! 아래 코드의 Promise 들은 전부 같다. 123456789var promise1 = Promise.resolve(1);var promise2 = Promise.resolve(promise1);var promise3 = Promise.resolve(promise1);var promise4 = Promise.resolve(promise2);console.log(promise1 === promise2);console.log(promise2 === promise3);console.log(promise1 === promise3);console.log(promise1 === promise4); 이것만으로는 별 특별한게 없다. 하지만 resolve 에는 Promise 정규화 라는 아주 강력한 기능이 있다. Promise 가 아닌 then 함수를 가진 객체 (보통 thenable 이라고 부른다) 를 인자로 넘길 경우 Promise 로 정규화한 뒤 반환한다! 1234567891011121314151617181920var thenable = &#123; then(resolve, reject) &#123; resolve(&#x27;안녕? 난 thenable 이야.&#x27;); &#125;&#125;;Promise.resolve(thenable).then(function(value) &#123; console.log(value); // 안녕? 난 thenable 이야.&#125;);// 심지어 이런 중첩된 thenable 도 정규화해버린다!var nestedThenable = &#123; then(resolve, reject) &#123; return resolve(thenable); &#125;&#125;;Promise.resolve(nestedThenable).then(function(value) &#123; console.log(value); // 안녕? 난 thenable 이야.&#125;); Promise.resolve 내부적으로 주어진 인자에 then 이라는 이름의 메서드가 있는지 판단하여, 있다면 그것을 Promise 로 정규화해버린다. 강력하다. 앞서 Promise 상태는 불변이라고 한거 기억나는가? Promise.resolve 는 그것까지 정규화한다. 123456789101112131415161718// 일반적인 thenable 이다.var thenable = &#123; then(resolve, reject) &#123; // 두 콜백을 전부 호출해버린다. resolve(&#x27;안녕? 난 thenable 이야.&#x27;); reject(&#x27;핫핫핫! 거부한다&#x27;); &#125;&#125;// 하지만 정규화.Promise.resolve(thenable) .then(function(value) &#123; console.log(value); // 안녕? 난 thenable 이야. &#125;) .catch(function(value) &#123; console.log(value); // 실행되지 않는다. &#125;); 만일 어떤 값이 Promise 인지 아닌지 판단할 수 없을 경우, Promise.resolve 로 감싸면 안전하게 그 값을 Promise 취급할 수 있게 해주는 아주 고마운 함수이다. 이 방법은 특히 Promise API 가 나오기 전의 비슷한 Promise 구현들 (jQuery Deferred Object, q, bluebird) 을 Promise 표준에 맞춰 일관되게 사용할때 매우 유용하다. 전달받은 인자가 의심쩍을 경우 Promise 로 래핑해버리자. 그게 Promise 라면 그냥 반환하니까 좋고, 아닐 경우에도 Promise 로 바꿔준다. 정말 사랑스러운 메서드다. Promise.reject([statusValue]);Promise.resolve 에서 상태값만 rejected 로 바뀐 대칭적인 메서드다. Promise.resolve 가 인자를 내부적으로 정규화해봐야 resolved 인지 rejected 인지 알 수 있다면, 이 메서드는 값이 무엇이든 그냥 rejcted 상태로 바꿔버린다는것만 다르다. Promise.all([ …promise ]);Promise 의 배열을 인자로 받고 Promise 가 전부 resolve 되면 resolved, 혹은 promise 배열중 하나라도 rejected 되면 rejected 가 되는 Promise 를 반환한다. then 의 콜백에 전달되는 인자는 Promise.all 에 전달된 promise 의 순서대로 상태값의 배열로 전달된다. 1234567891011var normalPm = new Promise(function(resolve) &#123; resolve(&#x27;ok-1&#x27;)&#125;);var asyncPm = delay(2000, function() &#123; return &#x27;ok-2&#x27; &#125;);var immidiatePm = Promise.resolve(&#x27;ok-3&#x27;);Promise.all([ normalPm, asyncPm, immidiatePm ]).then(function(resolvedArr) &#123; console.log(resolvedArr); // [ &#x27;ok-1&#x27;, &#x27;ok-2&#x27;, &#x27;ok-3&#x27; ]&#125;); Promise.race([ …promise ]);Promise.all 이 전부 resolved 혹은 하나라도 rejected 를 처리한다면 이 메서드는 인자로 전달된 promise 중 하나의 상태변화만을 처리한다. Promise 중 하나라도 상태가 변할 경우 즉시 그 Promise 의 상태값을 처리한다. 이름 그대로 경합이라고 볼 수 있다. 123456var rabbit = delay(1000, function() &#123; return &#x27;토끼&#x27; &#125;);var turtle = delay(2000, function() &#123; return &#x27;거북이&#x27; &#125;);Promise.race([ rabbit, turtle ]).then(function(resolved) &#123; console.log(resolved); // &#x27;토끼&#x27;&#125;); 위 예제의 실행 결과는 언제나 토끼 가 된다. 이 메서드가 일반적으로 유용하게 쓰이는 부분은 타임아웃 처리가 필요한 부분이다 12345678var userRequest = ajaxRequest(&#x27;/api/user/list&#x27;);var timeout = delay(3000, function() &#123; return Promise.reject(&#x27;서버 응답이 늦습니다&#x27;); &#125;);Promise.race([ userRequest, timeout ]) .then(handleUserList) .catch(handleServerTimeout) 서버 통신, WebSql 등의 작업, WebWorker 연계 등 사용처는 많다. 결론ES2015 이후 ECMAScript 에서는 차차 모든 비동기 건에 대해 Promise 인터페이스로 가는 중이다. Promise 를 한번 익혀둔다면 앞으로의 프로그래밍에 봄날이 오리라는 건 확실하다. Promise 에 대해 글을 쓰려고 마음먹은건 몇달 전이다. 지지부진했던 이유가 부분이 가볍게 설명하자니 너무 간단하고 성의없어지고, 조금만 살을 붙여도 너무 많아지는 거였다. 결국 써놓고 보니 장문의 포스트가 되어버렸다. 읽는데 굉장한 불편함이 있을거라 생각된다. :) 참고 비동기와 Promise 1 비동기와 Promise 2 비동기와 Promise 3 BsideSoft 공식 블로그 # 동기화 vs 비동기화 1 BsideSoft 공식 블로그 # 동기화 vs 비동기화 2 BsideSoft 공식 블로그 # 동기화 vs 비동기화 3 NHN Enter # 자바스크립트와 이벤트 루프 2ality # ECMAScript 6 promises - foundations jakearchibald’s blog # Tasks, microtasks, queues and schedules","pubDate":"Tue, 08 Nov 2016 15:00:00 GMT","guid":"https://blog.javarouka.me/2016/11/09/javascript-async-promise-2/","category":["Tech","javascript","ecmascript","promise","async"]},{"title":"비동기와 Promise #1","link":"https://blog.javarouka.me/2016/11/08/javascript-async-promise-1/","description":"Run to Completion다음 Java Code 가 있다. 어떤 웹 서버 프로그램에서 모듈의 사용 횟수를 카운팅하는 프로그램이다. 12345678910111213public class UserStore &#123; private long count = 0L; @Resource private UserProvider provider; public User findUser(String id) &#123; final User found = provider.getById(id); count++; return found; &#125;&#125; 모듈 호출시마다 사용 카운트 변수 count 를 1씩 증가시킨다. 언뜻 잘 동작할듯 싶지만 이 코드는 잘못된 통계를 내놓는다. count++ 는 한줄로 써 있어 단일연산인 것처럼 보이지만, 실제로는 count 값을 가져온다 1을 더한다 count 에 다시 할당한다 라는 3단계의 작업이다. 다수의 요청 스레드가 저 메서드를 호출할 경우 한 스레드는 count 값을 가져온 상태에서 다른 스레드가 이미 값을 갱신한 상태가 될 수도 있다. 최신의 값을 반영하지 못한 상태에서 여러 스레드가 값을 갱신하기 시작하면 결국 저 count 는 실제 콜 횟수와는 다른 값을 보여줄 것이다. 하지만 JavaScript 에선 이런 일이 일어나지 않는다. JavaScript 의 코드는 항상 실행-완료 (Run-to-completion) 을 보장하는데, 코드가 해석되고 수행될 때는 다른 코드의 실행이 되지 않는다는 실행 방식을 말한다. 위 코드를 javascript 버전이다. 12345678910111213141516(function(someModuleSystem) &#123; var count = 0; var userProvider = someModuleSystem.require(&#x27;userProvider&#x27;); function findUser(id) &#123; var found = userProvider.findUser(id); count++; return found; &#125; someModuleSystem.export(&#x27;userStore&#x27;, &#123; findUser: findUser &#125;);&#125;)(someModuleSystem); someModuleSystem 은 모듈 시스템(RequireJS 나 commonjs 등등…) 이라고 생각하자 위 코드에서는 여러 타이머나 이벤트 등의 비동기성을 띈 코드에서 이 모듈의 findUser 를 호출해도 완벽하게 이 모듈의 콜 카운트를 보장할 것이다. 더 이해를 높이기 위해 다음 코드를 보자 123456789101112131415161718// 0.1초간 실행되는 함수function workShortTime() &#123; var elapsed = (+new Date) + 100; while((+new Date) &lt; elapsed) &#123;&#125; console.log(&#x27;workShortTime complete&#x27;)&#125;// 2초간 실행되는 함수function workLongTime() &#123; var elapsed = (+new Date) + (1000 * 2); while((+new Date) &lt; elapsed) &#123;&#125; console.log(&#x27;workLongTime complete&#x27;)&#125;function work() &#123; setTimeout(workShortTime, 1); workLongTime();&#125; setTimeout 으로 0.001초만 대기한 뒤에 workShortTime 를 수행하게 하고 다음 workLongTime 을 수행한다. 하지만 0.001초가 지났다고 해도 workLongTime 을 중단하고 workShortTime 가 먼저 실행되진 않는다. 2초 뒤 workLongTime 가 끝난 다음에야 workShortTime 이 수행될 것이다.(실제 느린 PC 에서 이 코드를 브라우저가 화면을 그리고 있을때나, NodeJS 서버가 요청을 처리하는 도중 수행시키면 이 코드가 끝날 때까지 화면을 더이상 그리지 않고, NodeJS 서버라면 아무런 동작을 하지 않을 것이다.) javascript 의 친구들 몇명 소개Call Stack보통 프로그래밍 언어에서는 함수가 호출될 경우 함수들은 자신을 호출한 곳으로 되돌아갈 곳 을 알아야 한다. 이 정보는 대부분 stack 으로 관리된다. Java 프로그래머라면 이 정보를 보기 위한 Exception::printStacktrace 에 익숙할 것이다 JavaScript 도 타 언어와 비슷한 Call Stack 이라는 게 존재하고, 메서드 수행 시마다 Stack 에 입력한 뒤 순차적으로 스택을 비워가며 실행한다.스택이 다 비워질 경우 종료된다. 다음 코드를 보자. 먼저 스택을 보기 위한 코드부터 만들자. 12345678910// stacktrace 함수function stacktrace() &#123; try &#123; throw new Error(); &#125; catch(ex) &#123; // Error 구문을 지우기 위한 코드 console.log(ex.stack.split(&#x27;\\n&#x27;).slice(1).join(&#x27;\\n&#x27;)); &#125;&#125; 이제 코드 1234567891011121314function stepA() &#123; stepB();&#125;function stepB() &#123; stepC();&#125;function stepC() &#123; stacktrace(); console.log(&quot;complete!&quot;)&#125;console.log(&#x27;시작합니다.&#x27;, stacktrace())stepA(); 콘솔창에서 실행한다고 가정할 때 결과는 대충 아래와 같은 모습이다. 123456789 at stacktrace (&lt;anonymous&gt;:3:15) at &lt;anonymous&gt;:12:23시작합니다. undefined at stacktrace (&lt;anonymous&gt;:3:15) at stepC (&lt;anonymous&gt;:8:5) at stepB (&lt;anonymous&gt;:5:5) at stepA (&lt;anonymous&gt;:2:5) at &lt;anonymous&gt;:14:1complete! 제일 처음에는 호출 스택에는 아무것도 없다. 코드가 실행되면 그때 call stack 에 실행중인 함수(첫 코드 실행시에는 runScript 라고 하자) 가 삽입된다. 1stack = [ runScript ] 첫 코드 실행후 만나는 함수(메서드)는 stacktrace 다. 이 함수가 실행되는 시점의 스택은 1stack = [ runScript, stacktrace ] 이다. 그리고 stacktrace 함수가 종료되면서 stacktrace 는 제거되고 다시 console.log 가 실행된다. 그 시점의 스택은 이렇다. 콘솔에는 다음과 같이 찍힐 것이다. 12at stacktrace (&lt;anonymous&gt;:3:15)at &lt;anonymous&gt;:12:23 1stack = [ runScript, console.log ] 그 다음 console.log 실행이 끝나고 콘솔에는 시작합니다 undefined 가 찍힌다. 그리고 스택은 다시 비워져 runScript 만 남는다. 1stack = [ runScript ] 그 다음에는 stepA 함수가 실행되며 스택은 다음과 같다. 1stack = [ runScript, stepA ] 그 후 stepB, stepC 가 순차 실행되고 stepC 내부에서 stacktrace 를 실행하여 다음과 같이 된다 1stack = [ runScript, stepA, stepB, stepC, stacktrace ] stepC 에서 stacktrace, console.log 까지 실행한 뒤에 다시 stepB 로 돌아가는 시점의 stack 은 다음과 같을 것이다. 1stack = [ runScript, stepA, stepB ] 그리고 순차적으로 함수가 종료되며, 스택이 모두 비워지고 더이상 수행할 코드도 없다면 runScript 까지 지워지며 프로그램은 끝난다! javascript 실행기는 코드가 실행되면 Call Stack 을 조사한뒤 없어질 때까지 코드를 실행하고 스택이 전부 비워질 경우 실행을 종료하는 것이다. 중간에 새로운 함수 호출등으로 스택에 추가되어도 순차적으로 처리될 뿐, 작업 순서의 변동은 없다. 그렇다면 이벤트 핸들링 함수나 타이머 등의 작업, Ajax 등의 작업은 어떻게 일어날까. Event Loop, Task Queuejavascript 에는 여러 비동기성 작업들이 있다. 대충 목록을 나열하면 다음과 같은 것들이 있다 DOM 처리 (화면 갱신을 포함한다) 애니메이션 Ajax Timer Object Observer Callback Promise 일련의 비동기 작업들은 Event Loop 와 엔진이 실행되는 한 무한정 도는 루프와 Task Queue 라는 것으로 처리된다. 코드로 표현하면 다음과 같다. (MDN 참고) 123while(queue.waitForMessage()) &#123; queue.processNextMessage();&#125; Task Queue 를 감시하다가, Task가 있으면 꺼내서 javascript 의 Call Stack 에 추가한다. javascript 는 Call Stack 에 작업이 추가되었으므로 그것을 실행하여 Call Stack 단락에서 본 같은 작업을 진행하게 된다. 12345678910111213141516function stepA() &#123; timerA(); // 2&#125;function timerA() &#123; setTimeout(stepB, 100) // 3&#125;function stepB() &#123;&#125; // 7function stepC() &#123;&#125; // 5stepA(); // 1stepC(); // 4console.log(&quot;complete!&quot;); // 6 위 코드는 주석에 쓰인 숫자 순서대로 실행된다. 3 부분이 실행되는 시점의 Call Stack 은 다음과 같다. 1stack = [ runScript, stepA, timerA, setTimeout ] 이 되고 setTimeout 은 100 밀리세컨드 뒤의 타이머 작업 (stepB 함수를 Task Queue 에 넣는 작업) 을 준비한다. 그 뒤 6번째 주석의 코드가 수행 전 시점의 Call Stack 은 다음과 같다. 1stack = [ runScript ] 그리고 console.log 가 실행되고, 콘솔에 complete 를 출력한 뒤 종료되면 Call Stack 은 비워지고 일단 첫 코드 실행은 종료된다. Event Loop 는 Call Stack 이 비워졌으므로 Task Queue 를 뒤져보지만 비어있는 상태이기에 다음 루프를 진행한다.(대기한다고 표현하는게 더 나을수도) 0,1초가 지난 뒤 (Event Loop는 그 동안에도 여러번의 루프가 진행되고 있었을 것이다) Task Queue 에 stepB 함수가 추가된다. Call Stack 도 비어있는 상태이고 Job Queue 에도 작업이 있는 상태기에 Event Loop 는 Task Queue 에서 Task 을 하나 꺼내 실행시킨다. 실행된 함수는 Call Stack 에 추가되고 실행된다. 1stack = [ runScript, stepB ] 최종적으로 stepB 도 종료되고 수행이 끝나면 더이상 수행할 게 없으므로 다시 javascript 실행을 중단하고 Event Loop 는 다시 Task Queue 에 새로운 Task 이 들어오는지 루프를 돌기 시작할 것이다. 이게 javascript가 비동기를 실행하는 방법이다. 재미있는 것은 이 Event Loop 는 ECMAScript 에 포함되는 스펙은 아니며 javascript 엔진을 구동하는 환경에서 제공한다는 점이다. 브라우저라면 브라우저에서 따로 구현된 모듈에서, NodeJS 의 경우에는 libuv 라는 라이브러리로 동작한다. 이 이벤트 루프는 libuv 의 경우 다중 스레드로 구현되어 있다. ECMAScript 는 단일 스레드이고 javascript 환경은 다중 스레드라고 볼 수도 있겠다. Timer타이머의 동작은 위에서 설명한 대로 지정된 밀리초 이후 작업을 수행하는 것이 아닌 Timer Api 에서 해당 시간만큼 지연된 뒤에 Job Queue 에 추가한다. 추가만 한다는게 중요한데, Task Queue 에 이미 적재된 Task 이 많거나 javascript 실행에서 상당한 지연이 발생할 경우 그 작업은 예정된 시간보다 늦게 실행될 수 있다. setTimeout 과 setInterval 의 차이는 스케쥴링을 하느냐 안하느냐의 차이인데, 실제로는 미묘한 차이도 존재하는 듯 하다. 그렇다면 비동기 처리는따로 준비된 비동기 처리구문은 결국 Task Queue 에 작업을 추가하고 Event Loop 의 한번의 루프에 처리되는 일을 여러 타이밍에 나눠 담는 것이 avascript 의 비동기 처리라고 볼 수 있다. 실제 javascript 의 Call Stack 에 추가되는 시점이 Event Loop 에 의해 여러 시점이 된다면 비동기 처리가 되는 것이다. 장시간 수행 로직에 대한 비동기 처리 예제가령 서버에서 100만개의 유저리스트를 가져왔고 이 User 리스트에 대해 색인이 필요한 상황이라고 해보자.(물론 클라이언트에서 이걸 처리하고 있는게 이상하긴 하다) 이걸 정직하게 처리하면 분명 사용자는 처리되기 전 까지 버튼을 클릭하거나 페이지를 이동하는 등의 작업을 하지 못하고 정지된 화면을 감상하게 될 것이다. 이럴 경우 비동기 처리를 활용하여 분산처리하는게 좋다. 123456789101112131415161718192021222324252627282930313233var userList = [ ... 백만개 ... ];var indexed = &#123;&#125;;// 인덱싱 함수. 구현은 비워두었다.function indexing(user) &#123; // ... 어떤 인덱스 로직 구현 ...&#125;// 실제 작업 진행 함수// 유저리스트가 비어있다면 false 를 반환하고 있다면 인덱싱을 진행한다function process() &#123; if(!userList.length) return false; var user = userList.pop(); indexing(user); return true;&#125; // 작업자를 구동시키는 함수.// 타이머를 0 밀리세컨드로 허용하는 최소 단위의 스케줄로 매번 주어진 인자를 수행한다.function work(fn, name) &#123; return function go() &#123; setTimeout(function() &#123; var ret = fn(); console.log(ret ? &#x27;[&#x27; + name + &#x27;] processed&#x27; : &#x27;[&#x27; + name + &#x27;] stop&#x27;) if(ret) go(); &#125;, 0); &#125;();&#125;// work 함수로 분산 처리한다.// 몇개를 더 수행해도 상관 없지만 지연 시간이 0초로 주어진 이상 그리 효율은 없을것 같다.work(process, &#x27;process-1&#x27;);// work(process, &#x27;process-2&#x27;); 만일 인덱싱의 종료 조건을 알고 싶다면 work 함수의 종료 조건절 if(ret) go() 에 완료 콜백으로 처리하는 방법이 있다. 다음 포스트 에서 알아볼 Promise.all 과 같이 쓰면 코드가 더욱 간결해질 것이다. 참고 비동기와 Promise 1 비동기와 Promise 2 비동기와 Promise 3 BsideSoft 공식 블로그 # 동기화 vs 비동기화 1 BsideSoft 공식 블로그 # 동기화 vs 비동기화 2 BsideSoft 공식 블로그 # 동기화 vs 비동기화 3 NHN Enter # 자바스크립트와 이벤트 루프 2ality # ECMAScript 6 promises - foundations jakearchibald’s blog # Tasks, microtasks, queues and schedules","pubDate":"Mon, 07 Nov 2016 15:00:00 GMT","guid":"https://blog.javarouka.me/2016/11/08/javascript-async-promise-1/","category":["Tech","javascript","ecmascript","promise","async"]},{"title":"ES2015 - var, const, let","link":"https://blog.javarouka.me/2016/03/31/let-const/","description":"Hello, let?ES2015 에는 새로운 변수 선언법이 추가되었다. 예전에는 현재의 스코프에 ‘변수’를 ‘선언’ 하는 방법은 var 와 function 뿐이었다. 123456var a = 1; // 전역 스코프에 변수 a 선언function b() &#123;&#125;; // 전역 스코프에 함수 b 선언function c() &#123; var a = 3; // 함수 c 스코프에 변수 a 선언&#125; 이제는 새로운 변수 선언법인 const와 let 이 생겼다. 이 둘은 ES2015에 새로이 추가된 블럭 스코프에 묶이는 변수들이다.(사실 ES2015 에서는 var 를 쓰는건 문법면에서 추천하지 않고 있다.) const 는 불변 변수, let은 가변 변수를 선언할 때 쓰이며, 당연히 const 는 선언과 동시에 할당하지 않으면 TypeError가 발생한다. 기존에는 변수를 특정한 스코프에 묶으려면 이렇게 해야 했다. 12345678var hello = &quot;hello&quot;;(function() &#123; // IIFE function scope var hello = &quot;안녕&quot;; console.log(hello) // 안녕 &#125;)();console.log(hello); // hello 하지만 이젠 아주 간단히 해결된다. 123456789let hello = &quot;hello&quot;;// block scope&#123; let hello = &quot;안녕&quot;; console.log(hello) // 안녕 &#125;console.log(hello); // hello 그리고 const 키워드는 코드를 읽는데도 큰 도움을 준다. 변수의 불변성(immutable) 이라는 건 가독성 뿐 아니라 여러 면에서 장점이 많기 때문이다. 코드 블럭에 남발된 가변 변수의 존재는 자신의 어지간히 머리가 좋지 않은 이상 코드를 읽을 때 방해물이 되기 쉽다. 어떤 때 let 을 사용하고, 어떤때 const를 사용해야 할까결론부터 이야기하면, 일단 모든 변수에는 const 를 사용하고 본다. 그리고 어쩔 수 없이 가변값을 다루거나 특정 변수가 미래에 변할 가능성이 있을 때만 (좀 더 정확히는 TypeError 발생 시) let 을 사용하면 된다. 실제 const만을 사용하여 코딩해보면 let을 사용할 기회가 많지 않다는 사실에 놀랄 것이다. 혹시 loop 인덱스 변수에는 사용해야 하지 않나요? 라고 물을 수 있는데, ES2015 에서는 loop 마다 새로운 변수 바인딩을 생성하기에 아무 문제가 없다. 1234const fruit = &#123; &#x27;사과&#x27;: &#x27;맛있다&#x27;, &#x27;바나나&#x27;: &#x27;역시맛있다&#x27; &#125;for(const key in fruit) &#123; console.log(key, fruit[key]);&#125; 루프마다 ‘새로운 바인딩’ 이라는게 중요하다. 그렇다면 바로 다음 코드를 보자. 이건 어떻게 동작할까? 1234567const indexMap = [];for(let i = 0; i &lt; 10; i++) &#123; indexMap.push(function() &#123; return i; &#125;);&#125;console.log( indexMap.map(function(val)&#123; return val(); &#125;)); 결과는 1// [0, 1, 2, 3, 4, 5, 6, 7, 8, 9] 반면, 앞선 i 를 var 로 바꾸면, 결과는 완전히 달라진다. 12345678const indexMap = [];for(var i = 0; i &lt; 10; i++) &#123; indexMap.push(function() &#123; return i; &#125;);&#125;console.log( indexMap.map(function(val)&#123; return val(); &#125;));// [10, 10, 10, 10, 10, 10, 10, 10, 10, 10] var의 경우는 새로운 스코프 없이 한 변수에 인덱스가 추가되며 바인딩되었고, 결국 indexMap 에 순차적으로 추가한 함수들이 같은 스코프의 var 를 참조하면서(이걸 Closure 라고 부른다) 전부 10이 찍히게 된다. 이걸 막으려면 ES5 에서는 1234567for(var i = 0; i &lt; 10; i++) &#123; // 새 스코프를 생성하기 위해 즉시 실행 함수 호출(IIFE) 로 둘러싼다 (function(i) &#123; indexMap.push(function() &#123; return i; &#125;); &#125;)(i);&#125; 라는 다소 보기 좀 불편(?) 한 코드를 사용해서 먼저 함수 스코프로 감싸야 했다. let과 const를 쓰면 이젠 이런 코드로부터 해방이다~! 아, 혹시 위에 지나간 예제중에 let 을 const로 바꾸면 어떨까 하는 다음과 같은 코드를 생각했다면, 123for(const i = 0; i &lt; 10; i++) &#123; indexMap.push(function() &#123; return i; &#125;);&#125; 이것은 동작하지 않는다. 루프마다 새 바인딩이 되는 것은 맞아서 앞의 const i = 0; 부분은 문제가 없지만, i++ 이 부분이 문제가 된다. const 는 불변이기 때문이다. 전역 변수와 전역 프로퍼티JavaScript 를 어느정도 다뤄본 사람이라면 전역 변수에 대해 여러 생각이 있지만, 공통된 생각은 해롭다는 것에 동감할 것이다. var 를 사용해서 전역에 변수를 선언할 경우, 전역에 변수를 선언한다. 이건 당연하다. 하지만 여기서 끝나는게 아니라 전역객체의 프로퍼티에도 이 변수가 프로퍼티로 잡힌다. 12345678var a = 1;console.log(a); // 1console.log(window.a) // 1. 전역 객체(window) 에 프로퍼티로 자동으로 잡혔다하지만 let과 const는 전역에서 변수를 선언 시 전역 스코프에는 변수를 할당하나, 전역 프로퍼티에는 변수를 할당하지 않는다. 아래 코드를 보자.const a = 1;console.log(a); // 1console.log(window.a) // undefined. 전역 객체(window) 에 프로퍼티로 잡히지 않는다. 사실 ES2015의 특성 (모듈 및 블럭 스코프) 과 맞물려 전역객체에 뭔가를 할당할 일은 전혀라고 좋을 정도로 없어져 버렸기에, var는 더욱 쓸 일이 없어졌다. 호이스팅과 TDZ(Temporal Dead Zone)호이스팅은 간단히 설명하면 이런 현상을 말한다. 1234567891011var a = 1;function test() &#123; // undefined. 코드 실행 전 함수 내부 스코프의 a가 먼저 선언되고 undefined 상태가 된다. // 상위 스코프의 a는 shadow. console.log(a); var a = 3; // 이제야 3이 찍힌다. console.log(a);&#125; ES2015 이전에선 var 기반 변수 선언과 JavaScript의 함수 스코프의 특성으로 현재 스코프의 모든 변수 선언을 실행 전 먼저 선언하고 undefined 를 할당해두는 동작을 했다. 이걸 보통 사람이 코드를 위에서 아래로 읽어나갈 때 변수들이 현재 스코프의 최상단으로 끌어올려진다(Hoisted) 다고 하여 호이스팅이라고 부른다. let과 const 도 물론 호이스팅이 된다. 하지만 세부 내용은 좀 다르다. var 의 함수 스코프 단위의 호이스팅이 아닌 블럭 스코프 호이스팅이며, 선언만 할뿐 실행기가 undefined 등을 할당해주는 친절함 따위도 없다. 그리고 그 변수가 완전히 할당되기 전 사용하려 하면 오류가 난다. 코드를 보자 123456const a = 1&#123; console.log(a); const a = 10; console.log(a);&#125; 뭔가 1 다음 10이 출력될 것 같지만, 이 코드는 ReferenceError 를 낸다. 일단 코드가 실행되면 바깥 스코프에 a 가 10으로 선언된다. 블럭에 진입해서 새로운 스코프가 만들어지고, 블럭 안의 a 역시 호이스팅되어 바깥 스코프의 a를 가리지만, 아직 이 변수는 사용할 수 없는 상태이다. 이것을 ES2015 에서는 TDZ - Temporal Dead Zone 이라고 부른다. 코드가 실행되서 호이스팅과는 별개로 실제 코드의 선언문을 실행하게 되면 그때서야 변수가 성공적으로 초기화되고 할당 구문이 있다면 값이 할당되고 없다면 undefined 가 할당될 것이다. 특히 ES2015에 새로 추가된 변수 해체나 파라미터 기본값 처리 시 실수의 여지가 있다. 코드를 보자. 1234function test(a = b, b = 4)&#123; console.log(a,b);&#125;test(); // ReferenceError. 이건 실제로는 기본값 할당이 다음과 같이 처리되기에 TDZ 에 따라 ReferenceError 이다. 12let a = b; // TDZ!let b = 4;","pubDate":"Wed, 30 Mar 2016 15:00:00 GMT","guid":"https://blog.javarouka.me/2016/03/31/let-const/","category":["Tech","javascript","ecmascript"]}]}